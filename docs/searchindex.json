{"categories":[],"posts":[{"content":"Raycast Raycast 是一個混合形的工具，可以簡單的認識他是一個強化版的 Soptlight search\n這些進階功能有效的提高工作效率，值得認識認識\n安裝和設定 安裝相當容易，在官方網頁的右上角點擊 Download 就可以成功下載了～\n如果是 Homebrew 使用者\nbrew install --cask raycast General 按下 Cmd + , 可以開啟 Raycast Settings 的畫面～\n在第二個 Tab 的 Extensions 裡面列舉了很多 built-in 的 Applications！ 接下來的段落會介紹一些我比較常用的 Applications 🫡\n開機啟動 Startup 勾起來，在開機的時候會自動幫你把 Raycast 打開～\n取代 Spotlight 為了完全取代 Spotlight，我們可以跟隨官方指南\n將 Raycast Hotkey 修改成 Cmd + Space 關閉 macOS built-in 的 spotlight System Preferences \u0026gt; Keyboard \u0026gt; Shortcuts \u0026gt; Spotlight Extensions Extensions 是你會在 Raycast 能看到的工具們，分成 Apps, Commands, Scripts, Quicklinks\n每個分類都有一些一樣的欄位： Name, Type, Alias, Hotkey, Enabled。\n在搜尋時，會找出符合 Name 和 Alias 的 Extensions，以上面的截圖來說你可以輸入 Activity 或是 top 就可以開啟你的 mac 活動監視器！\n而 Hotkey 也相當容易理解，即使你不開啟 Raycast 也能透過快捷鍵綁定直接快速啟動該 App。 另如你可能會希望像是 Ubuntu 預設的那樣子，來個 Cmd + Shift + T 直接就開啟 Terminal 👍。\nApps 基本上就是你的 mac 中所有的 Applications。\n例如如果說你想開個 Air Drop 那直接在 Raycast 輸入就好了，很快 XD\nCommands 這邊就是 Raycast 提供的擴充功能了，想知道有哪些東西可以用就在這邊尋找！ 包含預設 built-in 的擴充功能，和手動下載的擴充功能\n下一段會介紹一些精選的功能介紹 ：）\nScripts Scripts 可以說是 Raycast 最實用的功能了，能讓你編輯簡單的 Script 基本上可以做到任何事情。 支援的語言有 Bash/App Script/Swift/Python/Ruby/Node.js，而且基本上你只有有 Bash 就可以做到任何事情了 👍\n開頭的 Shebang 我指定執行 fish，這樣子才吃得到我預設好的 alias。\n而中間那一長串註解是給 Raycast 看的，他會利用這些內容來定義怎麼執行這個 Script。\n例如 @raycast.icon 或是 @raycast.argument1 表示可以接受的參數，而 @raycast.mode 則表示當 Script 執行後如何處理回傳的結果\n#!/usr/bin/env fish # Required parameters: # @raycast.schemaVersion 1 # @raycast.title cht # @raycast.mode fullOutput # Optional parameters: # @raycast.icon 📖 # @raycast.argument1 { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;, \u0026quot;placeholder\u0026quot;: \u0026quot;Directory\u0026quot; } # Documentation: # @raycast.author XiaoXiao # @raycast.authorURL https://github.com/xiaoxiaosn # source ~/.config/fish/functions/cht.fish cht $argv[1] 個人常用的 Scripts: https://github.com/XiaoXiaoSN/dotfiles/tree/main/raycast\nQuicklinks 有時候有些需求比較單純，例如說只是想要快速開啟特定頁面這時候比起 Scripts 更適合使用 Quicklinks\n例如說使用 finder 開啟 Download 資料夾：\n或是用 VSCode 開啟特定專案位置：\n當然也可以帶參數，例如說 Google Search：\n常用指令 快速轉換 (Calculator History) 和 macOS 內建的 Spotlight 一樣提供各式單位轉換，更是擴充了很多不同的單位，按下 Enter 就可以快速複製結果～\n也可以輸入 Calculator History 來看看都算過了些什麼～\n日常單位 重量 距離 溫度 貨幣 算數 Raycast 也可以完成一些簡單的算數\nClipboard 輸入 Clipboard History 開啟剪貼簿的歷史紀錄，還可以搜尋！ 使用 Ctrl + n 和 Ctrl + p 選取你要的歷史紀錄，按一下 Enter 後就又複製起來啦～\n另外要強調一個很讚的功能，Clipboard History 頁面裡面可以為你複製過的圖片直接做 OCR\n先按 Cmd + k 開啟 Actions 選單，再選擇 Copy Text from Image 就可以把圖片中的文字直接抓出來了喔～\nSchedule 只要輸入 My Schedule 就可以開啟，第一次會詢問是否要給予存取日曆的權限\n可以快速看到今天安排行行程，非常實用\nSwitch Windows 是否有時候開了越來越多的視窗，要找東西的時候非常麻煩呢？\n輸入 switch 按下 Tab 或是 Enter，就會跳出這些視窗的名字，選下去就會跳到那個視窗囉。\nSnippet Raycast Snippet 讓你定義自己的 keyword 和想產生的 snippet 片段，當你輸入了那個 keycloak 時就會自動的取代掉\n例如說這個設定，我只要在任何地方，包含瀏覽器、VSCode、Slack 都可以，輸入 !@fstnetwork 他就會幫我把這個關鍵字取代成公司統編：\n或是輸入 !@eth 他就會幫我取代成我的錢包地址：\n另外他也提供 placeholder 的功能，只要在 snippet 中輸入用大括號包起來的東西 {} 當 snippet 轉換完後游標就會跳到那個位置\n╭◜◝ ͡ ◜ ͡ ╮ ╭◜◝◝ ͡ ͡◜◝ ͡ ◝╮ ( 好想要 ) ( 發廢文 ) ╰◟◞ ͜ ╭◜◝ ͡ ◜◝ ͡ ◝ ͡ ╮◞◟◞ ╯ ( 發一整天 ) ╰◟◞ ͜ ◟◞ ͜ ◟◞ ╯ ₍ᐢ..ᐢ₎ᐝ 也歡迎參觀官方提供的 Snippet 看看其他人有什麼奇怪的想法 https://snippets.ray.so/\n實用擴充 GIF 是否有時候臨時想找一張 GIF 來圖戰，但又要花時間去 Google 呢？\n安裝 Search for GIFs，並搜尋關鍵字，按一下 Enter 就可以直接複製到剪貼簿上面囉！\nShorten URL Shortener 可以幫你快速把一串網址給簡短化。 只需要簡單的填上你想要 shorten 的網址，按下 Enter 就會直接幫你複製到剪貼簿上了！\n直接貼上： https://tinyurl.com/2fcpre6\n快樂區 最後快樂的慶祝一下吧～～ Ref https://blog.justin0u0.com/Raycast-%E8%B6%85%E8%A9%B3%E7%B4%B0%E4%BB%8B%E7%B4%B9%EF%BC%81%E5%BF%AB%E9%80%9F%E6%8F%90%E5%8D%87%E7%94%9F%E7%94%A2%E5%8A%9B%E7%9A%84%E8%B6%85%E5%A5%BD%E7%94%A8%E5%B7%A5%E5%85%B7%EF%BC%81/\n","id":0,"section":"posts","summary":"Raycast Raycast 是一個混合形的工具，可以簡單的認識他是一個強化版的 Soptlight search 這些進階功能有效的提高工作效率，值得認識認識 安裝和設定 安裝相當容易，在官方網頁的右","tags":["macos","raycast"],"title":"macOS 生產力工具 - Raycast 真的很讚","uri":"https://blog.10oz.tw/20230830-raycast/","year":"2023"},{"content":" Elasticsearch version: 8.x\n認識 Data Stream Data Stream 是 Elasticsearch 官方幫常用模式建立的一個模板。 就如他的名字 Stream，他被用來管理跨多個 indexes 的 time series 資料。因此類似 logs, events, metrics 這類的時序資料就可以使用 Data Stream 來管理，\nData Stream 本身其實是多個的 indexes 所組成，包含了 index alias, index lifecycle manager 還有一些預設的 constraints。\n要建立一個 Data Stream 有三個主要欄位需要設定，這個 Data Stream 的命名將會被組合成 {type}-{dataset}-{namespace}\ntype 可以選 logs, metrics，未來可能會支援 traces, synthetics dataset 主要的名字，用來描述這個 Data Stream 放的是什麼資料。例如說 nginx.access、prometheus，預設值是 generic 以我的使用場景來看的話，系統要存 application logs 和 events，所以我就有兩個 dataset 分別叫做 application 和 event namespace 單純用來做資料分組，預設值是 default 例如說 logs-apm.app-default 就是一個 dataset=logs, namespace=apm.app, type=logs 的 Data Stream，而這個 Data Stream 會建立以 .ds-\u0026lt;data-stream\u0026gt;-\u0026lt;yyyy.MM.dd\u0026gt;-\u0026lt;generation\u0026gt; 命名的 indexes。\n在 Kibana 的 Web UI 中，這些索引預設是隱藏的。如果打開顯示就會看到類似 .ds-logs-apm.app-default-2023.07.10-000006 的索引名稱。\n和之前的 Index Alias 功能一樣，讀取時會讀取底下的所有 Indexes 但只會有一個 Index 是 write only 的！ Step by Step 建立 Data Stream https://www.elastic.co/guide/en/elasticsearch/reference/current/set-up-a-data-stream.html\n建立一個 ILM 官方建議使用 Index Lifecycle Manager(ILM) 來幫助管理 Data Stream 下的 indexes\n所以我們首先新增一個 ILM Policy loc-logs-policy\n每 30 GB 滾動到下一個 index 當資料到 14 days 時轉到 warn phase，並且合併成 1 個 primary shard 當資料到 60 days 時刪除舊資料 PUT _ilm/policy/loc-logs-policy { \u0026quot;policy\u0026quot;: { \u0026quot;phases\u0026quot;: { \u0026quot;hot\u0026quot;: { \u0026quot;actions\u0026quot;: { // rollover when the size exceeds 10GB \u0026quot;rollover\u0026quot;: { \u0026quot;max_size\u0026quot;: \u0026quot;10gb\u0026quot;, \u0026quot;max_age\u0026quot;: \u0026quot;1d\u0026quot; } } }, // After 14 days, move to the 'warm' phase \u0026quot;warm\u0026quot;: { \u0026quot;min_age\u0026quot;: \u0026quot;14d\u0026quot;, \u0026quot;actions\u0026quot;: { // shrink the index to 1 primary shard \u0026quot;shrink\u0026quot;: { \u0026quot;number_of_shards\u0026quot;: 1 }, // force merge index segments to reduce fragment count to 1 // This action makes the index read-only. \u0026quot;forcemerge\u0026quot;: { \u0026quot;max_num_segments\u0026quot;: 1 } } }, // After 60 days, delete index \u0026quot;delete\u0026quot;: { \u0026quot;min_age\u0026quot;: \u0026quot;60d\u0026quot;, \u0026quot;actions\u0026quot;: { \u0026quot;delete\u0026quot;: {} } } } } } 建立 Index Template Data Stream 實際上是由多個 Indexes 組成的，為了管理這些 Indexes 我們建立一個 Index Template，當 ILM 達到時間或是 Size 的條件 Rollover 時，新產生的 Index 會自動 Match 到 Index Template 上\nPUT _index_template/loc-logs-template { \u0026quot;index_patterns\u0026quot;: [\u0026quot;logs-application-dev*\u0026quot;], // 指定這個 Index Template 是 Data Stream type \u0026quot;data_stream\u0026quot;: { }, // 為了避免衝突，官方建議設置 200 以上的 priority \u0026quot;priority\u0026quot;: 500, // 綁定剛剛的 ILM \u0026quot;template\u0026quot;: { \u0026quot;settings\u0026quot;: { \u0026quot;index.lifecycle.name\u0026quot;: \u0026quot;loc-logs-policy\u0026quot; } }, // 寫一些有幫助的訊息 \u0026quot;_meta\u0026quot;: { \u0026quot;description\u0026quot;: \u0026quot;Manage application logs in our Dev environment\u0026quot;, \u0026quot;last_update\u0026quot;: \u0026quot;2023-08-24T17:25:24.254+08:00\u0026quot; } } 建立一個 Data Stream 必須要符合 Data Stream 規範來命名 {type}-{dataset}-{namespace}\nPUT _data_stream/logs-application-dev 由於我們剛剛有指定了 logs-application-dev 的 Index Template，在 Create 他會依照這個 Template 的定義產生 Data Stream\n回傳看起來會像是這個樣子～～\n{ \u0026quot;data_streams\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;logs-application-dev\u0026quot;, \u0026quot;timestamp_field\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;@timestamp\u0026quot; }, \u0026quot;indices\u0026quot;: [ { \u0026quot;index_name\u0026quot;: \u0026quot;.ds-logs-application-dev-2023.08.24-000001\u0026quot;, \u0026quot;index_uuid\u0026quot;: \u0026quot;bDB2EfrJTnCg-lXtVXk31A\u0026quot; } ], \u0026quot;generation\u0026quot;: 1, \u0026quot;_meta\u0026quot;: { \u0026quot;description\u0026quot;: \u0026quot;Manage application logs in our Dev environment\u0026quot;, \u0026quot;last_update\u0026quot;: \u0026quot;2023-08-24T17:25:24.254+08:00\u0026quot; }, \u0026quot;status\u0026quot;: \u0026quot;GREEN\u0026quot;, \u0026quot;template\u0026quot;: \u0026quot;loc-logs-template\u0026quot;, \u0026quot;ilm_policy\u0026quot;: \u0026quot;loc-logs-policy\u0026quot;, \u0026quot;hidden\u0026quot;: false, \u0026quot;system\u0026quot;: false, \u0026quot;allow_custom_routing\u0026quot;: false, \u0026quot;replicated\u0026quot;: false } ] } Ref https://www.elastic.co/guide/en/ecs/master/ecs-data_stream.html\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/set-up-a-data-stream.html#create-index-lifecycle-policy\n","id":1,"section":"posts","summary":"Elasticsearch version: 8.x 認識 Data Stream Data Stream 是 Elasticsearch 官方幫常用模式建立的一個模板。 就如他的名字 Stream，他被用來管理跨多個 indexes 的 time series 資料。因此類似 logs, events, metrics 這類的時序資料就","tags":["elasticsearch"],"title":"How to create an Elasticsearch Data Stream","uri":"https://blog.10oz.tw/20230817-how-to-create-elasticsearch-data-stream/","year":"2023"},{"content":"討論不付錢給 GitHub 的使用者，在 Organization 下的權限控制\n權限 Organization Teams GitHub 採 RBAC 權限控管，在 Organization 底下有 teams，teams 底下也可以再有一層 teams。\n另外要注意的是，team name 在 Organization 下是唯一的，即使是兩層的 teams 也是。\n舉個例子，這樣子 dev, be, fe, operator 是四個 Unique name。\nteams ---- dev ├── be └── fe operator 此時如果想在 dev 底下直接新增一個 team operator 是不行的，因為這個名字已經被使用了，會變成將 operator 移動到 dev 底下。 此時 GitHub 會詢問你是否要移動這個 team 的 parent，這可能會影響到擁有 dev team 的成員。\nRepository \u0026gt; Settings \u0026gt; Collaborators and teams\nRepository Permissions 有以下這幾種權限，越下面的權限越大同時也包含上一級別的權限\nRead Can read and clone this repository. Can also open and comment on issues and pull request. 可以開 PR 可以 comment, reviewer PR 不能 close PR （自己開的可以） 不能 assign reviewer Triage Can also manage issues and pull requests. 可以 assign reviewer 能 close PR 不可以 merge PR 只可以 push branch 到 forked repository Write Can read, clone, and push to this repository. Can also manage issues and pull requests. 可以 merge PR 可以 push branch 到這個 repository Maintain They can also manage issues, pull requests, and some repository settings. 不可以操作 Settings 下的 Secrets/Variables 不可以操作 Settings 下的成員 Admin 預設 create repository 的人會成為 admin 可以注意的是，如果同時有 teams 和個人權限發生衝突時，會以權限較大的那一個為主。 GitHub 也會在有衝突的設置旁寫上一個黃色三角形～～\n","id":2,"section":"posts","summary":"討論不付錢給 GitHub 的使用者，在 Organization 下的權限控制 權限 Organization Teams GitHub 採 RBAC 權限控管，在 Organization 底下有 teams，teams 底下也可以再有一層 teams。 另外要注意的是","tags":["github"],"title":"GitHub Permission 免費方案權限實驗","uri":"https://blog.10oz.tw/20230612-github-permission-for-free-user/","year":"2023"},{"content":"跟這個專案架構相同 kubelived，他的更詳細，可以參考他的介紹\n簡單來說就是 Keepalived(VRRP) + HAProxy\nVRRP (Virtual Router Redundancy Protocol) 設計上用來避免單點故障，當主要服務機器失去連線時可以切換到另一台備援機器上。 維護一組 Virtual IP 指向後面的服務們，使用者只需要將 Request 發到這組 VIP 就會被轉發到其中一台 Real Server 上。\n選舉 Master 當有多台 nodes 時，選舉其中一台作為 Master 其他作為 Backup，依照以下條件競爭\nPriority 最高者優先 VIP 和自身 IP 一致者 選 IP 地址最大的 選舉出 Master 後，Master node 會廣播 ARP 封包將 VIP 的 MAC/IP 設定到自己身上\nMaster 失敗 / Backup 搶佔 VRRP Master node 會定時發心跳包給其他 nodes，如果失去連線其他幾台 node 會重新選出 Master，並且發送廣播 ARP 封包將 VIP 重新定位到新的 Master 上。\n可以設置 nopreempt (No Preempt)，避免原本的 Master Node 恢復狀態後重新搶佔回 Master。 使用場景：假設 Master Node 出問題了，不斷開開關關導致頻繁切換，中間可能發生不預期的走錯路、掉封包問題\nKeepalived 實際上用來設定 VRRP 的管理員件，設定了 VRRP ID, VIP, 網卡\u0026hellip;，也包含用來檢查後端 K8s API Server 是否健康的 script，連續檢查不過就會觸發切換 Master node\n設置完成後會看起來像這樣：\n非 Master node 網卡上只有自己的 IP\n$ ip address show enp5s0 2: enp5s0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 9000 qdisc fq state UP group default qlen 1000 link/ether 7c:10:c9:d2:70:c3 brd ff:ff:ff:ff:ff:ff inet 192.168.97.17/24 metric 100 brd 192.168.97.255 scope global dynamic enp5s0 valid_lft 241387sec preferred_lft 241387sec ... Master node 網卡上多一筆 VIP，這裡是 192.168.97.200\n$ ip address show enp5s0 2: enp5s0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 9000 qdisc fq state UP group default qlen 1000 link/ether 7c:10:c9:d2:71:8c brd ff:ff:ff:ff:ff:ff inet 192.168.97.16/24 metric 100 brd 192.168.97.255 scope global dynamic enp5s0 valid_lft 189537sec preferred_lft 189537sec inet 192.168.97.200/32 scope global enp5s0 valid_lft forever preferred_lft forever ... HAProxy 前面透過 Keepalived 做到備援切換後，實際透過 HAProxy (port 8443) 將流量導向其他 K8s Control Plane (port 6443)\nRef https://github.com/clastix/kubelived https://www.qikqiak.com/post/use-kube-vip-ha-k8s-lb/ https://zhuanlan.zhihu.com/p/537216766\n","id":3,"section":"posts","summary":"跟這個專案架構相同 kubelived，他的更詳細，可以參考他的介紹 簡單來說就是 Keepalived(VRRP) + HAProxy VRRP (Virtual Router Redundancy Protocol) 設計上用來避免單點故障，當主要服務機器失去連線","tags":["kubernetes","ha","vrrp"],"title":"Kubernetes HA - Keepalived(VRRP) + HAProxy","uri":"https://blog.10oz.tw/20230609-kubernetes-ha-keepalived-haproxy/","year":"2023"},{"content":"Step by Step 部署 Elasticsearch 因為接下來會讓備份檔案儲存在 File System 內，所以先準備一個 PVC 給 Elasticsearch\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: elasticsearch-snapshot spec: accessModes: - ReadWriteMany resources: requests: storage: 20Gi storageClassName: \u0026quot;fs-sc\u0026quot; 這邊用 ECK (Elastic Cloud on Kubernetes) 來召喚一組新的 Elasticsearch。 在部署 Elasticsearch CR 時多 mount 一個 path.repo 這個 PV 是等等要用來存 snapshot 的地方\napiVersion: elasticsearch.k8s.elastic.co/v1 kind: Elasticsearch metadata: name: backup-es spec: nodeSets: - config: path.repo: \u0026quot;/backup\u0026quot; count: 1 name: default podTemplate: spec: containers: - name: elasticsearch volumeMounts: - mountPath: \u0026quot;/backup\u0026quot; name: backup volumes: - name: backup persistentVolumeClaim: claimName: elasticsearch-snapshot volumeClaimTemplates: - metadata: name: backup spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi version: 8.6.0 在 Elasticsearch 建立 Snapshot 部署好之後，建立一筆 snapshot repository 名字叫做 my_backup。 注意說這邊如果使用 fs 一定要指定 path.repo 包含的路徑\nPUT /_snapshot/my_backup { \u0026quot;type\u0026quot;: \u0026quot;fs\u0026quot;, \u0026quot;settings\u0026quot;: { \u0026quot;location\u0026quot;: \u0026quot;/backup/loc\u0026quot; } } 或是你有一個 s3 可以用來存備份檔 \u0026gt; u \u0026lt;\nPUT _snapshot/my_backup { \u0026quot;type\u0026quot;: \u0026quot;s3\u0026quot;, \u0026quot;settings\u0026quot;: { \u0026quot;client\u0026quot;: \u0026quot;secondary\u0026quot;, \u0026quot;bucket\u0026quot;: \u0026quot;name-of-bucket\u0026quot;, \u0026quot;region\u0026quot;: \u0026quot;region-of-bucket-same-as-cluster\u0026quot; } } 指定要在這個 snapshot repository 中備份的 index，這邊把 index system_search 備份到 snapshot system_search_snapshot 裡面\nPUT /_snapshot/my_backup/system_search_snapshot { \u0026quot;indices\u0026quot;: \u0026quot;system_search\u0026quot;, \u0026quot;ignore_unavailable\u0026quot;: true, \u0026quot;include_global_state\u0026quot;: false } 測試一下它有效 - 刪除及復原 如果想測試的話，敲一筆資料進去\nPOST /system_search/_doc { \u0026quot;data_process_permanent_identity\u0026quot;: \u0026quot;26bd375d-9be7-4c1c-9846-5cd187fd9b5d\u0026quot;, \u0026quot;data_process_revision\u0026quot;: 2, \u0026quot;data_process_name\u0026quot;: \u0026quot;TEST-BACKUP\u0026quot;, \u0026quot;logic_permanent_identity\u0026quot;: \u0026quot;10b785f5-f833-4c94-9dfb-eeacc8ea88bf\u0026quot;, \u0026quot;logic_revision\u0026quot;: 2, \u0026quot;logic_name\u0026quot;: \u0026quot;TEST-BACKUP-LOGIC\u0026quot;, \u0026quot;execution_id\u0026quot;: \u0026quot;Y3NtSqO4eboPm_oD_puy2A\u0026quot;, \u0026quot;task_id\u0026quot;: \u0026quot;WSCRLsEwGFGh6oAV4EqciA\u0026quot;, \u0026quot;timestamp\u0026quot;: 1668566827117, \u0026quot;sequence\u0026quot;: 2, \u0026quot;type\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;meta\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;source_digital_identity\u0026quot;: \u0026quot;sourceDID\u0026quot;, \u0026quot;target_digital_identity\u0026quot;: \u0026quot;TargetDID\u0026quot;, \u0026quot;label_id\u0026quot;: \u0026quot;b428b5d9-df19-5bb9-a1dc-115e071b836c\u0026quot;, \u0026quot;label_name\u0026quot;: \u0026quot;test\u0026quot; } 查一下確認他寫進去了，也可以看一下 total\nPOST /system_search/_search 直接讓這個 index 消失\nDELETE /system_search 然後 restore 他就回來了，可以再 search 確認資料無誤\nPOST /_snapshot/my_backup/system_search_snapshot/_restore?wait_for_completion=true Other notions ECK 在 Latest 2.6 版本，官方提供的 Kubernetes 版本只有 1.21-1.25 最新的 1.26 呢 QQ\nhttps://www.elastic.co/guide/en/cloud-on-k8s/current/k8s_supported_versions.html\n","id":4,"section":"posts","summary":"Step by Step 部署 Elasticsearch 因為接下來會讓備份檔案儲存在 File System 內，所以先準備一個 PVC 給 Elasticsearch kind: PersistentVolumeClaim apiVersion: v1 metadata: name: elasticsearch-snapshot spec: accessModes: - ReadWriteMany resources: requests: storage: 20Gi storageClassName: \u0026quot;fs-sc\u0026quot; 這邊用 ECK (Elastic Cloud on Kubernetes) 來召喚一組新的 Elas","tags":["elasticsearch"],"title":"Backup Elasticsearch index in File System","uri":"https://blog.10oz.tw/20230215-backup-elasticsearch-index-in-file-system/","year":"2023"},{"content":"我的設定檔在這 新的Neovim 的設定檔，有附上使用說明歡迎給建議或是幫忙 Debug (?\n還有一個以前用的 Vim 設定檔，不過沒怎麼更新了\n基本操作 移動你的游標 w, W 往前到下一個字的字首，e, E 下一個字的字尾 b, B 往回到前一個字的字首 $ 跳到行尾 0 跳到行首，^ 跳到該行第一個文字（不算 TAB 或是空白） {, } 往前/後跳一個段落 f 之後按任意字元，跳到該行下一個的那個字元 f 之後按任意字元，按 ; 再下一個，按 , 回上一個 C_o 跳回上一個遊標的位置， C_i 跳到下一個 C_d 向下滾動，C_u 向上滾動 * 搜尋並前往下一個目前遊標上的字，:noh 取消 # 搜尋並前往上一個目前遊標上的字，:noh 取消 複製貼上 p 往後貼上，P 往游標前貼上 u 是 undo, C_r 再 Redo 回去 也可以用 \u0026quot; 然後 a~z 來指定暫存器，例如 \u0026quot;ay 複製 \u0026quot;ap 貼上 d 是剪下，x 可以剪下遊標上的那一個字 c 可以刪除選取並原地進入插入模式，C 刪除該行以後並進入插入模式 \u0026gt;\u0026gt; \u0026lt;\u0026lt; 可以縮排該行 寫字囉 i 插入模式 I 在該行第一個字進入插入模式 a 在遊標後面進入插入模式 A 在行末進入插入模式 o 向下產生新一行進入插入模式 O 向上 s substitute 代替，剪下遊標上的字並進入插入模式 r 取代一個字元 插入模式下的操作 C-w 刪除遊標往回的一個字 C-u 刪除遊標往回的所有字 Note: 在 Bash 下很多操作也通用喔 https://github.com/tpope/vim-rsi 在檔案取代 %s %s/foo/bar/gc g 是全部、c 是確認 比剛剛更會移動 標記模式 m{a-zA-Z} 按一下 m 加上英文字就可以在那個字上標籤 '{a-zA-Z} 單引號加上標籤就飛過去那一行囉 `{a-zA-Z} 單引號加上標籤就飛過去標記的字囉 上面兩個也可以組合刪除，d'a 就是刪除刪到 'a 的地方 刪掉他 delm aA delete mark a and A 選取大師 選取技能之排列組合 動作類型： v visual 選取 d delete 剪下 c change 剪下後插入 y yank 複製 範圍： i inner 選取物件條件 a around 包含選取條件 名詞條件： w word s sentence p paragraph t tag (HTML, XML tags) '\u0026quot; 引號 )]}\u0026gt; 括號 viw 選取遊標上的字 i=inner w=word ciw 同上剪下遊標上的字並進入插入模式 vi\u0026quot; 選取 \u0026quot; 中間的字，' 也可以 va\u0026quot; 差別是會包含雙引號 a=around 切分頁(Tab) 囉 vim -p 檔案們，把他們開到新分頁 :e file.txt 在同一個分頁開啟新檔案 :tabe 開新分頁 (可以 :w 存起來) gt 下一個分頁， gT 上一個分頁 :new 在上方產生水平分割 Windows， :vnew 垂直分割 你的 Buffer :ls 4 h \u0026quot;plugin-config.vim\u0026quot; line 3 5 %a \u0026quot;prelude.vim\u0026quot; line 50 6 h \u0026quot;[No Name]\u0026quot; line 1 7 #h \u0026quot;init.vim\u0026quot; line 5 14 h \u0026quot;filetypes.vim\u0026quot; line 0 15 h \u0026quot;clipboard.vim\u0026quot; line 1 16 h \u0026quot;[No Name]\u0026quot; line 0 Press ENTER or type command to continue :ls 查看分頁內的 buffer 們 切換分頁 :b + 數字 可以切換到指定 Buffer，例如 :b4 :b + 部分檔案名 也可以切換，例如 :b init :bn go next buffer :bp go previous buffer :bl go last :bf go first :bd delete buffer 常用指令 想看 key mapping 你是不是設定了很多 key mapping 但忘記了呀？\n:map 或是想指定模式也可以\n:nmap for normal mode mappings :vmap for visual mode mappings :imap for insert mode mappings 輸出出來看的方法\n:redir! \u0026gt; vim_keys.txt :silent verbose map :redir END ref: https://stackoverflow.com/a/15756785\nNerdTree 視窗切換 C_w + [上下左右] 切換到 [上下左右] 的分割視窗 C_w + w 切換到下一個分割視窗 NerdTree 視窗 對檔案 t 開啟新分頁 對檔案 o 開啟新分頁，並跳過去 對資料夾 o 展開 / 縮合資料夾 按下 m 會進入檔案管理模式 再來按 a 可以新增檔案（資料夾的話就在後面加一個 /） Easy Motion 這裡的 \u0026lt;leader\u0026gt;\u0026lt;Plug\u0026gt; 都用 , 來示範，因此指令都是 ,, 開頭\n跳到字元 ,,s search 跳到搜尋此字元的位置 ,,f 從游標往下 search，跳到搜尋此字元的位置 ,,F 從游標往上 search，跳到搜尋此字元的位置 跳到字首 ,,b 從游標往下 search，跳到搜尋此字首的位置 ,,w 從游標往上 search，跳到搜尋此字首的位置 fzf.vim :Files 搜尋檔案名稱 (綁定到 \u0026lt;leader\u0026gt;ff) :Commands 搜尋指令名可能沒什麼用XDD (綁定到 \u0026lt;c-P\u0026gt;) vim-visual-multi c-n 選取遊標上的字 按 n N 選取下/上一個相同的字 q 跳過下一個選擇 Q 刪除目前選擇 3c-n 選取接下來的 3 個 \\\\A 選取文件上全部遊標上的那個字 C-mouseleft 選取點擊字元 C-mouseright 選取點擊字 vim-fugitive 更方便使用 Git 的插件，Github 連結\n用 :G 來呼叫 git 指令，例如說 :G commit -m init commit :Git blame blame 一下都是誰寫了些什麼 :Gvdiff 呼叫出檔案更新差異 (好像也可以解 Confilet) tpope/vim-surround 快速添加引號 選取後 S\u0026quot; ysiw\u0026quot; (yank surround inner word \u0026ldquo;) 移除引號 ds\u0026quot; (delete surround \u0026ldquo;) 更改引號 cs'\u0026quot; (change surround \u0026rsquo; to \u0026ldquo;) 安裝 tpop/vim-repeat 達成用 . 重複操作 Note: 搭配 visual multi 真香 XDD https://youtu.be/wjoSbLGZTao?list=PLBd8JGCAcUAH56L2CYF7SmWJYKwHQYUDI\u0026amp;t=782 tomtom/tcomment_vim \u0026lt;C-/\u0026gt; \u0026lt;C-/\u0026gt; 註解掉或是解開 telescope.nvim Github Link\nRef https://github.com/wsdjeg/vim-galore-zh_cn Cheat Sheet https://vim.rtorr.com/lang/zh_tw\n","id":5,"section":"posts","summary":"我的設定檔在這 新的Neovim 的設定檔，有附上使用說明歡迎給建議或是幫忙 Debug (? 還有一個以前用的 Vim 設定檔，不過沒怎麼更新了 基本操作 移動你的游標 w,","tags":["vim","neovim"],"title":"入坑 Vim 學習使用筆記","uri":"https://blog.10oz.tw/20230103-use-vim/","year":"2023"},{"content":"描述 私有 AWS ECR 登入指令很好找，文件上到處有\n$ aws ecr get-login-password \\ --region us-west-2 | docker login \\ --username AWS \\ --password-stdin \\ 000000000000.dkr.ecr.us-west-2.amazonaws.com 但是你知道嗎？ AWS 的 Public Registry 沒有分區域，所以你必須要指定 --region us-east-1 才可以唷\n$ aws ecr-public get-login-password \\ --region us-east-1 | docker login \\ --username AWS \\ --password-stdin \\ public.ecr.aws 寫錯或是沒寫用到預設的話\n$ aws ecr get-login-password \\ --region us-west-2 | docker -l \u0026quot;debug\u0026quot; login \\ --username AWS \\ --password-stdin \\ public.ecr.aws Error response from daemon: login attempt to https://public.ecr.aws/v2/ failed with status: 400 Bad Request Ref https://stackoverflow.com/a/69274999/6695274\n","id":6,"section":"posts","summary":"描述 私有 AWS ECR 登入指令很好找，文件上到處有 $ aws ecr get-login-password \\ --region us-west-2 | docker login \\ --username AWS \\ --password-stdin \\ 000000000000.dkr.ecr.us-west-2.amazonaws.com 但是你知道嗎？ AWS 的 Public Registry 沒有分區域，所以你必須要指定 --region us-east-1 才可以唷 $ aws","tags":["aws","ecr","docker"],"title":"Hey! 我想登入 AWS ECR","uri":"https://blog.10oz.tw/20221028-logic-public-ecr/","year":"2022"},{"content":"前情提要 這是一台架設在 Kubernetes 上，使用 Postgres Operator 部署的單節點資料庫，SRE 大大發現他的硬碟空間滿了，趕快來看一下 由於硬碟滿了 SQL Query 也下不了，於是先幫他加了 2 GB 的 pv。\n這是他的 log\n2022-01-27 03:09:49,785 INFO: Lock owner: None; I am MY_DB_NAME-0 2022-01-27 03:09:49,786 INFO: starting as a secondary 2022-01-27 03:09:50 UTC [413]: [1-1] 61f20cfe.19d 0 FATAL: could not write lock file \u0026quot;postmaster.pid\u0026quot;: No space left on device 2022-01-27 03:09:50,085 INFO: postmaster pid=413 /var/run/postgresql:5432 - no response 2022-01-27 03:09:50,102 WARNING: Postgresql is not running. 2022-01-27 03:09:50,102 INFO: Lock owner: None; I am MY_DB_NAME-0 2022-01-27 03:09:50,107 INFO: pg_controldata: pg_control version number: 1300 Catalog version number: 202007201 Database system identifier: 7024396656819753043 Database cluster state: in archive recovery pg_control last modified: Thu Jan 27 02:04:18 2022 Latest checkpoint location: 10/C800AA10 Latest checkpoint's REDO location: 10/C800A9D8 Latest checkpoint's REDO WAL file: 0000000900000010000000C8 Latest checkpoint's TimeLineID: 9 Latest checkpoint's PrevTimeLineID: 9 Latest checkpoint's full_page_writes: on Latest checkpoint's NextXID: 0:52538 Latest checkpoint's NextOID: 50198 Latest checkpoint's NextMultiXactId: 1 Latest checkpoint's NextMultiOffset: 0 Latest checkpoint's oldestXID: 479 Latest checkpoint's oldestXID's DB: 1 Latest checkpoint's oldestActiveXID: 52538 Latest checkpoint's oldestMultiXid: 1 Latest checkpoint's oldestMulti's DB: 1 Latest checkpoint's oldestCommitTsXid: 0 Latest checkpoint's newestCommitTsXid: 0 Time of latest checkpoint: Thu Jan 27 00:10:32 2022 Fake LSN counter for unlogged rels: 0/3E8 Minimum recovery ending location: 10/C9000000 Min recovery ending loc's timeline: 9 Backup start location: 0/0 Backup end location: 0/0 End-of-backup record required: no wal_level setting: replica wal_log_hints setting: on max_connections setting: 100 max_worker_processes setting: 8 max_wal_senders setting: 10 max_prepared_xacts setting: 0 max_locks_per_xact setting: 64 track_commit_timestamp setting: off Maximum data alignment: 8 Database block size: 8192 Blocks per segment of large relation: 131072 WAL block size: 8192 Bytes per WAL segment: 16777216 Maximum length of identifiers: 64 Maximum columns in an index: 32 Maximum size of a TOAST chunk: 1996 Size of a large-object chunk: 2048 Date/time type storage: 64-bit integers Float8 argument passing: by value Data page checksum version: 0 Mock authentication nonce: da09cd91aff4fc04822b4475aa0944dee4f3a297badcac611f47ff91071988b9 健康檢查時間 總之先 psql 進去資料庫 Query 一些資訊出來看看吧!\npg_database_size 9009 kB 而已呀少少\nSELECT pg_size_pretty(pg_database_size('YOUR_DB_NAME')); 退出 psql 直接看一下儲存空間，發現是 WAL log 占用掉了資源。\ndu -h | sort -h 回到 psql 再來查看一下 WAL 的相關設定\nSHOW ALL; -- 或是 SELECT * FROM pg_settings WHERE name LIKE '%wal%' 注意在 PostgreSQL 13 將 wal_keep_segments 換成了 wal_keep_size，不過基本上還是類似功能的東西\nwal_keep_size = wal_keep_segments * wal_segment_size (typically 16MB) WAL 的 SIZE 設定看上去沒有甚麼問題，不過另外發現了他的同步機制是開啟的，因此只開了單台的 Postgres 沒辦法同步變更到另外一台 Replicate\n按照 Postgres Operator Issue 這邊寫的，把 archive_mode 關掉吧!!!\n期待有大大幫修這張 Issue，在這之前都要自己記得喔 👍\nRef https://isdaniel.github.io/postgresql-wal-introduce/\nhttps://kknews.cc/zh-tw/code/g4b4nny.html\nhttps://www.slideshare.net/wenchen3/postgre-sql-wal\nhttps://www.postgresql.fastware.com/blog/how-to-solve-the-problem-if-pg_xlog-is-full\nhttps://github.com/zalando/postgres-operator/issues/1664#issuecomment-961761544\n","id":7,"section":"posts","summary":"前情提要 這是一台架設在 Kubernetes 上，使用 Postgres Operator 部署的單節點資料庫，SRE 大大發現他的硬碟空間滿了，趕快來看一下 由於硬碟滿了 SQL Query 也下不了，於是先幫他加了","tags":["kubernetes","postgres"],"title":"筆記 Debug PostgreSQL WAL 滿ㄌ","uri":"https://blog.10oz.tw/20220713-k8s-postgresql-wal-full/","year":"2022"},{"content":"一步一步的開始 安裝 kuberbuilder https://github.com/kubernetes-sigs/kubebuilder/issues/2642 kuberbuilder 在支援 1.18 前的準備\n首先下載 kuberbuilder\ncurl -L -o kubebuilder https://go.kubebuilder.io/dl/latest/$(go env GOOS)/$(go env GOARCH) chmod +x kubebuilder \u0026amp;\u0026amp; mv kubebuilder /usr/local/bin/ 或是你發現 Release 版還沒支援 Go version 1.18，從 GitHub 自己編譯最新版的來用\ngit clone https://github.com/kubernetes-sigs/kubebuilder.git cd kubebuilder make install Note: 後來不用跑 make install 可以用 make deploy 就好，他會做更多的事情。並且我注意到這個版本的 make install 不會幫你取代 Cert manager 的變數，他可以搞砸你的 CRD xDDD\n開新專案囉 mkdir unagi cd unagi kubebuilder init --domain xiao.xiao --repo github.com/xiaoxiaosn/unagi Get controller runtime: $ go get sigs.k8s.io/controller-runtime@v0.12.1 Update dependencies: $ go mod tidy 新增你要的 CRD go code，會問你要不要建 Resource 跟 Controller，我們當然選個 y\nkubebuilder create api --group unagi --version v1 --kind UnagiLive Create Resource [y/n] y Create Controller [y/n] y 把 CRD YAML 建立出來，有修改 CRD 定義的話記得重新跑個\nmake manifests 到 config/crd/bases/unagi.xiao.xiao_unagilives.yaml 可以看到你的 CRD，在 patches 裡面甚至有 conversion webhook 和 Cert Manager CA injection 的範例，這部分晚點玩\n到 config/samples/unagi_v1_unagilive.yaml 可以看到範例 CR\napiVersion: unagi.xiao.xiao/v1 kind: UnagiLive metadata: name: unagilive-sample spec: # TODO(user): Add fields here 準備好後開始安裝 CRD 到 K8s 中，如果發現 Kustomize 太舊了下載不到那可以參考這邊改個數字\nexport KUSTOMIZE_VERSION=4.5.5 # or other version you want make install 你可以在 K8s 中看到剛剛加上去的 CRD\n$ kubectl get crd unagilives.unagi.xiao.xiao NAME CREATED AT unagilives.unagi.xiao.xiao 2022-06-26T15:42:17Z 你還可以部署 CR 上去玩，然後用 kubectl get unagilive 看他\nkubectl apply -f config/samples/unagi_v1_unagilive.yaml 為了將 Controller 放到 K8s 中，我們需要做 docker image\n# make docker-build docker-push IMG=\u0026lt;some-registry\u0026gt;/\u0026lt;project-name\u0026gt;:tag make docker-build docker-push IMG=xiaoxiaosn/unagi:latest 然後部署上去\n# make deploy IMG=\u0026lt;some-registry\u0026gt;/\u0026lt;project-name\u0026gt;:tag make deploy IMG=xiaoxiaosn/unagi:latest 如果你用 kind 也可以提供一個不用 push 的方法直接 load\n# kind load docker-image \u0026lt;your-image-name\u0026gt;:tag --name \u0026lt;your-kind-cluster-name\u0026gt; kind load docker-image xiaoxiaosn/unagi:latest 就長出來啦\n$ kubectl get all -n unagi-system NAME READY STATUS RESTARTS AGE pod/unagi-controller-manager-7c99bd7fb7-9t6gr 2/2 Running 0 114s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/unagi-controller-manager-metrics-service ClusterIP 10.96.251.167 \u0026lt;none\u0026gt; 8443/TCP 114s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/unagi-controller-manager 1/1 1 1 114s NAME DESIRED CURRENT READY AGE replicaset.apps/unagi-controller-manager-7c99bd7fb7 1 1 1 114s 認識專案開始跑 我們確實有了一個架構，再來我們要開始加一些自定義的行為！\n修改 CRD 首先到 api/v1/unagilive_type.go 這邊會定義 UnagiLive 這個 CRD 的 Spec，我們在這邊加個喜歡的欄位\n我們希望我們養的 Unagi 有顏色跟尺寸大小，修改一下\n// UnagiLiveSpec defines the desired state of UnagiLive type UnagiLiveSpec struct { Color string `json:\u0026quot;color,omitempty\u0026quot;` Size string `json:\u0026quot;size,omitempty\u0026quot;` HasHorn bool `json:\u0026quot;hasHorn,omitempty\u0026quot;` } 還希望知道這個 CRD 被 Controller 處理的狀況如何\ntype UnagiLiveStatus struct { Status string `json:\u0026quot;status,omitempty\u0026quot;` // +optional ReconciledTime *metav1.Time `json:\u0026quot;reconciledTime,omitempty\u0026quot;` } 再加個 additionalPrinterColumns 因為想用 kubectl 看到更多資訊～ Status 多了個 priority 大於 1 的，就要用 -o wide 才給看\n// UnagiLive is the Schema for the unagilives API // +kubebuilder:printcolumn:name=\u0026quot;Status\u0026quot;,type=string,JSONPath=`.status.status`,description=\u0026quot;Unagi Status\u0026quot; // +kubebuilder:printcolumn:name=\u0026quot;Color\u0026quot;,type=string,JSONPath=`.spec.color`,description=\u0026quot;Unagi Color\u0026quot;,priority=1 type UnagiLive struct { metav1.TypeMeta `json:\u0026quot;,inline\u0026quot;` metav1.ObjectMeta `json:\u0026quot;metadata,omitempty\u0026quot;` Spec UnagiLiveSpec `json:\u0026quot;spec,omitempty\u0026quot;` Status UnagiLiveStatus `json:\u0026quot;status,omitempty\u0026quot;` } 修改 Controller 來到 controllers/unagilive_controller.go\n我們要把收到的 Unagi 給設定 Status，另外也增加一些 log 方便觀察\nfunc (r *UnagiLiveReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) { log := log.FromContext(ctx) log.Info(fmt.Sprintf(\u0026quot;Request: %+v\\n-----\\n\u0026quot;, req)) // Load the named UnagiLive object var unagiLive unagiv1.UnagiLive if err := r.Get(ctx, req.NamespacedName, \u0026amp;unagiLive); err != nil { log.Error(err, \u0026quot;unable to fetch unagiLive\u0026quot;) // we'll ignore not-found errors, since they can't be fixed by an immediate // requeue (we'll need to wait for a new notification), and we can get them // on deleted requests. return ctrl.Result{}, client.IgnoreNotFound(err) } log.Info(fmt.Sprintf(\u0026quot;Request unagiLive: %#v\\n-----\\n\u0026quot;, unagiLive)) unagiLive.Status.Status = \u0026quot;Reconciled\u0026quot; unagiLive.Status.ReconciledTime = \u0026amp;metav1.Time{Time: time.Now()} if err := r.Status().Update(ctx, \u0026amp;unagiLive); err != nil { log.Error(err, \u0026quot;unable to update unagiLive status\u0026quot;) return ctrl.Result{}, err } log.Info(\u0026quot;----- END -----\\n\\n\u0026quot;) return ctrl.Result{}, nil } 重新部署 CRD 和 Controller\nmake manifest make docker-build docker-push IMG=xiaoxiaosn/unagi:latest kubectl rollout restart deploy -n unagi-system 等他跑完後可以看到我們新的 Controller 設定好 Status 了～\nkubectl get unagilive -oyaml apiVersion: v1 items: - apiVersion: unagi.xiao.xiao/v1 kind: UnagiLive metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {\u0026quot;apiVersion\u0026quot;:\u0026quot;unagi.xiao.xiao/v1\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;UnagiLive\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;name\u0026quot;:\u0026quot;unagilive-sample\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;unagi-system\u0026quot;},\u0026quot;spec\u0026quot;:null} creationTimestamp: \u0026quot;2022-06-26T16:20:15Z\u0026quot; generation: 3 name: unagilive-sample namespace: unagi-system resourceVersion: \u0026quot;3228189\u0026quot; uid: 0dfaee8d-4396-42e5-9df2-112c1c330f86 spec: color: meow status: reconciledTime: \u0026quot;2022-06-26T19:34:27Z\u0026quot; status: Reconciled kind: List metadata: resourceVersion: \u0026quot;\u0026quot; selfLink: \u0026quot;\u0026quot; 召喚 Admission webhook 可以從 kuberbuilder create webhook --help 看到用法（defaulting webhook 他就是 mutating webhook）\n--defaulting if set, scaffold the defaulting webhook --programmatic-validation if set, scaffold the validating webhook kubebuilder create webhook --group unagi --version v1 --kind UnagiLive --defaulting --programmatic-validation 我們建立好了兩之 Admission webhooks (mutating and validation)，可以到 api/v1/unagilive_webhook.go 去看一下主要的邏輯\n我們修改 Mutating webhook 的 Default function，讓我們的 resource 進來時，會先照我們的邏輯做一次改變\n// Default implements webhook.Defaulter so a webhook will be registered for the type func (r *UnagiLive) Default() { unagilivelog.Info(\u0026quot;default\u0026quot;, \u0026quot;name\u0026quot;, r.Name) // 沒有填寫的話預設是 `m` 尺寸 if r.Spec.Size == \u0026quot;\u0026quot; { r.Spec.Size = \u0026quot;m\u0026quot; } // 沒有填寫的話預設是黃色 if r.Spec.Color == \u0026quot;\u0026quot; { r.Spec.Color = \u0026quot;yellow\u0026quot; } } validating 的 Admission webhook 則有 Create, Update and Delete 三種，分別對應到資源的新增、修改、刪除，檢查新的 resource 以及變化是否符合預期～\n例如我們可以限制尺寸是不可修改的！\n// ValidateUpdate implements webhook.Validator so a webhook will be registered for the type func (r *UnagiLive) ValidateUpdate(old runtime.Object) error { unagilivelog.Info(\u0026quot;validate update\u0026quot;, \u0026quot;name\u0026quot;, r.Name) oldSize := old.(*UnagiLive).Spec.Size newSize := r.Spec.Size if newSize != oldSize { return fmt.Errorf(\u0026quot;cannot change size after creation. try from `%s` update to `%s`\u0026quot;, oldSize, newSize) } return nil } 再來來到 config/webhook/manifests.yaml 看一下 resource 的定義，包含了說要監聽哪一些 resource 的哪一些行為，然後要掛哪裡的 webhook\n--- apiVersion: admissionregistration.k8s.io/v1 kind: MutatingWebhookConfiguration metadata: creationTimestamp: null name: mutating-webhook-configuration webhooks: - admissionReviewVersions: - v1 clientConfig: service: name: webhook-service namespace: system path: /mutate-unagi-xiao-xiao-v1-unagilive failurePolicy: Fail name: munagilive.kb.io rules: - apiGroups: - unagi.xiao.xiao apiVersions: - v1 operations: - CREATE - UPDATE resources: - unagilives sideEffects: None --- apiVersion: admissionregistration.k8s.io/v1 kind: ValidatingWebhookConfiguration metadata: creationTimestamp: null name: validating-webhook-configuration webhooks: - admissionReviewVersions: - v1 clientConfig: service: name: webhook-service namespace: system path: /validate-unagi-xiao-xiao-v1-unagilive failurePolicy: Fail name: vunagilive.kb.io rules: - apiGroups: - unagi.xiao.xiao apiVersions: - v1 operations: - CREATE - UPDATE resources: - unagilives sideEffects: None 準備部署上去玩玩 記得確保你有 Cert Manager 喔，我們會用到它的 webhook 來幫忙你注入 CA Bundle\n到 config/default/kustomization.yaml 確認一下，這些選項要開 (主要都是 Cert Manager \u0026amp;\u0026amp; Webhook 的部分)\nbases: # [WEBHOOK] To enable webhook, uncomment all the sections with [WEBHOOK] prefix including the one in # crd/kustomization.yaml - ../webhook # [CERTMANAGER] To enable cert-manager, uncomment all sections with 'CERTMANAGER'. 'WEBHOOK' components are required. - ../certmanager patchesStrategicMerge: # [WEBHOOK] To enable webhook, uncomment all the sections with [WEBHOOK] prefix including the one in # crd/kustomization.yaml - manager_webhook_patch.yaml # [CERTMANAGER] To enable cert-manager, uncomment all sections with 'CERTMANAGER'. # Uncomment 'CERTMANAGER' sections in crd/kustomization.yaml to enable the CA injection in the admission webhooks. # 'CERTMANAGER' needs to be enabled to use ca injection - webhookcainjection_patch.yaml # the following config is for teaching kustomize how to do var substitution vars: # [CERTMANAGER] To enable cert-manager, uncomment all sections with 'CERTMANAGER' prefix. - name: CERTIFICATE_NAMESPACE # namespace of the certificate CR objref: kind: Certificate group: cert-manager.io version: v1 name: serving-cert # this name should match the one in certificate.yaml fieldref: fieldpath: metadata.namespace - name: CERTIFICATE_NAME objref: kind: Certificate group: cert-manager.io version: v1 name: serving-cert # this name should match the one in certificate.yaml - name: SERVICE_NAMESPACE # namespace of the service objref: kind: Service version: v1 name: webhook-service fieldref: fieldpath: metadata.namespace - name: SERVICE_NAME objref: kind: Service version: v1 name: webhook-service 還有 config/crd/kustomization.yaml 的這些\npatchesStrategicMerge: # [WEBHOOK] To enable webhook, uncomment all the sections with [WEBHOOK] prefix. # patches here are for enabling the conversion webhook for each CRD - patches/webhook_in_unagilives.yaml #+kubebuilder:scaffold:crdkustomizewebhookpatch # [CERTMANAGER] To enable cert-manager, uncomment all the sections with [CERTMANAGER] prefix. # patches here are for enabling the CA injection for each CRD - patches/cainjection_in_unagilives.yaml #+kubebuilder:scaffold:crdkustomizecainjectionpatch 改好 kustomizate 後，來部署基本跟剛剛一樣\n# make docker-build docker-push IMG=\u0026lt;some-registry\u0026gt;/\u0026lt;project-name\u0026gt;:tag make docker-build docker-push IMG=xiaoxiaosn/unagi:latest # make deploy IMG=\u0026lt;some-registry\u0026gt;/\u0026lt;project-name\u0026gt;:tag make deploy IMG=xiaoxiaosn/unagi:latest 看一下成果，多了一個 service 從同一個 controller-manager 導出到 admission webhook 預設的 443 port\n$ kubectl get po,svc NAME READY STATUS RESTARTS AGE pod/unagi-controller-manager-6c779679c6-w266v 2/2 Running 0 98s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/unagi-controller-manager-metrics-service ClusterIP 10.96.251.167 \u0026lt;none\u0026gt; 8443/TCP 3d23h service/unagi-webhook-service ClusterIP 10.96.96.235 \u0026lt;none\u0026gt; 443/TCP 98s 成果驗收 來部署這個，預期可以看到 mutating webhook 給我們上 default 數值\napiVersion: unagi.xiao.xiao/v1 kind: UnagiLive metadata: name: try-admission-webhook namespace: unagi-system spec: {} 使用 kubectl get unagilive try-admission-webhook -oyaml 拿回來看，會發現 spec 被貼上預設值啦～ 且原本在被修改前的數值也被更新到 annotations.kubectl.kubernetes.io/last-applied-configuration 裡面\napiVersion: unagi.xiao.xiao/v1 kind: UnagiLive metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {\u0026quot;apiVersion\u0026quot;:\u0026quot;unagi.xiao.xiao/v1\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;UnagiLive\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;name\u0026quot;:\u0026quot;try-admission-webhook\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;unagi-system\u0026quot;},\u0026quot;spec\u0026quot;:{}} creationTimestamp: \u0026quot;2022-06-30T15:46:03Z\u0026quot; generation: 1 name: try-admission-webhook namespace: unagi-system resourceVersion: \u0026quot;3718189\u0026quot; uid: 77c4d9c1-ef32-49d9-b106-ebdf8889baee spec: color: red size: m hasHorn: true status: reconciledTime: \u0026quot;2022-06-30T15:46:03Z\u0026quot; status: Reconciled 再來看舊的 resource，由於他早就在 Kubernetes 內了，因此沒有經過 webhook，還是保持原本的模樣\n先把它拿出來看 kubectl get unagilive unagilive-sample -oyaml，這是一個沒有填寫 size 的 CR，後面\napiVersion: unagi.xiao.xiao/v1 kind: UnagiLive metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {\u0026quot;apiVersion\u0026quot;:\u0026quot;unagi.xiao.xiao/v1\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;UnagiLive\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;name\u0026quot;:\u0026quot;unagilive-sample\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;unagi-system\u0026quot;},\u0026quot;spec\u0026quot;:null} creationTimestamp: \u0026quot;2022-06-26T16:20:15Z\u0026quot; generation: 3 name: unagilive-sample namespace: unagi-system resourceVersion: \u0026quot;3717289\u0026quot; uid: \u0026quot;0dfaee8d-4396-42e5-9df2-112c1c330f86\u0026quot; spec: color: meow status: reconciledTime: \u0026quot;2022-06-30T15:39:37Z\u0026quot; status: Reconciled 然後改他 kubectl edit unagilive unagilive-sample，結果發現無法修改！！\nerror: unagilives.unagi.xiao.xiao \u0026quot;unagilive-sample\u0026quot; could not be patched: admission webhook \u0026quot;vunagilive.kb.io\u0026quot; denied the request: cannot change size after creation. try from `` update to `m` 原來是我們剛剛的 mutating webhook 的預設值跟 validation webhook 的不可變更檢查衝突了呀\n暫時把 validating webhook 給刪了 (? webhook 邏輯應該修改一下，特例允許從空值更改成預設值 m 我們可能需要迭代新版本的 CRD Multiple versions CRD 使用和產生第一個 v1 時相同的方式來產生 v2，這次 Resource 選 y 而第二個選項的 Controller 因為已經有了所以要選 n，不然會失敗！\nkubebuilder create api --group unagi --version v2 --kind UnagiLive Create Resource [y/n] y Create Controller [y/n] n 接下來比較麻煩，有不少地方要留意\n首先我們要為我們新版本的 UnagiLive 定義結構形狀，移動到api/v2/unagilive_type.go，參考 v1 更改預設產生的 Spec, Status，這次我增加了一個 Speed 欄位，我希望 Unagi 有移動速度可以設定～\n// UnagiLiveSpec defines the desired state of UnagiLive type UnagiLiveSpec struct { Color string `json:\u0026quot;color,omitempty\u0026quot;` Size string `json:\u0026quot;size,omitempty\u0026quot;` HasHorn bool `json:\u0026quot;hasHorn,omitempty\u0026quot;` Speed int `json:\u0026quot;speed\u0026quot;` } // UnagiLiveStatus defines the observed state of UnagiLive type UnagiLiveStatus struct { Status string `json:\u0026quot;status,omitempty\u0026quot;` // +optional ReconciledTime *metav1.Time `json:\u0026quot;reconciledTime,omitempty\u0026quot;` } 因為我們的 CRD 有了多版本，我們要指定在 etcd 中的實際儲存版本，我們在api/v2/unagilive_types.go 加上這行（或是你想加在 v1 也可以的）\n//+kubebuilder:storageversion 更多 kubebuilder 的選項可以參考文件\n這樣子基本的定義就完成了，不過版本發生改變時要怎麼同時兼容新版和舊版？ 所以需要有人來負責做這個不同版本之間的轉換器，這個角色就是 conversion webhook\n然而我們馬上就會遇到一個問題：如果我們有 $n$ 個 versions，兼容所有轉換是不是表示我們就要有 $n* (n-1)$ 這麼多個呢？\n在 kubebuilder 的概念中多準備了一個 Hub 的角色，所有的轉換都先經過 Hub 在轉換成其他的版本 例如說想要從 v2 轉成 v3，而目前的儲存版本是 v1 的時候會像是 v2 -\u0026gt; hub(v1) -\u0026gt; v3 理解完後我們來實作，使用 kubebuilder 建立 storaged version 是 v1 的 webhook 服務 Code\nkubebuilder create webhook --group unagi --version v1 --kind UnagiLive --conversion 來開一個 api/v1/unagilive_convetion.go 我們要在這邊宣告他是 Hub 或是一個 Convertible，在這裡因為 v1 是 storaged version 所以給他個 Hub\npackage v1 /* Implementing the hub method is pretty easy -- we just have to add an empty method called `Hub()` to serve as a [marker](https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/conversion?tab=doc#Hub). We could also just put this inline in our `cronjob_types.go` file. */ // Hub marks this type as a conversion hub. func (*UnagiLive) Hub() {} 再來到 api/v2/unagilive_convetion.go 幫她實作從 Hub 過來的邏輯，他是一個 Convertible\npackage v2 /* For imports, we'll need the controller-runtime [`conversion`](https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/conversion?tab=doc) package, plus the API version for our hub type (v1), and finally some of the standard packages. */ import ( \u0026quot;sigs.k8s.io/controller-runtime/pkg/conversion\u0026quot; v1 \u0026quot;github.com/xiaoxiaosn/unagi/api/v1\u0026quot; ) // +kubebuilder:docs-gen:collapse=Imports /* Our \u0026quot;spoke\u0026quot; versions need to implement the [`Convertible`](https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/conversion?tab=doc#Convertible) interface. Namely, they'll need `ConvertTo` and `ConvertFrom` methods to convert to/from the hub version. */ /* ConvertTo is expected to modify its argument to contain the converted object. Most of the conversion is straightforward copying, except for converting our changed field. */ // ConvertTo converts this UnagiLive to the Hub version (v1). func (src *UnagiLive) ConvertTo(dstRaw conversion.Hub) error { dst := dstRaw.(*v1.UnagiLive) // Spec dst.Spec.Color = src.Spec.Color dst.Spec.Size = src.Spec.Size dst.Spec.HasHorn = src.Spec.HasHorn // Status dst.Status.Status = src.Status.Status dst.Status.ReconciledTime = src.Status.ReconciledTime // +kubebuilder:docs-gen:collapse=rote conversion return nil } /* ConvertFrom is expected to modify its receiver to contain the converted object. Most of the conversion is straightforward copying, except for converting our changed field. */ // ConvertFrom converts from the Hub version (v1) to this version. func (dst *UnagiLive) ConvertFrom(srcRaw conversion.Hub) error { src := srcRaw.(*v1.UnagiLive) // Spec dst.Spec.Color = src.Spec.Color dst.Spec.Size = src.Spec.Size dst.Spec.HasHorn = src.Spec.HasHorn if src.Spec.Color == \u0026quot;red\u0026quot; \u0026amp;\u0026amp; src.Spec.HasHorn { dst.Spec.Speed = 3 } else { dst.Spec.Speed = 1 } // Status dst.Status.Status = src.Status.Status dst.Status.ReconciledTime = src.Status.ReconciledTime // +kubebuilder:docs-gen:collapse=rote conversion return nil } 在上述的轉換邏輯中，因為 v2 多了一個 Speed 欄位，而 v1 到 v2 又沒有這個欄位，因此給他一個邏輯，當你是紅色有角時，你的速度就是 3 倍。\n準備部署 來到 config 這邊把註解掉的部分打開\n到 config/crd/kustomization.yaml 打開 patches/webhook_in_\u0026lt;kind\u0026gt;.yaml 和 patches/cainjection_in_\u0026lt;kind\u0026gt;.yaml，你也可能已經在 Admission webhook 中開過了 到 config/default/kustomization.yaml 打開 bases 底下的 ../certmanager 和 ../webhook 打開 patchesStrategicMerge 底下的 manager_webhook_patch.yaml 和 webhookcainjection_patch.yaml 打開 CERTMANAGER 下的所有參數 安裝下去\nmake docker-build docker-push IMG=xiaoxiaosn/unagi:latest make deploy IMG=xiaoxiaosn/unagi:latest # kubectl rollout restart deployment.apps/unagi-controller-manager 見證更改 首先直接 get 會發現他給的 v2 的版本，kubectl 會自動去抓優先級最高的版本，\nkubectl get unagilive kubectl get UnagiLive.v1.unagi.xiao.xiao 如預期般拿到轉換過後的版本 ：）\nRef https://book.kubebuilder.io/quick-start.html https://mp.weixin.qq.com/s/Y0GwLgz9o2HONkl4FJdlVQ https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum\u0026amp;album_id=1851829124558848001\nTutorial https://github.com/kubernetes-sigs/kubebuilder/tree/master/docs/book/src\nhttps://www.cnblogs.com/charlieroro/p/15960829.html\n","id":8,"section":"posts","summary":"一步一步的開始 安裝 kuberbuilder https://github.com/kubernetes-sigs/kubebuilder/issues/2642 kuberbuilder 在支援 1.18 前的準備 首先下載 kuberbuilder curl -L -o kubebuilder https://go.kubebuilder.io/dl/latest/$(go env GOOS)/$(go env GOARCH) chmod +x kubebuilder \u0026amp;\u0026amp; mv kubebuilder /usr/local/bin/ 或是你發現 Release 版還沒支援 Go version 1.18，從 GitHub 自己編譯最新版的來","tags":["kubernetes","crd","operator"],"title":"kubebuilder 旅程","uri":"https://blog.10oz.tw/20220723-kubebuilder/","year":"2022"},{"content":"版本優先級 在 K8s 裡面有 preferred version，會選優先值最高的來做為預設值\n規則 \u0026quot;^v([\\\\d]+)(?:(alpha|beta)([\\\\d]+))?$\u0026quot;\nv{主版本}alpha|beta{副版本}\n只有 v 開頭的穩定版(GA)最先優先，主要版本大的優先度最高。 再來是 beta 和 alpha 第三個比較 beta alpha 下的副版本 最後其他的 case 就是按照字母排序 strings.Compare (lexicographically)\n參考這個範例可以更容易理解\n- v10 // GA(General availability) 10 - v2 // GA 2 - v1 // GA 1 - v11beta2 // GA 11 + beta 2 - v10beta3 // GA 10 + beta 3 - v3beta1 // GA 3 + beta 1 - v12alpha1 // GA 12 + alpha 1 - v11alpha2 // GA 11 + alpha 2 - foo1 // 用字典順序排 - foo10 // 用字典順序排 規則 Code https://github.com/kubernetes/kubernetes/blob/v1.24.2/staging/src/k8s.io/apimachinery/pkg/version/helpers.go#L34\nAPIGroup version 我們有一個 group 叫做 group.name，可以看到他會優先採用 v2\nkc proxy \u0026amp; curl localhost:8001/apis/group.name { \u0026quot;kind\u0026quot;: \u0026quot;APIGroup\u0026quot;, \u0026quot;apiVersion\u0026quot;: \u0026quot;v1\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;group.name\u0026quot;, \u0026quot;versions\u0026quot;: [ { \u0026quot;groupVersion\u0026quot;: \u0026quot;group.name/v2\u0026quot;, \u0026quot;version\u0026quot;: \u0026quot;v2\u0026quot; }, { \u0026quot;groupVersion\u0026quot;: \u0026quot;group.name/v1\u0026quot;, \u0026quot;version\u0026quot;: \u0026quot;v1\u0026quot; } ], \u0026quot;preferredVersion\u0026quot;: { \u0026quot;groupVersion\u0026quot;: \u0026quot;group.name/v2\u0026quot;, \u0026quot;version\u0026quot;: \u0026quot;v2\u0026quot; } } 會直接影響到 kubectl 的結果，直接 get 會拿到 v2 我們的 group.name 底下有 kind Cat\n$ kc get cats my-cat -oyaml apiVersion: group.name/v2 kind: Cat metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {\u0026quot;apiVersion\u0026quot;:\u0026quot;group.name/v1\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;Cat\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;name\u0026quot;:\u0026quot;my-cat\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;default\u0026quot;},\u0026quot;spec\u0026quot;:{\u0026quot;age\u0026quot;:18,\u0026quot;color\u0026quot;:\u0026quot;#009920\u0026quot;}} creationTimestamp: \u0026quot;2022-07-11T17:35:17Z\u0026quot; generation: 1 name: my-cat namespace: default resourceVersion: \u0026quot;5111716\u0026quot; uid: 388993d7-2075-406d-9668-4baec92d1562 spec: color: '#009920' 不過我們也可以指定 kind.version.group 去拿指定版本的資源\n$ kc get cats.v1.group.name my-cat -oyaml apiVersion: group.name/v1 kind: Cat metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {\u0026quot;apiVersion\u0026quot;:\u0026quot;group.name/v1\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;Cat\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;name\u0026quot;:\u0026quot;my-cat\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;default\u0026quot;},\u0026quot;spec\u0026quot;:{\u0026quot;age\u0026quot;:18,\u0026quot;color\u0026quot;:\u0026quot;#009920\u0026quot;}} creationTimestamp: \u0026quot;2022-07-11T17:35:17Z\u0026quot; generation: 1 name: my-cat namespace: default resourceVersion: \u0026quot;5111716\u0026quot; uid: 388993d7-2075-406d-9668-4baec92d1562 spec: age: 18 color: '#009920' 另外，kubectl 有 cache 我們也可以去欺騙他（？\nvim ~/.kube/cache/discovery/127.0.0.1_58359/servergroups.json { \u0026quot;name\u0026quot;: \u0026quot;group.name\u0026quot;, \u0026quot;versions\u0026quot;: [ { \u0026quot;groupVersion\u0026quot;: \u0026quot;group.name/v2\u0026quot;, \u0026quot;version\u0026quot;: \u0026quot;v2\u0026quot; }, { \u0026quot;groupVersion\u0026quot;: \u0026quot;group.name/v1\u0026quot;, \u0026quot;version\u0026quot;: \u0026quot;v1\u0026quot; } ], \u0026quot;preferredVersion\u0026quot;: { - \u0026quot;groupVersion\u0026quot;: \u0026quot;group.name/v2\u0026quot;, - \u0026quot;version\u0026quot;: \u0026quot;v2\u0026quot; + \u0026quot;groupVersion\u0026quot;: \u0026quot;group.name/v1\u0026quot;, + \u0026quot;version\u0026quot;: \u0026quot;v1\u0026quot; } }, 然後再去 kubectl get 不指定版本\nkc get cats my-cat -oyaml apiVersion: group.name/v1 kind: Cat metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {\u0026quot;apiVersion\u0026quot;:\u0026quot;group.name/v1\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;Cat\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;name\u0026quot;:\u0026quot;my-cat\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;default\u0026quot;},\u0026quot;spec\u0026quot;:{\u0026quot;age\u0026quot;:18,\u0026quot;color\u0026quot;:\u0026quot;#009920\u0026quot;}} creationTimestamp: \u0026quot;2022-07-11T17:35:17Z\u0026quot; generation: 1 name: my-cat namespace: default resourceVersion: \u0026quot;5111716\u0026quot; uid: 388993d7-2075-406d-9668-4baec92d1562 spec: age: 18 color: '#009920' 看一眼 etcd 來證明 sudo apt update sudo apt install etcd-client alias ec='ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key' ec get / --prefix --keys-only etcd 的 key 規則類似 /registry/{group}/{kind}/{namespace}/{name}\n# 用 json 格式拿出來看，發現是 Base64 $ ec get /registry/unagi.xiao.xiao/unagilives/unagi-system/unagilive-sample -wjson | jq . # 解開來看到原味內容 $ ec get /registry/unagi.xiao.xiao/unagilives/unagi-system/unagilive-sample -wjson | jq -r .kvs[0].value | base64 -d | jq '.metadata.name, .spec, .status' \u0026quot;unagilive-sample\u0026quot; { \u0026quot;color\u0026quot;: \u0026quot;meow\u0026quot; } { \u0026quot;reconciledTime\u0026quot;: \u0026quot;2022-07-07T09:14:56Z\u0026quot;, \u0026quot;status\u0026quot;: \u0026quot;Reconciled\u0026quot; } Ref https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/#version-priority\n","id":9,"section":"posts","summary":"版本優先級 在 K8s 裡面有 preferred version，會選優先值最高的來做為預設值 規則 \u0026quot;^v([\\\\d]+)(?:(alpha|beta)([\\\\d]+))?$\u0026quot; v{主版本}alpha|beta{副版本} 只有 v 開頭的穩定版(GA)","tags":["kubernetes","crd"],"title":"CRD Version Priority","uri":"https://blog.10oz.tw/20220713-crd-version-priority/","year":"2022"},{"content":"介紹 困擾許久終於在這裡找到解法\nInstall yarn’s IDE SDK for VSCode (the dlx command runs yarn in a separate environment, distinct from the workspace)\nyarn dlx @yarnpkg/sdks vscode Ref https://community.grafana.com/t/cannot-find-modules-or-corresponding-type-declarations-after-fresh-install/56498\n","id":10,"section":"posts","summary":"介紹 困擾許久終於在這裡找到解法 Install yarn’s IDE SDK for VSCode (the dlx command runs yarn in a separate environment, distinct from the workspace) yarn dlx @yarnpkg/sdks vscode Ref https://community.grafana.com/t/cannot-find-modules-or-corresponding-type-declarations-after-fresh-install/56498","tags":["typescript","vscode"],"title":"TypeScript workspace Cannot find module or its corresponding type declarations.ts(2307)","uri":"https://blog.10oz.tw/20220628-typescript-2307/","year":"2022"},{"content":"Introduction (Agenda) Hi 大家好我是 XiaoXiao，現職於 FST Network 擔任軟體工程師 這次主要是要分享 Kubernetes 如何在的自定義擴展定義的 CRD 中做到同時支援多個版本， 這場不會講得太深入主要會關注在使用 Conversion webhook 的經驗和一些容易忽略掉的小地方\n一、使用動機 (Motivation) 在這裡會先間單說明為什麼我為什麼會開始研究 conversion webhook，以及在什麼情況下可以使用 conversion webhook 定義一個 Proxy 的 CRD 作為範例，能在有實際案例的幫助下更好理解文章 二、快速認識 CRD (Get to know the CRD quickly) 首先會介紹如何在 Kubernetes 中定義 CRD 並且設定自己的後端來處理 CR 的變化 (Controller \u0026amp; Operator Pattern) 三、多版本的 CRD 和 Conversion webhook (Multiple versions CRD and conversion webhook) Kubernetes 中的版本關係 同時配置多個版本的資源更新時會發生什麼事？ 介紹 CRD 的轉換策略選擇 於是會加入 Conversion webhook 以及如何配置 Conversion webhook 實際遇到的問題以及建議方式 以 annotations 儲存消失的欄位 欄位更新時 ConversionReview objects 不會帶完整的 resource 進來（特別是非 Golang 使用者需要注意） 四、觀察實際案例 (Case demo) https://github.com/XiaoXiaoSN/conversion-webhook-example\n五、補充篇：與 Admission Webhook 一起玩耍 Admission webhook 也是一個經常被提及的 Resource，因此也看一下 CRD conversion webhook 與 Admission webhook 之間的工作流程 使用動機 (Motivation) 首先，看一下什麼時候會需要使用到 CRD 的 Conversion webhook\n穩定的推進版本 (v1alpha1, v1)，同時向下相容 支援新的欄位，或是將舊欄位改名、改結構 同一個 Cluster 下，不同的 Namespace 同時間支援著不同版本的 Controller 第三項就是我們在開發時實際遇到的困難！\n在我們的開發環境中同時存在有開發環境、串接環境、測試環境三套完整的系統各自在三個不同的 namespace 下，也就同時有三組 Operator 管理著各自 namespace 下的 CRDs\n然而，CRD 在 Kubernetes Cluster 下是共用的，當開發環境發生更新時，不可避免的也會影響到其他人在使用的穩定環境，因此更好的做法是在推出新的 CRD 版本且同時支援舊的版本！\n簡介一個 Demo 案例 我們建立一個 Proxy 的 CRD 作為範例，並用這個範例帶入後面的介紹\n目標透過這個 CRD 產生一個能夠透過 IP 阻擋使用者 HTTP 請求的 Proxy，通過 Proxy 的檢查能看到後面的網頁，沒有通過則會得到 403 的錯誤訊息\nAbout Kubernetes CRD CRD 的全名是 Custom Resource Definition，他本身也是一個 Kubernetes 的 Resource\n在 K8s 中有許多 built-in 的資源、API 定義，CRD 提供使用者編寫自己的定義來擴展 Kubernetes 的 Declarative API (宣告式 API)。 CRD 在整個 Kubernetes 生態中被非常廣泛的使用！\nDeclarative API (宣告式 API)：\nAPI 宣告他想要的狀態，而不是直接要求實時狀態 API represents a desired state, not an exact state 通常是 CRUD 風格就已經足夠 CRD 是定義，而依照 CRD 規格定義產生的資源稱為 CR\n官方 CRD 定義文件\nCRD 編寫格式 在定義好 CRD 之後，使用者僅需要編寫 YAML，就能以宣告式的方式定義服務的模樣 而此後 CR 任務的排程與資源的調度都能藉由 K8s 來幫你完成\n文件上額外規定的 4 個規則，包含保留字或是 properties 擺放方式\n實際上我們可以透過 CRD 提供的 openAPIV3Schema 欄位定義這個 Resource 的欄位，他提供了更嚴格的 OpenAPI V3 Schema 寫法，並且加上了一些 x-kubernetes- 開頭的擴充功能\n例如說： x-kubernetes-int-or-string 能同時支援數字和字串，這樣你就能輕鬆辦到 cpu: 5 or cpu: \u0026quot;5000m\u0026quot; 了！\n來個範例\napiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: name: proxies.example.group spec: group: example.group names: kind: Proxy listKind: ProxyList plural: proxies singular: proxy scope: Namespaced versions: - name: v1 schema: openAPIV3Schema: properties: apiVersion: type: string kind: type: string metadata: type: object spec: description: ProxySpec defines the desired state of Proxy properties: CIDR: type: string upstream: type: string type: object status: description: ProxyStatus defines the observed state of Proxy type: object type: object served: true storage: true 先來認識一下 CRD 在 Kubernetes 的行為 瞧瞧你的 CRD\nkubectl api-resources # 瞧瞧有什麼欄位可以用 kubectl explain proxy --recursive=true # 也可以指定版本 kubectl explain proxy --api-version='example.group/v3' --recursive=true # 瞧瞧我們的的新版本 :) kubectl api-versions # 或是 `kubectl proxy` 然後直接使用 RESTful API curl 127.0.0.1:8001 # 或是 `/apis/{group}`, `/apis/{group}/{version}` curl 127.0.0.1:8001/apis/example.group curl 127.0.0.1:8001/apis/example.group/v1 Custom Controller 我們首先可以先了解一下 Kubernetes Controller！\nController 的工作是負責將指定的資源製造成和宣告的一樣，這個動作稱為 Reconcile (協調、調和？)\n我們以新增一筆 ReplicaSet 來看，\n(透過 kubectl) 發送新增 Request 給 kube-apiserver kube-apiserver 驗證使用者的權限、欄位的正確性 kube-apiserver 在 etcd 中存入 ReplicaSet record Controller watch kube-apiserver 發現 etcd 的變化，並去取得完整的 ReplicaSet Controller 檢查 Cluster 內的狀況，確任 current state 是否和 desired state 相同 Controller 確保 Cluster 內的 pods, rs 等狀況和宣告的相同 （就是 Reconcile） 6.1 如果相同，Reconcile 完成，等待下一筆變更 6.2 不同的話，Reconcile 將狀態設為 requeue，過幾秒再來重新 Reconcile 一次 Data Flow 官方範例 kubernetes/sample-controller 中的圖 https://github.com/kubernetes/sample-controller/blob/master/docs/controller-client-go.md From https://lihaoquan.me/posts/k8s-crd-develop/ 介紹 CRD Controller Difference between Operator Pattern 本質上 Operator 就是 Custom Controller。\nController 在 Kubernetes 中的核心元件，在 Kubernetes 中內建的 Resources 也是經過 Controller 來達到 Desired state 的。\n因此可以說 Operator 是 CRD + Controller 以區別 Kubernetes built-in 的 Controller。\nConversion Webhook 一起看完前置的一些知識，再來可以來看看 Conversion webhook\nWhat is it 瞧瞧註解\na Webhook strategy instruct API server to call an external webhook for any conversion between custom resources.\nWith CRDs, however, each Kind will correspond to a single resource. \u0026ndash; kubebuilder\nStoraged version and Served Version\n誒嘿～！ kubectl 會去抓你目前存的最高的版本當作目標版本 (要部署過一次是哪招？) 不過我們還是可以在 annotations 上看見他實際的型狀 kubectl.kubernetes.io/last-applied-configuration\n儲存進 etcd 之前會先經過轉換，實際在是以 etcd 的形狀存在，因此雖然創建 v1 的時候有 age 欄位，但讀取出來時不會有\n# 每个 version 可以通过 served 标志启用或禁止 served: true # 有且只能有一个 version 必须被标记为存储版本 storage: true # 此属性标明此定制资源的 v1alpha1 版本已被弃用。 # 发给此版本的 API 请求会在服务器响应中收到警告消息头。 deprecated: true # 此属性设置用来覆盖返回给发送 v1alpha1 API 请求的客户端的默认警告信息。 deprecationWarning: \u0026quot;example.com/v1alpha1 CronTab is deprecated; see http://example.com/v1alpha1-v1 for instructions to migrate to example.com/v1 CronTab\u0026quot; Kubernetes functions by reconciling desired state (Spec) with actual cluster state (other objects’ Status) and external state, and then recording what it observed (Status). \u0026ndash; kubebuilder\n為什麼需要和什麼時候用 你的服務足夠穩定想要推進版本 (v1, v1alpha1)，同時間兩種我都要 想支援的新的欄位 不想破壞原本使用者的體驗，想要順暢的升級 你的同一個 Cluster 下，不同 Namespace 同時有著支援不同版本的 Controller 那麼我們什麼時候會需要 Conversion webhook 呢？\n我們想要將舊的欄位修改，但不想影響到使用中的用戶， 想要穩定的去推進版本並且能夠向下相容，在發出新版本 v1 後，過去使用 v1alpha1 的使用者也能繼續使用\n最後一點，同一個 Cluster 下，有著支援不同 CR 版本的 Controller 是我們在開發上實際遇到的問題。 兩個 Controller 一個想要 v1 版本一個想要 v2 版本時，就會需要 Conversion webhook 來幫忙做版本之間的轉換\n怎麼用 如果沒有設定 conversion webhook 的話，那麼會將目前儲存的直接套用到新版上，並將它改成對應版本\n如果儲存版本有必填欄位是否就會失敗?\n看一眼 etcd 來證明 sudo apt update sudo apt install etcd-client alias ec='ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key' ec get / --prefix --keys-only etcd 的 key 規則類似 /registry/{group}/{kind}/{namespace}/{name}\n# 用 json 格式拿出來看，發現是 Base64 $ ec get /registry/unagi.xiao.xiao/unagilives/unagi-system/unagilive-sample -wjson | jq . # 解開來看到原味內容 $ ec get /registry/unagi.xiao.xiao/unagilives/unagi-system/unagilive-sample -wjson | jq -r .kvs[0].value | base64 -d | jq '.metadata.name, .spec, .status' \u0026quot;unagilive-sample\u0026quot; { \u0026quot;color\u0026quot;: \u0026quot;meow\u0026quot; } { \u0026quot;reconciledTime\u0026quot;: \u0026quot;2022-07-07T09:14:56Z\u0026quot;, \u0026quot;status\u0026quot;: \u0026quot;Reconciled\u0026quot; } 簡化成腳本方便截圖\nETCDCTL_API=3 etcdctl \\ --cacert=/etc/kubernetes/pki/etcd/ca.crt \\ --cert=/etc/kubernetes/pki/etcd/peer.crt \\ --key=/etc/kubernetes/pki/etcd/peer.key \\ get $1 -wjson | jq -r .kvs[0].value | base64 -d | jq '{\u0026quot;name\u0026quot;: .metadata.name, \u0026quot;spec\u0026quot;: .spec}' Conversion Strategy 不過其實策略也只有 Webhook 或 None 可以選，預設是 None\nσ`∀´)σ 解釋 status.storedVersions （曾經用過的儲存版本）\n註冊 Conversion webhook 接下來實際來看 conversion webhook，可以在 CRD 中這樣註冊\nspec: conversion: strategy: Webhook webhook: clientConfig: service: namespace: system name: webhook-service path: /convert conversionReviewVersions: - v1 注意這邊的 conversionReviewVersions 指的是 ConversionReview 的版本，會按照 Array 的順序去支援，可選的有 v1, v1beta1，不過 v1beta1 在 1.16 就已經棄用了，基本這裡只會有 v1\nConversion Review example\n{ \u0026quot;apiVersion\u0026quot;: \u0026quot;apiextensions.k8s.io/v1\u0026quot;, \u0026quot;kind\u0026quot;: \u0026quot;ConversionReview\u0026quot;, \u0026quot;request\u0026quot;: { # Random uid uniquely identifying this conversion call \u0026quot;uid\u0026quot;: \u0026quot;705ab4f5-6393-11e8-b7cc-42010a800002\u0026quot;, # The API group and version the objects should be converted to \u0026quot;desiredAPIVersion\u0026quot;: \u0026quot;example.com/v1\u0026quot;, # The list of objects to convert. # May contain one or more objects, in one or more versions. \u0026quot;objects\u0026quot;: [ { \u0026quot;kind\u0026quot;: \u0026quot;CronTab\u0026quot;, \u0026quot;apiVersion\u0026quot;: \u0026quot;example.com/v1beta1\u0026quot;, \u0026quot;metadata\u0026quot;: { \u0026quot;creationTimestamp\u0026quot;: \u0026quot;2019-09-04T14:03:02Z\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;local-crontab\u0026quot;, \u0026quot;namespace\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;resourceVersion\u0026quot;: \u0026quot;143\u0026quot;, \u0026quot;uid\u0026quot;: \u0026quot;3415a7fc-162b-4300-b5da-fd6083580d66\u0026quot; }, \u0026quot;hostPort\u0026quot;: \u0026quot;localhost:1234\u0026quot; } ] } } 想要添加 CRD conversion webhook 只要在 sepc.conversion.webhookClientConfig 設定好指定的 server，再添加 CA Bundle 的配置就可以了\n轉換方案 注意所有 (Served) 的版本之間都要能夠自由轉換，且不會遺失資料\nIn Kubernetes, all versions must be safely round-tripable through each other. \u0026ndash; kubebuilder docs\n透過 Hub、中轉站 但是為了達到這個目標，當我們有 n 個 versions 時，難道我們就要寫 $n * (n-1)$ 個版本轉換邏輯嗎？\n這顯然是有點麻煩的，我們也可以做一個中轉的結構 v1 -\u0026gt; Hub(storaged) -\u0026gt; v3\n也就能將原本的轉換拓墣簡化：\n版本之間的轉換關係： 維護向前、向後版本 又或者承上面提到的，所有的版本都要能自由轉換！ 因此我們也可以讓每個版本維護上一個版本的轉換規則 v1 -\u0026gt; v2 -\u0026gt; v3\n因此，當新增 v1 版本而 storage version 是 v3 時，就會先轉成 v2 再轉成 v3。 這樣的機制下每個版本只要負責向前和向後轉換的規則就好，減少撰寫轉換邏輯複雜度且能夠輕易的新增、移除版本\n消失的欄位 設計好了轉換的模式後，再來會遇到一個問題：storage version 中不存在的欄位怎麼樣轉換回去？\n假設場景 v1 (storage version) 中有 CIDR 欄位\napiVersion: example.group/v1 kind: Proxy spec: CIDR: \u0026quot;192.168.0.0/24\u0026quot; upstream: \u0026quot;web:80\u0026quot; 而 v2 多了 CIDRs, timeoutSeconds 欄位，但卻將 CIDR 欄位給移除了\napiVersion: example.group/v2 kind: Proxy spec: CIDRs: - \u0026quot;192.168.0.0/24\u0026quot; - \u0026quot;123.0.0.1/32\u0026quot; upstream: \u0026quot;web:80\u0026quot; timeoutSeconds: 10 由於資料量較少的 v1 是儲存版本，因此新增一筆 v2 CR 時會先轉成 v1 再儲存，timeoutSeconds 欄位就會無家可歸，幫QQ 再次將新增的 CR 以 v2 格式取出來時也會發現缺少欄位！\n可以考慮使用第三方資料庫或是直接用 Kubernetes metadata.annotations 來幫存缺少的欄位，例如說我們將 v2 轉成 v1 時如下\napiVersion: example.group/v1 kind: Proxy metadata: annotations: proxy.v2.example.group/state: | { \u0026quot;CIDRs\u0026quot;: [\u0026quot;192.168.0.0/24\u0026quot;, \u0026quot;123.0.0.1/32\u0026quot;] \u0026quot;timeoutSeconds\u0026quot;: 10 } spec: CIDR: \u0026quot;192.168.0.0/24\u0026quot; upstream: \u0026quot;web:80\u0026quot; 這樣子編寫 v1 to v2 的 conversion 邏輯時就能夠從 metadata.annotations 中取得缺少的欄位了！\n撰寫 API 這其實就是一隻 HTTPS 的 JSON API，會用 POST 發到你指定的 webhook 上～\n官方範例就是讚\nhttps://kubernetes.io/zh-cn/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/#webhook-%E8%AF%B7%E6%B1%82%E5%92%8C%E5%93%8D%E5%BA%94\n接下來這段在官方文件中有提到 新增版本的步驟 注意 etcd 內存的版本，不會經過 conversion webhook 刪除版本的步驟 確保所有的客戶端都沒有在使用這個版本了，可以到 kube-apiserver 的 log 再次確認 將欲刪除的版本 served 設置成 false，並確保你的客戶沒有叫 到 CRD 的 status.storedVersions 確保 etcd 內沒有你欲刪除的版本 把他刪掉吧～ 記得 conversion webhook 的轉換也可以刪了 kubernetes-sigs/kube-storage-version-migrator 這個能用？ https://github.com/kubernetes-sigs/kube-storage-version-migrator\nkubectl proxy \u0026amp; curl --header \u0026quot;Content-Type: application/json-patch+json\u0026quot; \\ --request PATCH http://localhost:8001/apis/apiextensions.k8s.io/v1/customresourcedefinitions/\u0026lt;your CRD name here\u0026gt;/status \\ --data '[{\u0026quot;op\u0026quot;: \u0026quot;replace\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/status/storedVersions\u0026quot;, \u0026quot;value\u0026quot;:[\u0026quot;v1\u0026quot;]}]' Example ConversionReview 可以用的有哪些 v1 v1alpha1\n版本优先级 不考虑 CustomResourceDefinition 中版本被定义的顺序，kubectl 使用 具有最高优先级的版本作为访问对象的默认版本。 通过解析 name 字段确定优先级来决定版本号，稳定性（GA、Beta 或 Alpha） 级别及该稳定性级别内的序列。\n他在 Kubernetes 中怎麼運作流程 tail /var/log/kubernetes/audit.log | grep example.group\n會收到 ConversionReview\n實際案例 Cert manager tag: v1.0.0-alpha.1 pkg/internal/apis/certmanager func Convert_\nCert Manager 有過 Conversion Webhook https://github.com/cert-manager/cert-manager/pull/3178 - 新增 deploy/crds/crd-certificaterequests.yaml ㄉ - 刪除 deploy/crds/crd-issuers.yaml ㄉ\nWarning: Do not reuse a CA that is used in a different context unless you understand the risks and the mechanisms to protect the CA\u0026rsquo;s usage. \u0026ndash; from Kubernetes docs\nHTTP Proxy CRD 案例描述 我們有 dev, sit namespace 下的兩個後端服務和兩個 Controller 在獨立的 namespace 有著 conversion webhook Field Managed Defaulting: Values for fields that appliers do not express explicit interest in should be defaulted. This prevents an applier from unintentionally owning a defaulted field that might cause conflicts with other appliers. If unspecified, the default value is nil or the nil equivalent for the corresponding type. \u0026ndash; https://kubernetes.io/blog/2021/08/06/server-side-apply-ga/#using-server-side-apply-in-a-controller\n為了避免不小心修改到，因此僅會給明確關注的欄位，其他的就是 Default value\n一問一答 Q: 存在 etcd 的 v1 被更新後，會變成 v2 存進去嗎\n不會，他會保持原樣。甚至可能過不了新的欄位檢查\nQ: 在沒有 Conversion webhook 的情況下我部署非 stored 的版本會怎樣？\n會使用 None 的策略 for conversion without webhook more precisely: None: The converter only change the apiVersion and would not touch any other field in the custom resource. https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#customresourceconversion-v1-apiextensions-k8s-io\nQ: CRD versions 的 served 表示啟用與否，但他和刪除的差異是什麼？\n使用上基本沒有差了，但是 status.storedVersions 還存在時不能夠刪除版本但可以切換成不 served 補充 served: false 是直接不能使用，但標記 deprecated 只是提醒不能用\nQ: 某個資源在 etcd 裡面是 v1，storage version 從 v1 改成 v2 後，這時候去 get v1 版本他會經過轉換嗎？\n這是個流程問題，應該是先拿出來指定資源後，再去檢查是否有效果 因此我想答案是不會\n拿來跟 Admissions webhook 比較 conversion webhook 和 admissions webhook 的先後次序 應該是： Aggregator –\u0026gt; KubeAPIServer –\u0026gt; APIExtensions\n搭配前面的 Admission Webhook 講解 https://stackoverflow.com/questions/69198043/what-happens-when-creaing-crd-without-relating-operator\nRef https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/\napiextensions go doc https://pkg.go.dev/k8s.io/apiextensions-apiserver@v0.24.2/pkg/apis/apiextensions\n解析kubernetes Aggregated API Servers https://blog.csdn.net/u010278923/article/details/78890533?spm=a2c6h.12873639.article-detail.3.e432294cdAIfpg\nDocker compose -\u0026gt; Kubernetes https://youtu.be/pCXFhCfOAIg\nhttps://speakerdeck.com/david50407/operator-sdk-dai-ni-wan-zhuan-kubernetes?slide=63\nKubernetes CRD开发实践 https://lihaoquan.me/posts/k8s-crd-develop/\nOperator pattern https://www.readfog.com/a/1654115901312700416 diff between Controller and Operator https://stackoverflow.com/a/47857073/6695274\nKubebuilder https://book.kubebuilder.io/architecture.html\n","id":11,"section":"posts","summary":"Introduction (Agenda) Hi 大家好我是 XiaoXiao，現職於 FST Network 擔任軟體工程師 這次主要是要分享 Kubernetes 如何在的自定義擴展定義的 CRD 中做到同時支援多個版本， 這場不會講得太","tags":["kubernetes","crd"],"title":"Kubernetes CRD and Conversion Webhook","uri":"https://blog.10oz.tw/20220427-kubernetes-crd-and-conversion-webhook/","year":"2022"},{"content":"首先 這個網站上找找喜歡的配色 (ﾉ\u0026gt;ω\u0026lt;)ﾉ https://vimcolorschemes.com/\n例如說 vim-sublime-monokai\n問題 這次問題是行數左邊那條灰色太討厭了吧!! 這是因為 airblade/vim-gitgutter 這個套件會標示出 git 變更的項目但這個 theme 顯然沒有料想到這個問題\n認識一下 Vim 語法高亮 首先了解一下 Vim 顏色設定的語法，可以到 Vim 裡面輸入\n:h hi \u0026quot; h 是 help，hi 是 highlight 的簡寫 語法像是這樣\n\u0026quot; hi[ghlight] [default] {group-name} {key}={arg} .. highlight Comment gui=bold hi Comment term=bold ctermfg=Cyan guifg=#80a0ff gui=bold :h highlight-group 可以看到更多的 group-name 例如 Cursor =\u0026gt; the character under the cursor LineNr =\u0026gt; Line number Normal =\u0026gt; normal text \u0026hellip;\n首先有三種類型的 Terminal，不過我大概只會用到 cterm 吧\nterm (terminal: vt100, xterm\u0026hellip;) cterm (color terminal: MS-DOS console, color-xterm\u0026hellip;) gui (Graphical User Interface) 可以搭配 fg, bg 來改字體和背景顏色，或是不加東西表示屬性像是粗體、底線這類的\n可用的 attr-list 有:\nattribute description bold 粗體 underline 底線 reverse 反白，inverse same as reverse italic 斜體 standout nocombine override attributes instead of combining them NONE no attributes used (used to reset it) \u0026quot; 游標所在那行的字變成綠色 hi CursorLine ctermfg=green \u0026quot; 游標所在那行的反白 + 底線 hi CursorLine cterm=reverse,underline \u0026quot; 清除掉顏色 hi CursorLine clear \u0026quot; 憤怒全清 hi clear \u0026quot; 查看目前設定 verbose hi LineNR 尋找解決方法 如何找到 HighLight Group 把這段 function 貼到你的 .vimrc 下註冊，就可以看到游標所在的那個位置有哪些 highlight-group 囉!\n繼續找問題 可是行數左邊那行沒辦法把游標貼上去看阿QQ\n於是直接去翻設定找看看哪裡用到了 grey 這個顏色XDDD\n找到了 原來那一行的名字叫做 SignColumn 呀!\ncall s:h('SignColumn', { 'fg': s:lightblack, 'bg': s:grey }) SignColumn column where signs are displayed\n知道名字其實就很好處理了，把顏色改掉就好啦~~\nhi! link SignColumn LineNr 相關情報 https://stackoverflow.com/a/46636973 手動開關那條 SignColumn\nIf you are using Vim 8.0 or newer (or NeoVim), this is now a simple setting:\n$ vim \u0026quot;+help signcolumn\u0026quot; \u0026quot;+only\u0026quot; For instance,\n:set scl=no \u0026quot; force the signcolumn to disappear :set scl=yes \u0026quot; force the signcolumn to appear :set scl=auto \u0026quot; return the signcolumn to the default behaviour Ref https://youtu.be/XTdxBreTYdM?list=PLBd8JGCAcUAH56L2CYF7SmWJYKwHQYUDI\nhttps://neovim.io/doc/user/options.html#'signcolumn'\n","id":12,"section":"posts","summary":"首先 這個網站上找找喜歡的配色 (ﾉ\u0026gt;ω\u0026lt;)ﾉ https://vimcolorschemes.com/ 例如說 vim-sublime-monokai 問題 這次問題是行數左邊那條灰色太討厭了吧!! 這是因為 airblade/vim-gitgutter 這個套件會標示出 git 變更","tags":["vim"],"title":"Vim Color Schemes","uri":"https://blog.10oz.tw/20220205-vim-color-schemes/","year":"2022"},{"content":"開始使用 上次更換了一下 Blog 的 hugo theme，但是後來發現直接用 git clone 下載下來的 theme 沒有更新到 GitHub 上面 (╯•̀ὤ•́)╯。\n歐給歐給，我們改用一下 Submodule 處理一下\n加入 Submodule 這次目標要把從 Gitee 上 Clone 回來的 Repo XiaoXiaoSN/hugo-theme-pure 作為 Theme， 放到 XiaoXiaoSN/XiaoXiaoBlog 的 themes/pure 資料夾下！\ngit rm themes/pure git submodule add git@github.com:XiaoXiaoSN/hugo-theme-pure.git themes/pure 完成後我們會多一個 .gitmodules 檔案，裡面的內容也很直觀\n[submodule \u0026quot;themes/pure\u0026quot;] path = themes/pure url = git@github.com:XiaoXiaoSN/hugo-theme-pure.git 把更新推出去～ git push origin master 第一次使用 Submodule 的話 為了測試我再另外下載一份\ngit clone --depth 1 git@github.com:XiaoXiaoSN/XiaoXiaoBlog.git testXiaoXiaoBlog 進去後我們可以用 git submodule 查看目前的狀態\n$ git submodule c97723a02ac3abace65a6433eab381f0acbe2719 themes/pure $ git submodule init 子模組 'themes/pure'（git@github.com:XiaoXiaoSN/hugo-theme-pure.git）已對路徑 'themes/pure' 註冊 $ git submodule update 正複製到 '/Users/arios/Project/XiaoXiaoBlog/themes/pure'... 子模組路徑 'themes/pure'：簽出 'c97723a02ac3abace65a6433eab381f0acbe2719' 或是也可以合在一起做\ngit submodule update --init 更新 Submodule 要測試更新 Submodule 所以我們先到被註冊的 Submodule 製造一個 Commit 模擬依賴的模組被更新的狀態～\n# cd hugo-theme-pure git commit -m 'chore: just a empty commit' --allow-empty 再來我們回到剛剛的專案內，並且 cd 到 Submodule 的資料夾\n# cd themes/pure $ git pull origin master 來自 github.com:XiaoXiaoSN/hugo-theme-pure * branch master -\u0026gt; FETCH_HEAD 更新 c97723a..afa94b2 Fast-forward 回到這邊發現 Submodule 已經更新了\n# cd ../.. $ git submodule +afa94b26c59df0c4ce226f173d88fdc8ba9a0246 themes/pure (heads/master) 再重新推出去就好囉～～\ngit add --all git commit -m 'feat: upgrade `themes/pure`' git push origin master 看那個 Commit Hash 是不是不一樣了呀 \u0026gt;u\u0026lt; Ref https://blog.wu-boy.com/2011/09/introduction-to-git-submodule/\n","id":13,"section":"posts","summary":"開始使用 上次更換了一下 Blog 的 hugo theme，但是後來發現直接用 git clone 下載下來的 theme 沒有更新到 GitHub 上面 (╯•̀ὤ•́)╯。 歐給歐給，我們改用一下 Submodule 處理一","tags":["git","hugo"],"title":"用一下 Git Submodule 啦","uri":"https://blog.10oz.tw/20220124-use-git-submodule/","year":"2022"},{"content":" Ubuntu 18.04 Kubernetes 1.21.4\n問題描述 其中一台 Master 機器突然掛掉開不起來，因此決定把他刪掉再加一台新的\n# 找出有問題的節點 $ kubectl get node NAME STATUS ROLES AGE VERSION ip-172-16-16-101 NotReady,SchedulingDisabled control-plane,master 2d9h v1.22.1 ip-172-16-16-102 Ready control-plane,master 2d9h v1.21.4 ip-172-16-16-103 Ready control-plane,master 23h v1.21.4 # 處理掉他！！！ $ kubectl drain ip-172-16-16-101 --force --ignore-daemonsets --delete-local-data $ kubectl delete node ip-172-16-16-101 然後問題來惹，新節點再 kubeadm join 時，竟然等不到剛剛刪掉的機器，卡在這邊跑不下去了！！\n[etcd] Checking etcd cluster health 這裡是加上 --v=5 的詳細資料 然後看 kubelet 的 log\n$ systemctl status kubelet # 滿滿的找不到啊 Failed to get etcd status for https://172.16.16.101:2379: failed to dial endpoint https://172.16.16.101:2379 with maintenance client: context deadline exceeded 開始處理它 到其他台 Master 去，我們要直接動 ETCD 裡面的資料， 首先安裝工具\nsudo apt install etcd-client jq 使用 member list 查看目前的 ETCD 成員紀錄\nETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key member list -w=json | jq . 抓到問題仔還待在裡面\n{ \u0026quot;header\u0026quot;: { \u0026quot;cluster_id\u0026quot;: 17126876678076365000, \u0026quot;member_id\u0026quot;: 863997665741218400, \u0026quot;raft_term\u0026quot;: 1998 }, \u0026quot;members\u0026quot;: [ { \u0026quot;ID\u0026quot;: 863997665741218400, \u0026quot;name\u0026quot;: \u0026quot;ip-172-16-16-103\u0026quot;, \u0026quot;peerURLs\u0026quot;: [ \u0026quot;https://172.16.16.103:2380\u0026quot; ], \u0026quot;clientURLs\u0026quot;: [ \u0026quot;https://172.16.16.103:2379\u0026quot; ] }, { \u0026quot;ID\u0026quot;: 11409705404260921000, \u0026quot;name\u0026quot;: \u0026quot;ip-172-16-16-102\u0026quot;, \u0026quot;peerURLs\u0026quot;: [ \u0026quot;https://172.16.16.102:2380\u0026quot; ], \u0026quot;clientURLs\u0026quot;: [ \u0026quot;https://172.16.16.102:2379\u0026quot; ] }, { \u0026quot;ID\u0026quot;: 12364568155915485000, \u0026quot;name\u0026quot;: \u0026quot;ip-172-16-16-101\u0026quot;, \u0026quot;peerURLs\u0026quot;: [ \u0026quot;https://172.16.16.101:2380\u0026quot; ], \u0026quot;clientURLs\u0026quot;: [ \u0026quot;https://172.16.16.101:2379\u0026quot; ] } ] } 要再去拿一次 Hex 的 ID 然後呼叫 member remove 砍了他\n$ ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key member list bfd894ca145a242, started, ip-172-16-16-103, https://172.16.16.103:2380, https://172.16.16.103:2379 9e576a9d2cd3b2cc, started, ip-172-16-16-102, https://172.16.16.102:2380, https://172.16.16.102:2379 ab97c53a3e73018b, started, ip-172-16-16-101, https://172.16.16.101:2380, https://172.16.16.101:2379 $ ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key member remove ab97c53a3e73018b 回到新的節點去 kubeadm reset 掉後重跑，就可以囉！\nRef https://www.jianshu.com/p/451dc38b1289 https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/\n","id":14,"section":"posts","summary":"Ubuntu 18.04 Kubernetes 1.21.4 問題描述 其中一台 Master 機器突然掛掉開不起來，因此決定把他刪掉再加一台新的 # 找出有問題的節點 $ kubectl get node NAME STATUS ROLES AGE VERSION ip-172-16-16-101 NotReady,SchedulingDisabled control-plane,master 2d9h v1.22.1 ip-172-16-16-102 Ready control-plane,master 2d9h v1.21.4 ip-172-16-16-103 Ready control-plane,master 23h","tags":["kubernetes"],"title":"K8s master 退出不乾淨之新結點進不來","uri":"https://blog.10oz.tw/20210903-k8s-rejoin-drain-node/","year":"2021"},{"content":"準備 deb 檔 準備兩台實驗機器一台當 Server 一台當做 Client 我們先到 Server 這邊隨便弄個 .deb 檔案出來，這次就拿 helm 來當實驗品吧\ncurl https://baltocdn.com/helm/signing.asc | sudo apt-key add - sudo apt-get install apt-transport-https --yes echo \u0026quot;deb https://baltocdn.com/helm/stable/debian/ all main\u0026quot; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list sudo apt-get update sudo apt-get install helm # 或是直接下載，會在當前資料夾 apt-get download helm 下載下來的 .deb 會 Cache 在這邊 /var/cache/apt/archives\n$ ls -al /var/cache/apt/archives | grep helm -rw-r--r-- 1 root root 13674294 Sep 1 05:25 helm_3.6.3-1_amd64.deb # 幫她搬個家，開一個任意資料夾來放 sudo mkdir -p /usr/local/mydebs cp /var/cache/apt/archives/helm_3.6.3-1_amd64.deb /usr/local/mydebs 利用 dpkg-dev 工具來製造描述檔\n$ sudo apt-get install dpkg-dev # 跑看看會出什麼 $ dpkg-scanpackages debs/amd64 Package: helm Version: 3.6.3-1 Architecture: amd64 Maintainer: Matt Fox \u0026lt;matt@getbalto.com\u0026gt; Installed-Size: 44069 Filename: debs/amd64/helm_3.6.3-1_amd64.deb Size: 13674294 MD5sum: e9f028c0e7fc7253a912f9021abc4e3d SHA1: 12cf12bde1fb05aff129bf61f4bc21c5cadd1bc8 SHA256: 27c1a4822b134a2ae4e4e053a5fbb946ef34a33188cdf8a094c2299c3b8ae67b Section: default Priority: extra Homepage: https://helm.sh/ Description: The package manager for Kubernetes License: unknown Vendor: matt@Foxes-iMac.hitronhub.home dpkg-scanpackages: info: Wrote 1 entries to output Packages file. # 打包起來放 dpkg-scanpackages /usr/local/mydebs | gzip -9c \u0026gt; /usr/local/mydebs/Packages.gz 以上前置作業準備好了，已經可以開服務來跑了 在 ubuntu 機器裡面 APT 的來源檔案寫在 /etc/apt/sources.list 或是 /etc/apt/sources.list.d/ 資料夾裡面，可以在這邊加入自己的來源！\n本地檔案讀取方法，不過其他台機器就看不到啦～\necho \u0026quot;deb [trusted=yes] file:/usr/local/mydebs ./\u0026quot; \u0026gt;\u0026gt; /etc/apt/sources.list 開 HTTP Server 你懶的話 python3 -m http.server 直接開起來，我試過也可以動 haha 不過不知道會不會有什麼風險 😂\n可以找 Apache2 來幫忙做 Web Server\nsudo apt-get install apache2 Apache Web Server 預設讀取的位置在 /var/www/html，我們幫他開一個子目錄來做事\nmkdir /var/www/html/foo cp /usr/local/mydebs/Packages.gz /var/www/html/foo # 要提供的機器是 amd64 所以再開一個資料夾，把 `deb` 放進去 mkdir /var/www/html/foo/amd64 cp /usr/local/mydebs/helm_3.6.3-1_amd64.deb /var/www/html/foo/amd64 現在的目錄格式像是這樣\n/var/www/html$ tree . ├── foo │ ├── Packages.gz │ └── amd64 │ └── helm_3.6.3-1_amd64.deb └── index.html 出發去另外一台 Client 的機器，把這個 APT Repository 放進去來源檔～\n# 這邊的 172.16.16.39 是剛剛那台 Apache Server 的內網 IP echo \u0026quot;deb [trusted=yes] http://172.16.16.39/foo/ /\u0026quot; \u0026gt;\u0026gt; /etc/apt/sources.list # 然後更新 apt-get update # 然後就查得到！ apt-cache search helm 離線安裝 deb 檔案 Install\nsudo dpkg -i package_file.deb # or sudo apt install package_file.deb Remove\nsudo apt-get remove package_name Ref https://help.ubuntu.com/community/Repositories/Personal https://medium.com/sqooba/create-your-own-custom-and-authenticated-apt-repository-1e4a4cf0b864 https://askubuntu.com/a/184340/1411904 Debian APT 格式 https://wiki.debian.org/DebianRepository/Format https://help.ubuntu.com/kubuntu/desktopguide/C/manual-install.html\n","id":15,"section":"posts","summary":"準備 deb 檔 準備兩台實驗機器一台當 Server 一台當做 Client 我們先到 Server 這邊隨便弄個 .deb 檔案出來，這次就拿 helm 來當實驗品吧 curl https://baltocdn.com/helm/signing.asc | sudo apt-key add - sudo apt-get install apt-transport-https --yes echo \u0026quot;deb https://baltocdn.com/helm/stable/debian/ all main\u0026quot; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list","tags":["ubuntu","apt"],"title":"來架一台私有 APT Repository","uri":"https://blog.10oz.tw/20210901-build-apt-repository/","year":"2021"},{"content":"安裝 在 docker 裡面啟動 kubernetes 的工具，在 local 端測試相當實用方便!\n官方有提供多個平台的安裝方式，看這點我\n這邊用一個 macOS 的 HomeBrew 來裝\nbrew install kind kind version # kind v0.11.0 go1.16.3 darwin/amd64 常用指令寫下來 建立新群集 注意要指定 kube config 的位置，不然他會幫你放到 ~/.kube/config 裡面喔，亂亂的不好整理吧!! kind create cluster --kubeconfig $HOME/.kube/kind.conf 還可以用 --name 來架設多個群集 (預設 name 會給你 kind) kind create cluster --name kind-2 取得目前建立的 kind get clusters 刪掉群集 kind delete cluster Ref https://kind.sigs.k8s.io/\n","id":16,"section":"posts","summary":"安裝 在 docker 裡面啟動 kubernetes 的工具，在 local 端測試相當實用方便! 官方有提供多個平台的安裝方式，看這點我 這邊用一個 macOS 的 HomeBrew 來裝 brew install kind kind version # kind v0.11.0 go1.16.3 darwin/amd64 常用指令寫下","tags":["kubernetes","kind"],"title":"kind 筆記","uri":"https://blog.10oz.tw/20210821-kind-notes/","year":"2021"},{"content":"介紹 Nix (Nixpkgs) Nix 一般來說是指 Nixpkgs 是一套套件管理系統，利用獨特的函數式語 言來定義安裝的套件。在安裝套件為每一個獨立套件的依賴項做版本控制，避免了傳統套件管理系統安裝不同套件用到相同依賴時的版本更新問題！或是移除、安裝某些需要許多依賴的軟體時，能節省你許多時間！！又或者你同時需要 MySQL 5.5, MySQL 5.7 的 Instance 時也適用～\n能夠做到原子性安裝、刪除，因此能輕易的退版、升級，更能輕易得做到開發環境的切換。（當然代價是同時會有多個版本的軟體佔用儲存空間）\nNixOS NixOS 則是基於 Nixpkgs 來管理整個 Linux Kernel 的 OS，所有的系統設定也都由 nix 支援，能夠配置的切換攜帶到另一台機器上！\n缺點 自成一格的管理模式固然能做到很多事，但也導致許多套件未能支援，需仰賴社群共同維護的力量持續更新與完善整體生態 所有的 Packages 都在這邊，如果發現有缺少的資源可以幫他開 PR 唷～\n安裝 Nix 跟隨官方下載教學的指示，MacOS 這樣裝\n$ sh \u0026lt;(curl -L https://nixos.org/nix/install) # 預設只會幫你在 `/etc/bashrc` `/etc/zshrc` 做好引用， # 如果你想在 fish 使用的話，這裡有人幫忙做連結 fisher install lilyball/nix-env.fish Nixpkgs 常用指令 nix-env 安裝及管理套件安裝 nix-env -i hello Install the package hello nix-env -e hello Remove the package hello nix-env -q List installed packages nix-shell 安裝套件並在新的 shell 開啟 這在測試一些套件時非常有用，不會影響到你平時使用的環境\nnix-shell -p pgformatter nix-collect-garbage 清除沒有被使用到的儲存連結 nix-collect-garbage --delete-older-than 30d 尋找你要的套件們 https://search.nixos.org/\n在 NixOS 環境\nnix-env -iA nixos.go 非 NixOS 環境（單純 Nix Package 管理）\nnix-env -iA nixpkgs.go 列出(query)已安裝套件們\nnix-env -q 解除安裝(uninstall)已安裝套件們\nnix-env --uninstall direnv NixOS 常用指令 nixos-rebuild switch 更新 configuration.nix 後切換到新的系統環境設定 nixos-option nixos-option system.stateVersion 查看某個設定值說明！ Ref https://www.bobby285271.top/zh/ops/nixos-installation NixOS: How it works and how to install it! https://youtu.be/oPymb2-IXbg https://nix.dev/\n","id":17,"section":"posts","summary":"介紹 Nix (Nixpkgs) Nix 一般來說是指 Nixpkgs 是一套套件管理系統，利用獨特的函數式語 言來定義安裝的套件。在安裝套件為每一個獨立套件的依賴項做版本控制，避免了傳統套","tags":["nix","nixos"],"title":"認識一次 Nix 套件管理系統","uri":"https://blog.10oz.tw/20210708-first-take-nix-package-manager/","year":"2021"},{"content":"Linux DE Linux 的 Desktop Environments 真的多到不可思議啦，怎麼選怎麼玩咧\nKDE Plasma 5 大家熟知的一個輕量 DE，有現代且優雅的介面和高度可自訂的優點。 不過也由於高度自訂的關係導致上手難度會相對提高！\n預設安裝 Plasma 的有 openSUSE、Kubuntu 和 KDE Neon，當然作為熱門 DE 常見的 Linux 發行版也其安裝教學\nGNOME 真正的大佬來了，做為最多 Linux 發行版（和多數的 BSD 系統）預設的 DE，更有許多的 DE 都是基於他修改來的。 缺點是大家都說他胖 QQ，如果要選擇安裝在輕量型機器上時可能不是首選\nUbuntu 目前也是使用 GNOME 作為其預設 DE\nXfce 具有超輕量、低耗、穩定等優點，也是目前 linux 發行版常見的預設 DE，雖然較沒有高級的功能設定但是在性能優先的環境下可以考慮使用 Xfce\n知名預設 DE 為 Xfce 的有 kali linux官方也有教你轉 KDE) 以及 Xubuntu\nLXDE \u0026amp;\u0026amp; LXQt 輕量型的 DE，從名字不難看出是由 Qt 開發的，從過去的 LXDE 移植到 Qt 後輕量化了不少！ 然後 LXQt 作者是個台灣人喔xDDD\nRaspberry Pi OS 使用的 DE PIXEL 是由 LXDE 修改而來\nPantheon Like macOS 設計的 DE，基於 GNOME 開發而來。 我個人使用時間最長的環境，直到我用惹真正的 macOS 才發現他根本不行嘛 xDDD 不過也是好幾年以前的事情了，他持續有在更新可以再多看一下～～\nelementary OS 預設 DE\nUnity 這是我最早接觸到的一個 DE，也是早期 Ubuntu 的預設介面（Ubuntu 17.04是最後一個預載 Unity 桌面環境的版本） 它也是由 GNOME 修改而來。 Ref https://itsfoss.com/best-linux-desktop-environments/ https://github.com/twtrubiks/linux-note/tree/master/linux-de\n","id":18,"section":"posts","summary":"Linux DE Linux 的 Desktop Environments 真的多到不可思議啦，怎麼選怎麼玩咧 KDE Plasma 5 大家熟知的一個輕量 DE，有現代且優雅的介面和高度可自訂的優點。 不過也由於高度自訂的關係導","tags":["linux","de"],"title":"認識一次常見 Linux GUI (Desktop Environments)","uri":"https://blog.10oz.tw/20210706-known-popular-linux-de/","year":"2021"},{"content":"描述問題 錯誤訊息類似這樣： 認識問題 原來呢，在 Rust 裡面的 Async 分享變數時會參考 Send Sync 這兩個 Trait\nSend 表示他能在不同的 Thread 中傳遞 A type is Send if it is safe to send it to another thread.\nSync 表示他能同時被多個線程分享使用 (T is Sync if and only if \u0026amp;T is Send) A type is Sync if it is safe to share between threads (T is Sync if and only if \u0026amp;T is Send).\n並且要注意， Send 和 Sync 是自動分配的 Traits，因此大部分接觸到的元件都會是實作 Send 或 Sync 的，像是可以注意以下幾點例外：\nraw pointers are neither Send nor Sync (because they have no safety guards). UnsafeCell isn\u0026rsquo;t Sync (and therefore Cell and RefCell aren\u0026rsquo;t). Rc isn\u0026rsquo;t Send or Sync (because the refcount is shared and unsynchronized). 更多的內容請讀 官方說明\n那麼為什麼我們需要這兩個 Auto Trait 呢？ 這就是 Rust 對記憶體管理厲害的地方了～\n能夠在 Compiler time 就抓出可能發生 race condition 的程式碼，確保變數使用的安全性！\nRef https://blog.rust-lang.org/inside-rust/2019/10/11/AsyncAwait-Not-Send-Error-Improvements.html https://hexilee.me/2019/11/07/async-block-send/ https://doc.rust-lang.org/nomicon/send-and-sync.html\n","id":19,"section":"posts","summary":"描述問題 錯誤訊息類似這樣： 認識問題 原來呢，在 Rust 裡面的 Async 分享變數時會參考 Send Sync 這兩個 Trait Send 表示他能在不同的 Thread 中傳遞 A type is Send if it is safe to send it to another thread. Sync 表","tags":["rust","future"],"title":"Rust - Future cannot be sent between threads safely","uri":"https://blog.10oz.tw/20210703-rust-future-cannot-be-sent-between-threads-safely/","year":"2021"},{"content":"內容開始 已經是很公開的標準了，資料多到不行～～ 還是筆記一下\n取得座標 - getCurrentPosition MDN Doc\nconst successCallback = (position) =\u0026gt; { // position.coords.latitude 緯度 // position.coords.longitude 精度 // position.timestamp 取得的時間戳 ex:1624703519728 } const errorCallback = (err) =\u0026gt; { // err.code 列表 // err.PERMISSION_DENIED: 1 // err.POSITION_UNAVAILABLE: 2 // err.TIMEOUT: 3 if (err.code === err.PERMISSION_DENIED) { console.log('你就是沒開嘛') } } const options = { // false | true enableHighAccuracy: true, // integer (milliseconds) // amount of time before the error callback is invoked, // if 0 it will never invoke. timeout: 5000, // integer (milliseconds) // infinity - maximum cached position age. maximumAge: 0 } navigator.geolocation.getCurrentPosition(successCallback, errorCallback, options) 定期查看座標 - watchPosition MDN Doc\n// 會回傳一個 id 用來取消 watch，其它用法跟 getCurrentPosition 一樣的 const wid = navigator.geolocation.watchPosition(successCallback, errorCallback, options) // 這樣子關～ navigator.geolocation.clearWatch(wid) 確認權限 有時候會想要檢查權限現在的狀態\nnavigator.permissions.query({ name: 'geolocation' }) .then(result =\u0026gt; { // result.state 有三種 // granted 允許 // prompt 要詢問 // denied 封鎖 }) 計算兩點之間的距離 感覺會放在一起用～ 筆記起來\nconst getDistance = (lat1, lng1, lat2, lng2, unit) =\u0026gt; { const radLat1 = (Math.PI * lat1) / 180 const radLat2 = (Math.PI * lat2) / 180 const theta = lng1 - lng2 const radTheta = (Math.PI * theta) / 180 let dist = Math.sin(radLat1) * Math.sin(radLat2) + Math.cos(radLat1) * Math.cos(radLat2) * Math.cos(radTheta) if (dist \u0026gt; 1) { dist = 1 } dist = Math.acos(dist) dist = (dist * 180) / Math.PI dist = dist * 60 * 1.1515 if (unit === 'K') { dist *= 1.609344 } if (unit === 'N') { dist *= 0.8684 } return dist // 'M' is statute miles (default) } Ref https://www.pluralsight.com/guides/how-to-use-geolocation-call-in-reactjs https://developer.mozilla.org/zh-TW/docs/Web/API/Navigator/geolocation\n","id":20,"section":"posts","summary":"內容開始 已經是很公開的標準了，資料多到不行～～ 還是筆記一下 取得座標 - getCurrentPosition MDN Doc const successCallback = (position) =\u0026gt; { // position.coords.latitude 緯度 // position.coords.longitude 精度 // position.timestamp 取得的時間戳 ex:1624703519728 } const errorCallback = (err) =\u0026gt; { // err.code 列","tags":["javascript","location","geographic"],"title":"JavaScript 取得座標位址","uri":"https://blog.10oz.tw/20210623-get-geo-in-javascript/","year":"2021"},{"content":"你問阿狗是什麼 GitOps + Kubernetes 的產物，相當不錯的運維工具\n先來裝 Argo CD 我們要用 helm 安裝裝起來喔\nhelm repo add argo-cd https://argoproj.github.io/argo-helm helm repo update 來準備個 values.yaml\ninstallCRDs: false global: image: tag: v1.8.6 dex: enabled: false server: extraArgs: - --insecure # 如果說你有需要用反向代理抓 subpath，可以在這裡設定 # - --basehref=/argo # - --rootpath=/argo config: # 這裡要把你要監看的 git repo 放上來， # 範例是私有 Gitlab 的設定方式 repositories: | - name: dev-argo insecure: true insecureIgnoreHostKey: true sshPrivateKeySecret: name: argocd-secret key: webhook.gitlab.secret type: git url: git@gitlab.10oz.tw:self_group/dev-argo.git metrics: enabled: true configs: secret: # 這裡產生一個 ssh key 來設定 gitlab repo 裡面的 deploy key # 然後把相應的 private 提供給 Argo 使用 gitlabSecret: |- first set ssh-public-key in gitlab repo, Settings \u0026gt; Repository \u0026gt; Deploy Keys and replace the field with ssh-private-key PS: 後面有說這裏的 Repository 跟 Secret 在哪裡弄 :) 反正先裝等等還能改 XDD\n下個安裝指令\nhelm install argo-cd argo-cd/argo-cd --version 2.11.0 --namespace argocd --values ./values.yaml 你可以把他 port forward 出來看一下\nkubectl port-forward svc/argo-cd-argocd-server 8080:443 -n argocd 帳號是 admin，而密碼會自動產生，預設是 Argo-CD server 的 Pod Name\n# 醬子拿出來看 kubectl get pods -l app.kubernetes.io/name=argocd-server -o name | cut -d'/' -f 2 另外，也可以安裝 argo cli 來修改密碼\nbrew install argocd argocd login localhost:8080 argocd account update-password 開起來會看到這樣的畫面 (PS: 那兩個方框框還不會有，等一下才要裝) 按到左邊齒輪的 Settings 然後 Repositories，如果說你的 Gitlab Repo 還沒設定的話，這裡不會是綠色勾勾 Success 再來設定 ArgoCD 先來搞定 Gitlab Repo 剛剛上面填了一個 repository 的地址，現在要讓他成真 (? 總之就開一個 self_group/dev-argo Repo 在 gitlab.10oz.tw，請自己依照環境調整齁 開好了之後就點進去吧~~\n首先你需要長一個 ssh rsa key 出來\nssh-keygen -f ./argo-deploy-key 然後把你的 Public Key (argo-deploy-key.pub) 設在這裡～ 這時候 Argo 有能力去看你的 Gitlab Repo 了，他會告訴你說你的 Repo 裡面是空ㄉ喔喔喔喔\n讓我們來塞一點東西進去ㄅ，一個 application 用來設定 Argo 的監看目標，而這次監看的目標是 traefik/ingress-route 這個資料夾底下的一般 kubernetes 設定檔案\n. ├── README.md ├── applications │ ├── traefik-ingress-route.yaml └── traefik └── ingress-route └── argo-route.yaml applications/traefik-ingress-route.yaml\nkind: Application apiVersion: argoproj.io/v1alpha1 metadata: name: golang-traefik-ingress-route namespace: argocd spec: project: default destination: name: in-cluster namespace: traefik source: path: traefik/ingress-route repoURL: 'git@gitlab.10oz.tw:self_group/dev-argo.git' targetRevision: HEAD syncPolicy: automated: prune: true traefik/ingress-route/argo-route.yaml\nkind: IngressRoute apiVersion: traefik.containo.us/v1alpha1 metadata: name: argocd-server-route namespace: argocd spec: routes: - kind: Rule match: Host(`foo.10oz.tw`) \u0026amp;\u0026amp; PathPrefix(`/argo`) services: - name: argo-cd-argocd-server port: 80 Commit 推出去，就醬子就能動了喔 👍👍\nRef https://argoproj.github.io/argo-cd/#quick-start https://www.qikqiak.com/post/gitlab-ci-argo-cd-gitops/\n","id":21,"section":"posts","summary":"你問阿狗是什麼 GitOps + Kubernetes 的產物，相當不錯的運維工具 先來裝 Argo CD 我們要用 helm 安裝裝起來喔 helm repo add argo-cd https://argoproj.github.io/argo-helm helm repo update 來準備個 values.yaml installCRDs: false global: image: tag: v1.8.6 dex: enabled: false server: extraArgs: - --insecure # 如果說你","tags":["argo","cd","gitlab"],"title":"究竟阿狗能做什麼呢","uri":"https://blog.10oz.tw/20210409-what-can-argocd-do/","year":"2021"},{"content":"發現 k8s 機器的硬碟空間滿了 滿了耶！！怎麼會這樣 趁還有空間趕快 ssh 進去看一眼\ndev@k8s07:~$ df -h Filesystem Size Used Avail Use% Mounted on udev 5.9G 0 5.9G 0% /dev tmpfs 1.2G 4.5M 1.2G 1% /run /dev/mapper/ubuntu--vg-ubuntu--lv 98G 70G 23G 76% / tmpfs 5.9G 0 5.9G 0% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs 5.9G 0 5.9G 0% /sys/fs/cgroup /dev/sda2 976M 213M 696M 24% /boot tmpfs 1.2G 0 1.2G 0% /run/user/1000 閉眼先清空一波 Docker image, volume\u0026hellip;\ndocker system prune -a 檢查一下還有啥米東西佔用了我們的空間\nsudo du -ahx / | sort -rh | head -n 20 find /var/lib/docker/ -name \u0026quot;*.log\u0026quot; -exec ls -sh {} \\; | sort -h -r | head -20 一看發現原來我有一個 30G 一個 18G 的 docker logs，有夠大啦😂 看一下 log 內容就發現了原因是最近新增的爬蟲的關係 QQ (還有 fluent-bit 也不小)\n解決他 沒事沒事，之前可能大意了沒有想到這種 Case 簡單加個規則就好了\ncat \u0026gt; /etc/docker/daemon.json \u0026lt;\u0026lt;EOF { \u0026quot;exec-opts\u0026quot;: [\u0026quot;native.cgroupdriver=cgroupfs\u0026quot;], \u0026quot;log-driver\u0026quot;: \u0026quot;json-file\u0026quot;, \u0026quot;log-opts\u0026quot;: { \u0026quot;max-size\u0026quot;: \u0026quot;1g\u0026quot;, \u0026quot;max-file\u0026quot;: \u0026quot;3\u0026quot; }, \u0026quot;storage-driver\u0026quot;: \u0026quot;overlay2\u0026quot; } EOF The max-size is a limit on the docker log file, so it includes the json or local log formatting overhead. And the max-file is the number of logfiles docker will maintain. After the size limit is reached on one file, the logs are rotated, and the oldest logs are deleted when you exceed max-file.\nNote: Restart Docker for the changes to take effect for newly created containers. Existing containers do not use the new logging configuration.\n# Restart docker. systemctl restart docker # 手動刪除舊的大檔案 cat /dev/null \u0026gt; 大檔案.log 一個小坑 另外要注意，我第一次寫的時候 daemon.json docker cgroup driver 設定成 systemd 就炸掉了XDD\n$ journalctl -xeu kubelet # ....something failed to run Kubelet: misconfiguration: kubelet cgroup driver: \u0026quot;cgroupfs\u0026quot; is different from docker cgroup driver: \u0026quot;systemd\u0026quot; # ...something Ref https://www.linode.com/community/questions/16922/my-disk-is-filling-up-how-can-i-find-the-culprit https://docs.docker.com/config/containers/logging/configure/#configure-the-default-logging-driver https://stackoverflow.com/questions/31829587/docker-container-logs-taking-all-my-disk-space\n","id":22,"section":"posts","summary":"發現 k8s 機器的硬碟空間滿了 滿了耶！！怎麼會這樣 趁還有空間趕快 ssh 進去看一眼 dev@k8s07:~$ df -h Filesystem Size Used Avail Use% Mounted on udev 5.9G 0 5.9G 0% /dev tmpfs 1.2G 4.5M 1.2G 1% /run /dev/mapper/ubuntu--vg-ubuntu--lv 98G 70G 23G 76% / tmpfs 5.9G 0 5.9G 0% /dev/shm tmpfs","tags":["docker","linux","log"],"title":"啥? k8s node 硬碟空間滿了","uri":"https://blog.10oz.tw/20210402-what-k8s-node-disk-full/","year":"2021"},{"content":"流水帳開始 😂 Terraform 先裝點東西吧 來安裝 terraform\nbrew tap hashicorp/tap brew install hashicorp/tap/terraform 首先登入你的 aws iam 建立一組 Access key, Secret key\n直接產一個 main.tf 檔案~ 下面有指令直接來跑跑看，你應該要多一個 ec2 機器👍\nprovider \u0026quot;aws\u0026quot; { # access_key = \u0026quot;$AWS_ACCESS_KEY_ID\u0026quot; # secret_key = \u0026quot;$AWS_SECRET_ACCESS_KEY\u0026quot; region = \u0026quot;ap-northeast-1\u0026quot; } data \u0026quot;aws_ami\u0026quot; \u0026quot;ubuntu\u0026quot; { most_recent = true filter { name = \u0026quot;name\u0026quot; values = [\u0026quot;ubuntu/images/hvm-ssd/ubuntu-bionic-18.04-amd64-server-*\u0026quot;] } filter { name = \u0026quot;root-device-type\u0026quot; values = [\u0026quot;ebs\u0026quot;] } filter { name = \u0026quot;virtualization-type\u0026quot; values = [\u0026quot;hvm\u0026quot;] } owners = [\u0026quot;099720109477\u0026quot;] # Canonical } # resource \u0026lt;resource_type\u0026gt; \u0026lt;resource_name\u0026gt; resource \u0026quot;aws_instance\u0026quot; \u0026quot;example\u0026quot; { ami = data.aws_ami.ubuntu.id instance_type = \u0026quot;t2.micro\u0026quot; } 上面這一段開一個基本 ec2 instance 的範例，其實官方有教 點我\n第一次進來要先初始化一下！\nterraform init terraform fmt # 格式化文件 terraform plan # 檢查與線上版本的差異 terraform apply # 準備部署 注意喔，再來個 yes 你就發射出去了 # terraform destroy kOps 出現了 跟隨官方腳步走，kOps 帶你部署 terraform \u0026raquo; 點我 networking 那邊可以選你需要的 CNI，不填寫也可以動啦，不過你會得到預設的 Kubenet\nkops create cluster \\ --networking calico \\ --name=ptcg.10oz.tw \\ --state=s3://ptcg-bucket-tf \\ --dns-zone=ptcg.10oz.tw \\ --zones=ap-northeast-1a \\ --out=. \\ --target=terraform 會看到以下的 log\nI0331 02:43:11.734871 11785 new_cluster.go:231] Inferred \u0026quot;aws\u0026quot; cloud provider from zone \u0026quot;ap-northeast-1a\u0026quot; I0331 02:43:12.025276 11785 subnets.go:180] Assigned CIDR 172.20.32.0/19 to subnet ap-northeast-1a I0331 02:43:13.000070 11785 create_cluster.go:713] Using SSH public key: /Users/xiaorenhao/.ssh/id_rsa.pub I0331 02:43:17.504798 11785 executor.go:111] Tasks: 0 done / 79 total; 45 can run I0331 02:43:17.521376 11785 dnszone.go:242] Check for existing route53 zone to re-use with name \u0026quot;ptcg.10oz.tw\u0026quot; W0331 02:43:17.904862 11785 vfs_castore.go:604] CA private key was not found I0331 02:43:18.010251 11785 keypair.go:195] Issuing new certificate: \u0026quot;etcd-clients-ca\u0026quot; I0331 02:43:18.017672 11785 keypair.go:195] Issuing new certificate: \u0026quot;etcd-peers-ca-events\u0026quot; I0331 02:43:18.022377 11785 keypair.go:195] Issuing new certificate: \u0026quot;etcd-manager-ca-events\u0026quot; I0331 02:43:18.022427 11785 keypair.go:195] Issuing new certificate: \u0026quot;apiserver-aggregator-ca\u0026quot; W0331 02:43:18.022450 11785 vfs_castore.go:604] CA private key was not found I0331 02:43:18.022474 11785 keypair.go:195] Issuing new certificate: \u0026quot;ca\u0026quot; I0331 02:43:18.029875 11785 keypair.go:195] Issuing new certificate: \u0026quot;master\u0026quot; I0331 02:43:18.034989 11785 keypair.go:195] Issuing new certificate: \u0026quot;etcd-manager-ca-main\u0026quot; I0331 02:43:18.131053 11785 keypair.go:195] Issuing new certificate: \u0026quot;etcd-peers-ca-main\u0026quot; I0331 02:43:18.247347 11785 dnszone.go:249] Existing zone \u0026quot;ptcg.10oz.tw.\u0026quot; found; will configure TF to reuse I0331 02:43:19.689156 11785 executor.go:111] Tasks: 45 done / 79 total; 16 can run I0331 02:43:19.694681 11785 executor.go:111] Tasks: 61 done / 79 total; 16 can run I0331 02:43:20.133663 11785 executor.go:111] Tasks: 77 done / 79 total; 2 can run I0331 02:43:20.134776 11785 executor.go:111] Tasks: 79 done / 79 total; 0 can run I0331 02:43:20.156638 11785 target.go:221] Terraform output is in . I0331 02:43:20.433778 11785 update_cluster.go:313] Exporting kubecfg for cluster kops has set your kubectl context to ptcg.10oz.tw Terraform output has been placed into . Run these commands to apply the configuration: cd . terraform plan terraform apply Suggestions: * validate cluster: kops validate cluster --wait 10m * list nodes: kubectl get nodes --show-labels * ssh to the master: ssh -i ~/.ssh/id_rsa ubuntu@api.ptcg.10oz.tw * the ubuntu user is specific to Ubuntu. If not using Ubuntu please use the appropriate user based on your OS. * read about installing addons at: https://kops.sigs.k8s.io/operations/addons. 會看見 kOps 幫你建立好了可以開啟 Kubernetes 服務的 terraform 檔案，直接給他跑下去\nterraform plan terraform apply 跑完後用這個指令來檢查你的 k8s cluster 是否有健康跑起來了\nkops validate cluster --wait 10m 開出來的 admin token 一天就會過期，建議是自己建立一個適合自己用的 Service Account， 不過你需要 admin token 的時候可以這麼做\nkops export kubecfg --admin 附錄：我想你會需要 Ingress Route\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.44.0/deploy/static/provider/cloud/deploy.yaml 打完收工 kops delete cluster \\ --name=ptcg.10oz.tw \\ --state=s3://ptcg-bucket-tf \\ --yes terraform destroy 然後建議要多人工檢查一下，因為我下完指令後很開心的洗洗睡了，隔天才注意到 Mount 的 PV 沒有幫我刪掉QQ 下次請記得到 EC2 Volume 看看喔！！\nRef https://shazi7804.github.io/terraform-manage-guide/command/plan.html https://medium.com/@chihsuan/terraform-%E8%87%AA%E5%8B%95%E5%8C%96%E7%9A%84%E5%9F%BA%E7%A4%8E%E6%9E%B6%E6%A7%8B%E4%BB%8B%E7%B4%B9-f827e8975e98 https://godleon.github.io/blog/DevOps/terraform-getting-started/\n","id":23,"section":"posts","summary":"流水帳開始 😂 Terraform 先裝點東西吧 來安裝 terraform brew tap hashicorp/tap brew install hashicorp/tap/terraform 首先登入你的 aws iam 建立一組 Access key, Secret key 直接產一個 main.tf 檔案~ 下面有指令直接來跑跑看，你應該要多一個 ec2 機器","tags":["terraform","kops"],"title":"想用 Terraform 與 kOps 也得寫個筆記","uri":"https://blog.10oz.tw/20210331-terraform-and-kops-need-a-note/","year":"2021"},{"content":" 這是發生在測試鏈 Rinkeby 與 EIP-1559 的故事 也是沒有好好更新節點版本又不認真追時事的故事\n事件發生 大約在晚上 11 點，在家裡測試 SIT 環境的 feature 時，剛好需要幫我的以太錢包充值 發現！ 不妙！ 充不進去耶，怎麼沒反應咧？\n找 log 但一切正常，這時發現卡在 8,290,928 想說這個位置是不是發生了什麼奇怪的交易，來查查看好了～ google 後發現， EIP 1559 實裝在 Rinkeby 惹！ 雖然之前沒有認真關注這個提案，但還是知道他是一個吵很大的硬分叉 馬上 ssh 連到我們的 full node 去看看，最高節點就是在 8,290,928 的位置\n好啦，找到原因了～～ 我們來跟一下硬分叉吧\n更新一下 首先下載最新的包~~\nsudo add-apt-repository -y ppa:ethereum/ethereum -y apt-cache policy ethereum # 確認版本 sudo apt-get upgrade ethereal geth version # 確認版本 然後重啟就好囉\n# 再重新開回服務 geth --rinkeby --http --http.addr 0.0.0.0 --ws --ws.addr 0.0.0.0 --ws.origins * --rpcvhosts=* 知道問題後就也不難了，但是開發這個真的要跟時事呀😂\n不然會跟我一樣，都分叉一天了才發現自己的服務沒有更新 QQ\n","id":24,"section":"posts","summary":"這是發生在測試鏈 Rinkeby 與 EIP-1559 的故事 也是沒有好好更新節點版本又不認真追時事的故事 事件發生 大約在晚上 11 點，在家裡測試 SIT 環境的 feature 時，剛好需要幫我的以太錢","tags":["blockchain","ethereum","geth"],"title":"小紀錄更新 Rinkeby Ethereum 節點","uri":"https://blog.10oz.tw/20210326-little-bit-update-rinkeby-ethereum/","year":"2021"},{"content":"問題描述 helm release 明明就存在，但是他就是跟你說沒有部署的版本\nError: UPGRADE FAILED: \u0026quot;code-server\u0026quot; has no deployed releases 處理一下 原來是狀態不對，可能上一次部署的時候失敗了，只要你加上 --force 再給他跑下去就好\n或者說去找到 secrets sh.helm.release.v1.{server_name}.v{version} 修改一下裡面的 labels status，改成 deployed\nmetadata: name: sh.helm.release.v1.code-server.v31 namespace: foo uid: b94b5861-8f98-4e8c-bb81-e715975d8c22 resourceVersion: '46153334' creationTimestamp: '2021-03-04T06:12:08Z' labels: modifiedAt: '1614838331' name: code-server owner: helm status: failed # 改這裏成 deployed version: '31' 再重新 Retry 一下 helm upgrade 就可以囉\n","id":25,"section":"posts","summary":"問題描述 helm release 明明就存在，但是他就是跟你說沒有部署的版本 Error: UPGRADE FAILED: \u0026quot;code-server\u0026quot; has no deployed releases 處理一下 原來是狀態不對，可能上一次部署的時候失敗了，只要你加上 --force 再給他","tags":["kubernetes","helm"],"title":"helm3 說 has no deployed releases","uri":"https://blog.10oz.tw/20210326-helm3-has-no-deployed-releases/","year":"2021"},{"content":" GitLab Community Edition 12.7.0 go version go1.15 darwin/amd64\n問題描述 事實上這次包含兩個問題，一個是 Privite Gitlab 的認證另一個是 Gitlab Subgroup 的支援\nPrivite Gitlab 存取私有的 Gitlab 可以修改你的 go env\nexport GOPRIVATE=gitlab.company.com.tw Subgroup 你的 go.mod\nmodule example.com/test require gitlab.com/org/subgroup/repo/pkg/foo v0.0.0 replace gitlab.com/org/subgroup/repo/pkg/foo =\u0026gt; gitlab.com/org/subgroup/repo.git/pkg/foo v1.0.0 Ref https://gitlab.com/gitlab-org/gitlab-foss/-/issues/30785\n","id":26,"section":"posts","summary":"GitLab Community Edition 12.7.0 go version go1.15 darwin/amd64 問題描述 事實上這次包含兩個問題，一個是 Privite Gitlab 的認證另一個是 Gitlab Subgroup 的支援 Privite Gitlab 存取私有的 Gitlab 可以修改你的 go env export GOPRIVATE=gitlab.company.com.tw Subgroup 你的 go.mod module example.com/test require gitlab.com/org/subgroup/repo/pkg/foo v0.0.0 replace gitlab.com/org/subgroup/repo/pkg/foo","tags":["golnag","gitlab","subgroup"],"title":"go get 與私有 Gitlab","uri":"https://blog.10oz.tw/20210316-go-get-privite-gitlab-repo/","year":"2021"},{"content":"問題描述 這幾天工作遇到 chromedp 爬蟲執行完後沒有被關閉！ 導致 memory 不斷堆積\n因為監測 metrics 的最小單位是 container，一開始調查以為是程式記憶體過高所以嘗試用 pprof 錄了一段後發現沒有直接的上升，於是直接進入容器裡面觀察 process 佔用的資源\n哇嗚，發現好多 chrome 的屍體 好了，開始研究為什麼 chromedp 沒幫我們把它關掉。 此時發現一張 Issue 有這個問題和其他人的研究成果\n解決方法 其實解決方法 chromedp 已經給你了\nFROM chromedp/headless-shell:latest ... # Install dumb-init or tini RUN apt install dumb-init # or RUN apt install tini ... ENTRYPOINT [\u0026quot;dumb-init\u0026quot;, \u0026quot;--\u0026quot;] # or ENTRYPOINT [\u0026quot;tini\u0026quot;, \u0026quot;--\u0026quot;] CMD [\u0026quot;/path/to/your/program\u0026quot;] 就是第 7 行的那個，在 docker image 中不要直接去跑你的程式而是用 dumb-init 去包起來跑！ 就可以避免殭屍進程了\n原因是這樣的，一般來說在執行 OS 的時候 Pid 為 1 的服務會是系統服務(ex: systemd, launchd)，然而在 Container 裡面 Pid=1 是我們自己的程式！\n$ man launchd launchd(8) BSD System Manager\u0026rsquo;s Manual launchd(8)\nNAME launchd \u0026ndash; System wide and per-user daemon/agent manager\n當一個 Process 被關閉時，他的 SubProcess 會被託管給 Pid=1 的 Process，但是我們寫的程式並沒有託管的功能所以那些 SubProcess 就被 hang 在那邊成為殭屍。\n更多深入了解可以看 dumb-init github 和 dumb-init：一个 Docker 容器初始化系统\nRef https://github.com/chromedp/chromedp/issues/752 https://github.com/chromedp/docker-headless-shell#using-as-a-base-image https://github.com/Yelp/dumb-init 詳細說明 https://www.infoq.cn/article/2016/01/dumb-init-docker\n","id":27,"section":"posts","summary":"問題描述 這幾天工作遇到 chromedp 爬蟲執行完後沒有被關閉！ 導致 memory 不斷堆積 因為監測 metrics 的最小單位是 container，一開始調查以為是程式記憶體過高所以嘗","tags":["chromedp","chromium","golang","linux"],"title":"Chromedp 殭屍進程","uri":"https://blog.10oz.tw/20210306-chromedp-zombi-process/","year":"2021"},{"content":"GFW (great fire wall) 中國大陸在 2008 年啟動的計畫，監管所有的網路流量並且阻擋許多境外的網站和不受允許的 IP，例如說 youtube, google search, facebook 都是被禁止的。也因此有了翻牆找自由的需求，幫 QQ\nGFW 擋掉的方法有域名污染、關鍵字阻斷、特徵攔截\u0026hellip;等等，只要他看見你的封包含有他不喜歡的關鍵字，或是黑名單的 IP 就直接斷掉你的網路封包。\n因此想要繞過 GFW 的審核，就需要用上封包加密，他看不懂的東西他不會隨便的就把你給封鎖掉，也就有機會可以碰觸到外面的世界。 不過這樣會面臨到另一個問題，加密的內容 GFW 看不懂，google 也一樣看不懂，因此需要有一台跳板機來解密，然後跳板機幫你做到你真正想要做的事情，再將結果加密傳回去給你。\n常用技術與工具們 VPS (Virtual Private Server) 也就是跳板機啦，常用的供應商有 Linode, Vultr，都是老牌穩定價格合理的廠商。\n他們會租借一台虛擬的主機和 IP 給你，就好像有一台實際的電腦，你可以連線進去在上面做任何的事情~~ 當然也包含架設 VPN 跳板喔\nsocks5 跑在第五層(Session Layer)的代理服務，很常被用來作為 VPN 服務的代理，不過這個協定不包含加密，因此一般會再搭配其他服務一起使用。 另外他無法做到全局代理，例如更低層級的 TCP, ICMP 這些協定，你 ping 回來還會是自己的 IP\n可以使用類似 tun2sock 這類工具，轉換所有的流量至 socks5，以達到全局代理的效果，當然別忘記還沒加密嘿\nShadowSocks (SS, SSR) 最有知名度的翻牆工具，內容就是簡單的對封包做對稱加密，支援多種加密法，也有各種語言實作套件，不過也因為他簡單所以有很多人都表示這種翻牆的特徵已經能夠被 GFW 識別出來了，然而目前的翻牆最大宗還是使用 ShadowSocks 再加上 socks5 代理\n然後作者在 github 上突然的消失好幾個月惹，大家都說他被中國政府抓去喝茶惹\nSSR(ShadowSocksR) 是 ShadowSocks 的 fork 修改版\nV2Ray 來自 Project V，V2Ray 專案就是個超級綜合包，支援許多種不同的協議(當然也包含 ShasowSocks)，可以自定義出口協定、入口協定、白名單\u0026hellip;，抽象程度很高可以彈性的做變化，也因此複雜度相當高\n也有發行自己的協議 - VMess，他是基於 TLS 的加密演算法，用於保護內容，混淆特徵。\n平台上推薦的用法是 VMess + WSS，也就是用 vemss 協議加密再透過 TLS 加密過的 websocket 傳輸，加完密基本上從外觀上看就是一個跟所有人都一樣的正常 websocket 連線，而且被 GFW 抓走的案例也相對少很多，因此被認為是一個主流的翻牆方式～～\nTrojan 不太認識這個QQ，是個後來出現的明日之星(?\n他和 V2Ray 相同也是跑在 WSS 上做加密、混淆，不過他不像 V2Ray 有這麼多的選擇，也就更輕量更簡單。\n專線(IPLC, IEPL) 中國內部的網路有幾種線路，常見的 163, CN2\u0026hellip; 還有其他幾種骨感網路的流量，不是很了解但知道他們都是要過 GFW 的。\nIPLC 就厲害啦，他不過 GFW 所以不用翻！不過這線路貴得很，基本不在選項內 XDD\nTODO嗎 像是傳統的 VPN 協議就會有明顯的特徵， PPTP L2TP openVPN SSTP\u0026hellip;\nRef https://www.v2ray.com/developer/intro/guide.html https://www.youtube.com/watch?v=XKZM_AjCUr0\u0026amp;list=PLqybz7NWybwUgR-S6m78tfd-lV4sBvGFG https://github.com/trojan-gfw/trojan https://wivwiv.com/post/ssr-v2ray-trojan/ https://blog.wongcw.com/2019/07/03/iepl%E3%80%81iplc%E8%A9%B3%E7%B4%B0%E4%BB%8B%E7%B4%B9%E5%8F%8A%E5%8D%80%E5%88%A5/\n","id":28,"section":"posts","summary":"GFW (great fire wall) 中國大陸在 2008 年啟動的計畫，監管所有的網路流量並且阻擋許多境外的網站和不受允許的 IP，例如說 youtube, google search, facebook 都是被禁止的。也因此有了翻牆找自由","tags":["gfw","vpn"],"title":"VPN \u0026 GFW - 科學上網","uri":"https://blog.10oz.tw/20210124-vpn-and-gfw/","year":"2021"},{"content":"關於 protobuf null value golang 預設建出來的是沒有指標的，但是有時候就是需要指標來判斷啊！\noption protobuf v3 從 1.12 開始支援實驗性功能 option，讓用戶可以像是 v2 時一樣使用 option 去產生一個 nullable 的欄位\nsyntax = \u0026quot;proto3\u0026quot;; message Foo { int32 bar = 1; optional int32 baz = 2; } https://stackoverflow.com/a/62566052/6695274\nwrappers 不過， gogo-proto 並不支援阿QQ，\n但也不能就這麼捨棄 gogo-proto，因此我們需要選擇另一個方案\nimport \u0026quot;google/protobuf/wrappers.proto\u0026quot;; message Foo { int32 bar = 1; google.protobuf.Int32Value baz = 2; } https://stackoverflow.com/a/50099927/6695274\n記得在 --go-output= 內加上 Mgoogle/protobuf/wrappers.proto=github.com/gogo/protobuf/types\n但是但是，無法支援 enum 我難過\ncustom wrappers 只好自己動手做 (?\nenum Status { STATUS_OK = 0; STATUS_FAIL = 1; } message NullInt32 { bool valid = 1; int32 value = 2; } message NullStatus { bool valid = 1; Status value = 2; } message Foo { int32 bar = 1; NullInt32 baz = 2; NullStatus status = 3; } gen 成 golang 的 code 之後就這樣用，基本上跟 wrappers 的用法是一樣的\ntype NullStatus struct { Valid bool `protobuf:\u0026quot;varint,1,opt,name=valid,proto3\u0026quot; json:\u0026quot;valid,omitempty\u0026quot;` Value Status `protobuf:\u0026quot;varint,2,opt,name=value,proto3,enum=blackblock.Status\u0026quot; json:\u0026quot;value,omitempty\u0026quot;` XXX_NoUnkeyedLiteral struct{} `json:\u0026quot;-\u0026quot;` XXX_unrecognized []byte `json:\u0026quot;-\u0026quot;` XXX_sizecache int32 `json:\u0026quot;-\u0026quot;` } func (m *NullStatus) GetValid() bool { if m != nil { return m.Valid } return false } func (m *NullStatus) GetValue() Status { if m != nil { return m.Value } return Status_STATUS_OK } type Foo struct { Bar int32 `protobuf:\u0026quot;varint,1,opt,name=bar,proto3\u0026quot; json:\u0026quot;bar,omitempty\u0026quot;` Baz *NullInt32 `protobuf:\u0026quot;bytes,2,opt,name=baz,proto3\u0026quot; json:\u0026quot;baz,omitempty\u0026quot;` Status *NullStatus `protobuf:\u0026quot;bytes,3,opt,name=status,proto3\u0026quot; json:\u0026quot;status,omitempty\u0026quot;` XXX_NoUnkeyedLiteral struct{} `json:\u0026quot;-\u0026quot;` XXX_unrecognized []byte `json:\u0026quot;-\u0026quot;` XXX_sizecache int32 `json:\u0026quot;-\u0026quot;` } 好啦，希望不要用到啦😅\n","id":29,"section":"posts","summary":"關於 protobuf null value golang 預設建出來的是沒有指標的，但是有時候就是需要指標來判斷啊！ option protobuf v3 從 1.12 開始支援實驗性功能 option，讓用戶可以像是 v2 時一樣使用 option","tags":null,"title":"gRPC - protobuf v3 產生 nullable 欄位","uri":"https://blog.10oz.tw/20201123-nullable-column-in-protobuf-v3/","year":"2020"},{"content":"開始安裝 下載後會得到一個資料夾 istio-1.7.4 把他加入你的執行檔中吧\ncurl -L https://istio.io/downloadIstio | sh - export PATH=$PWD/istio-1.7.4/bin:$PATH istioctl version # 成功就是有囉 預設的 Profile 們有六個，我就先用 default 吧\ndefault demo minimal remote empty preview Core components istio-egressgateway X istio-ingressgateway X X X istiod X X X X istioctl profile list istioctl install --set profile=default 裝好之後來實驗一下喔，開一個新的 namespce 並安裝官方範例 book info，裡面包含 4 個微服務\nkubectl create namespcae istio-bookinfo # kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml kubectl apply -n istio-bookinfo -f https://raw.githubusercontent.com/istio/istio/release-1.7/samples/bookinfo/platform/kube/bookinfo.yaml 目前的 pod 裡面都只有 1 個 Container，我們要注入 istio 的 envoy proxy 讓每個 Pod 裡面多一個 sidecar\n\u0026gt; ~/istio » kubectl get po -n istio-bookinfo NAME READY STATUS RESTARTS AGE details-v1-79c697d759-9kvrq 1/1 Running 0 3m41s productpage-v1-65576bb7bf-w9gf6 1/1 Running 0 3m38s ratings-v1-7d99676f7f-tq9kw 1/1 Running 0 3m40s reviews-v1-987d495c-j655s 1/1 Running 0 3m40s reviews-v2-6c5bf657cf-l595s 1/1 Running 0 3m39s reviews-v3-5f7b9f4f77-4qdtb 1/1 Running 0 3m39s kubectl label namespace istio-bookinfo istio-injection=enabled kubectl get namespace -L istio-injection # 重新部署，就把 Pod 都刪掉吧 kubectl delete (kubectl get all | grep pod | awk '{print $1}') 如果要關掉的話\nkubectl label namespace default istio-injection- 再來看看，是不是每個 Pod 裡面都多一個 Container 啦~\n\u0026gt; ~/istio » kubectl get pod NAME READY STATUS RESTARTS AGE details-v1-79c697d759-lqt6k 2/2 Running 0 3m15s productpage-v1-65576bb7bf-zwgqd 2/2 Running 0 3m15s ratings-v1-7d99676f7f-fqvvd 2/2 Running 0 3m15s reviews-v1-987d495c-kbc4z 2/2 Running 0 3m14s reviews-v2-6c5bf657cf-749bn 2/2 Running 0 3m14s reviews-v3-5f7b9f4f77-f7wvk 2/2 Running 0 3m14s 我們的服務目前長這樣 kubectl port-forward svc/productpage 9080:9080 -n istio-bookinfo 利用 Kaili 視覺化 traffic # 詳細內容在 https://github.com/istio/istio/tree/1.7.0/samples/addons kubectl apply -f samples/addons 檢查 namespace istio-system 內，多了 grafana, kiali, prometheus, tracing, zipkin 這幾個服務\n來看看 kaili 喔～\nport-forward svc/kiali 20001:20001 -n istio-system kaili 可以用流量直接幫我們畫出 service 之間的關係圖 Reference https://istio.io/latest/docs/setup/getting-started/ https://istio.io/latest/docs/setup/additional-setup/config-profiles/ https://istio.io/latest/docs/examples/bookinfo/\n","id":30,"section":"posts","summary":"開始安裝 下載後會得到一個資料夾 istio-1.7.4 把他加入你的執行檔中吧 curl -L https://istio.io/downloadIstio | sh - export PATH=$PWD/istio-1.7.4/bin:$PATH istioctl version # 成功就是有囉 預設的 Profile 們有六個，我就先用 default 吧 default demo minimal remote empty preview Core components istio-egressgateway X istio-ingressgateway","tags":["kubernetes","istio","service-mesh"],"title":"新米 Istio - 安裝篇","uri":"https://blog.10oz.tw/20201115-a-istio-beginner/","year":"2020"},{"content":"架構 ECS(Elastic Container Service) 是 AWS 上的容器管理服務，架構上可以簡單分成幾層:\nCluster 一個群集 :) Service 可以把它當作 \u0026ldquo;執行企劃\u0026rdquo;，就像是一個 docker-compose 將多個 docker 服務包裝起來 Task 由 Service 產生的工作任務，負責維護 Container 的部署，在 EC2 模式就是他負責部署服務到機器上的 Container 你的 AP 在這裡，他就是最底層的容器服務啦 分成兩種模式，差別在底層的機器是否需要自己管理， 無論是哪種都可以做 Auto Scaling 來確保服務的可用性\nFargate mode ECS 的預設選擇模式，是比較後來才出來的功能。 不需要自己來管理底層的機器(EC2)，還會幫忙處理掉 Auto Scaling 和 loading balance，讓開發人員可以專注在服務、網路層級，推薦使用 EC2 mode 底層的機器是自己分配的 EC2 instance，也可以設定 Spot 模式在不需要的時候是關機的，價格低非常多 按照官方教的走 https://docs.aws.amazon.com/zh_tw/AmazonECS/latest/developerguide/ecs-cli-tutorial-fargate.html\n# 一個新的 ECS Cluster ecs-cli configure --cluster silkrode --default-launch-type FARGATE --config-name tutorial --region ap-northeast-1 ecs-cli configure profile --access-key AKIAW5********SDNHKT --secret-key YFFP36xe+b********pnOSlVT1+JLs7Ck07kGYJS --profile-name tutorial-profile ecs-cli up --cluster-config tutorial --ecs-profile tutorial-profile aws ec2 describe-security-groups --filters Name=vpc-id,Values=vpc-0d0b9a2b847dd6eaf --region ap-northeast-1 aws ec2 authorize-security-group-ingress --group-id sg-0a8d7d69bd7302908 --protocol tcp --port 8000 --cidr 0.0.0.0/0 --region ap-northeast-1 docke-compose.yml\nversion: '3' services: web: image: xiao4011/toolbox ports: - \u0026quot;8000:8000\u0026quot; depends_on: - \u0026quot;redis\u0026quot; logging: driver: awslogs options: awslogs-group: tutorial awslogs-region: ap-northeast-1 awslogs-stream-prefix: web redis: image: redis ecs-params.yml\nversion: 1 task_definition: task_execution_role: ecsTaskExecutionRole ecs_network_mode: awsvpc task_size: mem_limit: 0.5GB cpu_limit: 256 run_params: network_configuration: awsvpc_configuration: subnets: - subnet-007b5172614cc7c27 security_groups: - sg-0a8d7d69bd7302908 assign_public_ip: ENABLED ecs-cli compose --project-name tutorial service up --create-log-groups --cluster-config tutorial --ecs-profile tutorial-profile 服務開完就關掉惹 XDD\nRef AWS ECS vs Kubernetes: https://cloud.netapp.com/blog/aws-ecs-vs-kubernetes-an-unfair-comparison ECS介紹 (EC2 mode \u0026amp; Fargate mode) https://youtu.be/22IsSW3YD0A https://docs.aws.amazon.com/AmazonECS/latest/developerguide/clusters.html\n","id":31,"section":"posts","summary":"架構 ECS(Elastic Container Service) 是 AWS 上的容器管理服務，架構上可以簡單分成幾層: Cluster 一個群集 :) Service 可以把它當作 \u0026ldquo;執行企劃\u0026rdquo;，就像是一個 docker-compose 將多個 docker","tags":["aws"],"title":"有一天路過 AWS ECS","uri":"https://blog.10oz.tw/20201009-aws-ecs-beginner/","year":"2020"},{"content":"介紹一下 在遇見 GraphQL 的時候最常被比較的就是 Restful API，畢竟 Rustful API 是目前的主流設計，此時我們就必須了解到什麼情況下使用 GraphQL 能帶來效益\nOver Fetch Restful API 的回傳會是一整個 resource， /user/1 會回傳 id=1 的 User 的全部資料，然而在很多情況下我們不需要這麼多的資料，可能 我們僅僅只需要 user 的名字而已 在 GraphQL 你可以指定你所需要的欄位，大大的減少了傳輸無用資料的消耗 Under Fetch 也就是 n+1 問題，情景是 user 有很多的 friends，每個朋友都是一名 User，在 Restful 的設計中，每個 User resource 都是一支 API，想想就頭痛 QQ。因此會在後端客製化 API 做 eager loading，一次回傳這些資料 但到了 GraphQL 這完全不是問題，你可以向下定義你所需要的資料，並嵌入 User 中 query { User(id: 1) { Name AvatarURL friends { ID Name } } } 在設計上，GraphQL 關注 明確的解釋查詢語言與型態系統 而不去描述伺服器端實作，前後端之間以 Schema 定義溝通介面，雙方有共通的資料型態以及明確定義的詞彙來討論\n讓一切清楚且簡單～\n怎麼用r 工具會用一點 - GraphQL Playground 認識一些 GraphQL Schema GraphQL 定義自己的語法格式，他是個 SDL (Schema Define Language)\n首先來定義一個 type 也就是基本的物件，基本型別有 Int Float String Boolean ID，也可以用 ! 來定義該欄位是否是 Nullable 的\ntype Student { id: Int! name: String! \u0026quot;可以寫註解說每個學生都有 sid\u0026quot; studentID: String! \u0026quot;\u0026quot;\u0026quot; 多行註解說： 每個學生都可以填一個電話 \u0026quot;\u0026quot;\u0026quot; phone: Phone \u0026quot;\u0026quot;\u0026quot; 每個人都可以發很多文 \u0026quot;\u0026quot;\u0026quot; articles: [Article!] } type Phone { phoneNumber: String! } type Article { title: String! content: String! } 基本型別不夠用嗎，我們來自定義一下，Date 然後這個型別的實作要伺服器端自己來喔\nscalar Date # 用法這樣 type Article2 { title: String! content: String! date: Date! } 也可以定義枚舉類別(enumeration)\nenum GradingStatus { INPROGRESS GRADUATED } type Student2 { gradingStatus: GradingStatus! } 當你的物件可能是不同的結構時，你可以找 union\n\u0026quot;\u0026quot;\u0026quot; union 定義 User 可能是 Student 也可能是 Teacher \u0026quot;\u0026quot;\u0026quot; union User = Student | Teacher 或是 interface 也能滿足你的需求\ninterface User { id: ID! name: String! phone: Phone } type Student implements User { id: ID! name: String! phone: Phone # 你還可以定義更多更多... } type Teacher implements User { id: ID! name: String! phone: Phone # 你還可以定義更多更多... } query mutation 驚嘆號 (enum with default)\n語法知道一下 (query, mutation, subscription) 有三種基本語法 query, mutation, subscription\nquery 可以簡單想像他是 RestfulAPI 中的 GET，用來拿各種資料\nfragment 可以抽出常用的結構來簡化語法\nquery { me { ...UserBrief } # 可以一次定義多個 query user(name: \u0026quot;foo\u0026quot;) { id ...UserBrief } } # fragment 可以幫助重用參數 fragment UserBrief on User { name email } union 有時候回傳的不一定是同一種物件，這時候可以這麼做\n# 一個 people 可能是 Teacher 或是 Student，不同的 type 會回傳不同的內容 query people { ...on Teacher { teacherID name } ...on Student { studentID name grade } } # 等價的，你也可以寫成這樣 query people { ...pTeacher ...pStudent } fragment pTeacher on Teacher { teacherID name } fragment pStudent on Student { studentID name grade } mutation 可以簡單想像他是 RestfulAPI 中的 POST，用來變更資料\nmutation { newUser(name: \u0026quot;foo\u0026quot; email: \u0026quot;bar@mail.tw\u0026quot;) { id # 回傳的 id ...UserBrief } } fragment UserBrief on User { name email } 也可以用 $ 開頭寫點變數\nmutation create($name: String $email: String) { newUser(name: $name email: $email) { id # 回傳的 id ...UserBrief } } fragment UserBrief on User { name email } subscription 建立 websocket 長連線來接收資料的變更，用法跟 query 很像，在資料變更時就收到訊息囉\nsubscription { me { name email } } Introspection 自我查詢 GraphQL 可以利用自我查詢來取得目前的 Schema\nquery ListTypes { __schema { # 取得 gql 定義了哪些 Types types { kind # Object, InputObject, Enum, Scalar name description # 這裡也可以直接 fields 拿詳細資訊 } } } query TypeDetail { # 我們想要拿 Role 這個 Type 的詳細資料 __type(name: \u0026quot;Role\u0026quot;) { name kind fields { name type { ofType{ name } } } } } query IntrospectionQuery { # 我要拿全部操作(query, mutation, subscription) __schema { queryType { ...OprationDetail } mutationType { ...OprationDetail } subscriptionType { ...OprationDetail } } } fragment OprationDetail on __Type { name fields { name type { ofType{ name } } } } graphQL 自帶文件，具備一般 API Server 沒有的優勢，棒棒ㄉ\nHASURA https://cloud.hasura.io/project/88f267cd-3f1b-45fa-a1e1-a7ceed6ba10a/env-vars\nRef Think in GraphQL https://ithelp.ithome.com.tw/users/20111997/ironman/1878 https://graphql.org/learn/schema/\n","id":32,"section":"posts","summary":"介紹一下 在遇見 GraphQL 的時候最常被比較的就是 Restful API，畢竟 Rustful API 是目前的主流設計，此時我們就必須了解到什麼情況下使用 GraphQL 能帶來效益 Over Fetch Restful API 的回傳會是一","tags":["graphql","gql"],"title":"GraphQL 打招呼","uri":"https://blog.10oz.tw/20201009-hello-graphql/","year":"2020"},{"content":"好文章推推，直接抄爆 https://learnku.com/articles/24924\n設定開始 撰寫設定檔 首先 vim ~/.vimrc 改成下面這模樣\n\u0026quot;============================================================================== \u0026quot; vim 内置配置 \u0026quot;============================================================================== \u0026quot; 设置 vimrc 修改保存后立刻生效，不用在重新打开 \u0026quot; 建议配置完成后将这个关闭，否则配置多了之后会很卡 \u0026quot; autocmd BufWritePost $MYVIMRC source $MYVIMRC \u0026quot; 关闭兼容模式 set nocompatible set nu \u0026quot; 设置行号 set cursorline \u0026quot;突出显示当前行 set showmatch \u0026quot; 显示括号匹配 \u0026quot; tab 缩进 set tabstop=4 \u0026quot; 设置Tab长度为4空格 set shiftwidth=4 \u0026quot; 设置自动缩进长度为4空格 set autoindent \u0026quot; 继承前一行的缩进方式，适用于多行注释 \u0026quot; 定义快捷键的前缀，即\u0026lt;Leader\u0026gt; let mapleader=\u0026quot;,\u0026quot; \u0026quot; ==== 系统剪切板复制粘贴 ==== \u0026quot; v 模式下复制内容到系统剪切板 vmap \u0026lt;Leader\u0026gt;c \u0026quot;+yy \u0026quot; n 模式下复制一行到系统剪切板 nmap \u0026lt;Leader\u0026gt;c \u0026quot;+yy \u0026quot; n 模式下粘贴系统剪切板的内容 nmap \u0026lt;Leader\u0026gt;v \u0026quot;+p \u0026quot; 开启实时搜索 set incsearch \u0026quot; 搜索时大小写不敏感 set ignorecase syntax enable syntax on \u0026quot; 开启文件类型侦测 filetype plugin indent on \u0026quot; 启用自动补全 \u0026quot; 退出插入模式指定类型的文件自动保存 au InsertLeave *.go,*.sh,*.php write \u0026quot;============================================================================== \u0026quot; 插件配置 \u0026quot;============================================================================== \u0026quot; 插件开始的位置 call plug#begin('~/.vim/plugged') \u0026quot; Shorthand notation; fetches https://github.com/junegunn/vim-easy-align \u0026quot; 可以快速对齐的插件 Plug 'junegunn/vim-easy-align' \u0026quot; 用来提供一个导航目录的侧边栏 Plug 'scrooloose/nerdtree' \u0026quot; 可以使 nerdtree Tab 标签的名称更友好些 Plug 'jistr/vim-nerdtree-tabs' \u0026quot; 可以在导航目录中看到 git 版本信息 Plug 'Xuyuanp/nerdtree-git-plugin' \u0026quot; 支援更多 git 的功能 Plug 'tpope/vim-fugitive' Plug 'tpope/vim-rhubarb' Plug 'shumphrey/fugitive-gitlab.vim' \u0026quot; 可以在文档中显示 git 信息 Plug 'airblade/vim-gitgutter' \u0026quot; 查看当前代码文件中的变量和函数列表的插件， \u0026quot; 可以切换和跳转到代码中对应的变量和函数的位置 \u0026quot; 大纲式导航, Go 需要 https://github.com/jstemmer/gotags 支持 Plug 'majutsushi/tagbar' \u0026quot; 自动补全括号的插件，包括小括号，中括号，以及花括号 Plug 'jiangmiao/auto-pairs' \u0026quot; Vim状态栏插件，包括显示行号，列号，文件类型，文件名，以及Git状态 Plug 'vim-airline/vim-airline' \u0026quot; 代码自动完成，安装完插件还需要额外配置才可以使用 Plug 'Valloric/YouCompleteMe' \u0026quot; 下面两个插件要配合使用，可以自动生成代码块 Plug 'SirVer/ultisnips' Plug 'honza/vim-snippets' \u0026quot; 配色方案 Plug 'fatih/molokai' \u0026quot; go 主要插件 Plug 'fatih/vim-go', { 'tag': '*' } \u0026quot; go 中的代码追踪，输入 gd 就可以自动跳转 Plug 'dgryski/vim-godef' \u0026quot; markdown 插件 Plug 'iamcco/mathjax-support-for-mkdp' Plug 'iamcco/markdown-preview.vim' \u0026quot; 模糊搜尋 Plug 'junegunn/fzf', { 'dir': '~/.fzf', 'do': './install --all' } Plug 'junegunn/fzf.vim' \u0026quot; 多行編輯 Plug 'mg979/vim-visual-multi' \u0026quot; 搜尋 Plug 'mileszs/ack.vim' let g:ackprg = 'ag --nogroup --nocolor --column' \u0026quot; 插件结束的位置，插件全部放在此行上面 call plug#end() \u0026quot;============================================================================== \u0026quot; 主题配色 \u0026quot;============================================================================== let g:rehash256 = 1 let g:molokai_original = 1 colorscheme molokai \u0026quot; colorscheme sublimemonokai \u0026quot;============================================================================== \u0026quot; vim-go 插件 \u0026quot;============================================================================== let g:go_fmt_command = \u0026quot;goimports\u0026quot; \u0026quot; 格式化将默认的 gofmt 替换 let g:go_autodetect_gopath = 1 let g:go_list_type = \u0026quot;quickfix\u0026quot; let g:go_version_warning = 1 let g:go_highlight_types = 1 let g:go_highlight_fields = 1 let g:go_highlight_functions = 1 let g:go_highlight_function_calls = 1 let g:go_highlight_operators = 1 let g:go_highlight_extra_types = 1 let g:go_highlight_methods = 1 let g:go_highlight_generate_tags = 1 let g:go_highlight_format_strings = 1 let g:go_highlight_function_arguments = 1 let g:go_highlight_generate_tags = 1 let g:go_highlight_variable_declarations = 1 let g:godef_split=2 \u0026quot;============================================================================== \u0026quot; NERDTree 插件 \u0026quot;============================================================================== \u0026quot; 打开和关闭NERDTree快捷键 map \u0026lt;F10\u0026gt; :NERDTreeToggle\u0026lt;CR\u0026gt; \u0026quot; 显示行号 let NERDTreeShowLineNumbers=1 \u0026quot; 打开文件时是否显示目录 let NERDTreeAutoCenter=1 \u0026quot; 是否显示隐藏文件 let NERDTreeShowHidden=1 \u0026quot; 设置宽度 \u0026quot; let NERDTreeWinSize=31 \u0026quot; 忽略一下文件的显示 let NERDTreeIgnore=['\\.pyc', '\\~$', '\\.swp', '.git'] \u0026quot; 打开 vim 文件及显示书签列表 let NERDTreeShowBookmarks=2 \u0026quot; 在终端启动vim时，共享NERDTree let g:nerdtree_tabs_open_on_console_startup=1 \u0026quot;============================================================================== \u0026quot; majutsushi/tagbar 插件 \u0026quot;============================================================================== \u0026quot; majutsushi/tagbar 插件打开关闭快捷键 nmap \u0026lt;F9\u0026gt; :TagbarToggle\u0026lt;CR\u0026gt; let g:tagbar_type_go = { \\ 'ctagstype' : 'go', \\ 'kinds' : [ \\ 'p:package', \\ 'i:imports:1', \\ 'c:constants', \\ 'v:variables', \\ 't:types', \\ 'n:interfaces', \\ 'w:fields', \\ 'e:embedded', \\ 'm:methods', \\ 'r:constructor', \\ 'f:functions' \\ ], \\ 'sro' : '.', \\ 'kind2scope' : { \\ 't' : 'ctype', \\ 'n' : 'ntype' \\ }, \\ 'scope2kind' : { \\ 'ctype' : 't', \\ 'ntype' : 'n' \\ }, \\ 'ctagsbin' : 'gotags', \\ 'ctagsargs' : '-sort -silent' \\ } \u0026quot;============================================================================== \u0026quot; nerdtree-git-plugin 插件 \u0026quot;============================================================================== let g:NERDTreeGitStatusIndicatorMapCustom = { \\ \u0026quot;Modified\u0026quot; : \u0026quot;✹\u0026quot;, \\ \u0026quot;Staged\u0026quot; : \u0026quot;✚\u0026quot;, \\ \u0026quot;Untracked\u0026quot; : \u0026quot;✭\u0026quot;, \\ \u0026quot;Renamed\u0026quot; : \u0026quot;➜\u0026quot;, \\ \u0026quot;Unmerged\u0026quot; : \u0026quot;═\u0026quot;, \\ \u0026quot;Deleted\u0026quot; : \u0026quot;✖\u0026quot;, \\ \u0026quot;Dirty\u0026quot; : \u0026quot;✗\u0026quot;, \\ \u0026quot;Clean\u0026quot; : \u0026quot;✔︎\u0026quot;, \\ 'Ignored' : '☒', \\ \u0026quot;Unknown\u0026quot; : \u0026quot;?\u0026quot; \\ } let g:NERDTreeGitStatusShowIgnored = 1 \u0026quot;============================================================================== \u0026quot; nerdtree-git-plugin 插件 \u0026quot;============================================================================== \u0026quot; [Buffers] Jump to the existing window if possible let g:fzf_buffers_jump = 1 nnoremap \u0026lt;leader\u0026gt;fl :Lines nnoremap \u0026lt;leader\u0026gt;fbl :BLines nnoremap \u0026lt;leader\u0026gt;ff :Files \u0026quot;============================================================================== \u0026quot; Valloric/YouCompleteMe 插件 \u0026quot;============================================================================== \u0026quot; make YCM compatible with UltiSnips (using supertab) let g:ycm_key_list_select_completion = ['\u0026lt;C-n\u0026gt;', '\u0026lt;space\u0026gt;'] let g:ycm_key_list_previous_completion = ['\u0026lt;C-p\u0026gt;', '\u0026lt;Up\u0026gt;'] let g:SuperTabDefaultCompletionType = '\u0026lt;C-n\u0026gt;' \u0026quot; better key bindings for UltiSnipsExpandTrigger let g:UltiSnipsExpandTrigger = \u0026quot;\u0026lt;tab\u0026gt;\u0026quot; let g:UltiSnipsJumpForwardTrigger = \u0026quot;\u0026lt;tab\u0026gt;\u0026quot; let g:UltiSnipsJumpBackwardTrigger = \u0026quot;\u0026lt;s-tab\u0026gt;\u0026quot; \u0026quot;============================================================================== \u0026quot; 支援更多 git \u0026quot;============================================================================== \u0026quot; GBrower gitlab let g:fugitive_gitlab_domains = ['https://gitlab.silkrode.com.tw'] let g:gitlab_api_keys = {'gitlab.silkrode.com.tw': '這個可能不能公開'} \u0026quot;============================================================================== \u0026quot; 其他插件配置 \u0026quot;============================================================================== \u0026quot; markdwon 的快捷键 map \u0026lt;silent\u0026gt; \u0026lt;F5\u0026gt; \u0026lt;Plug\u0026gt;MarkdownPreview map \u0026lt;silent\u0026gt; \u0026lt;F6\u0026gt; \u0026lt;Plug\u0026gt;StopMarkdownPreview \u0026quot; tab 标签页切换快捷键 :nn \u0026lt;Leader\u0026gt;1 1gt :nn \u0026lt;Leader\u0026gt;2 2gt :nn \u0026lt;Leader\u0026gt;3 3gt :nn \u0026lt;Leader\u0026gt;4 4gt :nn \u0026lt;Leader\u0026gt;5 5gt :nn \u0026lt;Leader\u0026gt;6 6gt :nn \u0026lt;Leader\u0026gt;7 7gt :nn \u0026lt;Leader\u0026gt;8 8gt :nn \u0026lt;Leader\u0026gt;9 8gt :nn \u0026lt;Leader\u0026gt;0 :tablast\u0026lt;CR\u0026gt; 安裝相關插件 Plug - vim 套件管理工具 我們要用 Plug 來裝插件 https://github.com/junegunn/vim-plug\nunix 版本\ncurl -fLo ~/.vim/autoload/plug.vim --create-dirs \\ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 然後輸入 vim +PlugInstall 開始安裝 再來安裝 vim +GoInstallBinaries golang tools，雖然沒意外的話早就裝過惹呢XDD\n你完成我 - 自動補齊工具 YouCompleteMe 剛才已經用 Plug 下載下來了，不過還不能直接使用\ncd .vim/plugged/YouCompleteMe brew install cmake macvim # 可選: python mono go nodejs # 如果不指定 go 的話，他會安裝 C# Go JavaScript Rust Jaca python3 install.py --go-completer 使用者筆記 插件們 雖然剛剛裝了滿滿的 plugin 但也要會用才行rrr 😂😂\nNERDTree - 左邊的 Sidebar C_w + [上下左右] 切換到 [上下左右] 的分割視窗 C_w + w 切換到下一個分割視窗 在 NERDTress 對檔案 t 開啟新分頁 在 NERDTress 對檔案 o 開啟新分頁，並跳過去 在 NERDTress 對資料夾 o 展開/縮合資料夾 在 NERDTress 按下 m 會進入檔案管理模式，再來按 a 可以新增檔案 切換到指定分頁 \u0026lt;Leader\u0026gt;[1-9] 或是上面有設定 [1-9]gt vim-fugitive 提供了很多在 vim 上面整合 git 的功能 :Gdiffsplit 水平分割 git diff 畫面 (上下) :Gvdiff 垂直分割 git diff 畫面 (看左右好像比較習慣) :GBrowser 直接在網頁(github, gitlab)上開啟目前的檔案 Vim 基本常用指令 多行修改: C_V 選取， I 進入修改模式 C_d 下滑一頁 C_b 上滑一頁 :set syn=yaml 設定語法高亮 Ref https://learnku.com/articles/24924 https://github.com/ycm-core/YouCompleteMe\n","id":33,"section":"posts","summary":"好文章推推，直接抄爆 https://learnku.com/articles/24924 設定開始 撰寫設定檔 首先 vim ~/.vimrc 改成下面這模樣 \u0026quot;============================================================================== \u0026quot; vim 内置配置 \u0026quot;============================================================================== \u0026quot; 设置 vimrc 修改保存后立刻生效，不用在重新打开 \u0026quot; 建议配置完成后将这","tags":["vim","golang"],"title":"我要裝 vim","uri":"https://blog.10oz.tw/20200926-wanna-install-vim/","year":"2020"},{"content":" 這次筆記內容會圍繞在比特幣這個區塊鍊加密貨幣系統 然後比特幣是一種讓北極熊沒有家住的技術 (?\n區塊鏈的安全 區塊鏈鏈的模式，保證新的區塊接續前一個區塊，當區塊越多越難被修改 共識機制需要多數節點認同保護資料不易被竄改，也就是去中心化的部分啦 密碼學上的困難問題保護使用資產不會被任意取用，也在建立新的區塊時增加難度，就是挖礦的部分啦 共識機制 這是在分散式系統中相當常見的問題，當節點多了，在同步上出現分歧時應該要聽誰的? 究竟誰手中的資料才是正確的呢?\n拜占庭將軍問題 描述有數個將軍各自在不同地方，但有著相同的任務，而這個任務非常艱難，必須要每個將軍同時進攻、或是同時撤退，否則就會失敗。\n因此在出發之前，每位將軍會投票決定之後才開始行動， 然而\u0026hellip;在這樣的條件下，竟有還有幾位將軍是隱藏身分的間諜!?\n在節點中，同樣會遇到這樣的問題，當節點中出現了不遵守規定的惡意節點時，該如何將它的影響降低呢?\n挖礦 也就是增加難度，比特幣使用 PoW(Proof-of-Work)，讓北極熊沒地方住 ，讓每個節點用工作量來證明自己。如果你想要搞破壞的話，你必須付出比整個鏈上過半的計算能力，然而在現在廣大的比特鏈生態來說，這是不可能的。\n每個鏈上的共識機制都不同，例如乙太鍊上使用的是 PoS\n激勵機制 在前一個段落的區塊鍊安全那邊有說到使用 PoW 來保證難以隨意的添加區塊，但是認真想想誰要做這麼吃力的事情? 因此激勵機制的部分就是 給你錢幫我算 (*´∀`)~♥ xdd\n區塊鏈節點 身為一個去中心化的點對點系統，當然一定要有節點。在比特鏈上可以大致分兩種節點，全節點(Full Node)與輕量節點(Light Node)\n全節點: 存放著完整的比特鏈資訊(好幾十GB)，工作是打包區塊上鏈以及驗證其他人上傳區塊的合法性 輕量節點: 也稱為簡單支付驗證（SPV）節點，不需要儲存所有區塊資訊，也不會對鏈上的安全性做出貢獻，就只是個 read user。可以是手機或是電腦的客戶端軟體，他能夠驗證某一筆交易是否在區塊鏈中 礦工仔: 準確來說礦工不一定是比特網路的一部分，礦工只需要向全節點要求交易回來打包、計算，再將節點廣播出去給所有的全節點驗證就好了 挖礦仔常見問題 Q: 挖礦是啥米?\n當有一筆交易要進行的時候，交易方拋出他的交易資訊，請人幫他簽核，成功幫他完成任務的人會有獎金\nQ: 這個簽核任務有是啥米?\n礦工們會將交易區塊資訊 + Nonce 拿去 hash，不斷的替換 Nonce 取得某一組 hash 值開頭是 n 個 bits 為 0 的解答，第一個拿到解答的就是這次挖礦的成功者。因此越多人參與解題就越難挖到礦\nQ: 這樣不就超難挖礦的嗎?\n每經過 2016 個交易認證後難度會改變(要求開頭的 0 變多個或變少)，改變依照之前的交易認證時間，如果太久就變簡單一點，反之亦然。\nQ: 挖礦挖不完的嗎?\n會挖完的，最一開始驗證一筆交易礦工可以拿到 50 塊錢比特幣，每次產生出 21萬塊錢比特幣後，獎勵就會少一半，直到最後小於比特幣可以支付的最小單位 (10的-8次方比特幣)\n交易模型 UTXO Model (Unspent Transaction Output)，在比特幣鏈上的餘額並不是直接儲存一個數字的，如果你今天想要拿到某個地址的餘額的話，就需要從第一個區塊開始看，把每一筆還沒有被消費掉的交易(Unspent Transaction)加起來，這個數字才會是你的餘額。 例如說:\nA 轉給 C 100 btc .... (tx1) B 轉給 C 120 btc .... (tx2) 到這裡 C 有 2 筆未使用交易，總共 220 btc 如果 C 要轉給 A 130 塊錢的話，就必須從他的 UTXO 裡面選出來交易 C -\u0026gt; A 130 btc .... (tx3) C -\u0026gt; C 90 btc .... (tx4) 多餘的錢錢要還給自己呀！ 因此最後的結果中，C 消耗了 tx1, tx2 C 剩下一筆 90 塊的未使用交易 粉塵攻擊 在 UTXO 系統中會遇到的身分問題，可以參考這篇寫得很棒 XDD https://iview.sina.com.tw/post/23868182\n在區塊上的交易紀錄基本上都是公開透明的，可以共大眾來查找。\n公有鏈：完全去中心化，也就是完全公開透明、任何人都可以加入，每個人都可以讀取上面的資料的鏈。 私有鏈：部分去中心化，是完全私有的區塊鏈，寫入權限全被一處中心所把持，而讀取權限則被這處中心限制，但此鏈交易速度比較快並且也保持了不可篡改性，是給私有公司使用的鏈。 聯盟鏈：介於公有鏈和私有鏈之間，和私有鏈最大的不同是，它適用於多個機構共同使用，或者一整個行業、聯盟用的；而私有鏈是一家企業或公司用的\nMerkle Tree 不可修改性 如果今天有人想要修改一個區塊的交易紀錄，會需要把後續所有的 Block 都修改才行，\n用於快速驗證交易存在某個區塊\nBIP (Bitcoin Improvement Proposals) BIP-32 HD-Wallet 定義 Hierarchical Deterministic wallet，可以由一個 Seed 來產生多組錢包地址(包含公鑰、私鑰) 好處是只需要記得 Seed 就可以動態錢包，不需要記得很長的密碼\nBIP-39 助記詞 助記詞(mnemonic)將 Seed 用英文單字來編碼表示，更方便記憶。 做法是 seed + checkSum 然後每 11bits 兌換呈一個對應的字\nBIP-44 多帳號的 HD-Wallet 基於 BIP-32 的系統，讓他同時支援多種幣別， 而一組助記詞可以產出 N 組私鑰，每組私鑰對應一種幣種(BTC, ETH\u0026hellip;) 表示形式像是:\nm / purpose' / coin_type' / account' / change / address_index 每個欄位有不同意義 - purpose' 固定寫 44 表示是依照 BIP-44 規則產生後面的樹跟子節點 - coin_type' 一組 Seed 可以為不同幣別產生多個完全獨立的錢包地址，例如比特幣是 0，以太幣是 60 \u0026raquo;\u0026gt; 這邊有列表 - account' 一組 Seed 可以為不同帳號產生多個完全獨立的錢包地址 - change' 固定用 0 表示外部鍊(external chain) 用於對外部收款付款， 1 表示內部鍊(internal chain)，這什麼意思\u0026hellip;我看不懂QQ - index' 剛剛說了麻，一個 Seed 可以產很多地址，index 表示你要第幾個錢包地址\ncoin account chain address path Bitcoin first external first m / 44\u0026rsquo; / 0\u0026rsquo; / 0\u0026rsquo; / 0 / 0 Bitcoin Testnet first external first m / 44\u0026rsquo; / 1\u0026rsquo; / 0\u0026rsquo; / 0 / 0 可以到這個網站上實際產生一組試試看 https://iancoleman.io/bip39/\n錢包地址 比特幣錢包地址可能是 1, 3, bc1 開頭，測試鏈上的地址是 m, n, 2, tb1 開頭\n交易 有分幾種交易簽章模式，差別在如何使用 tx out，每個 tx out 上都有不同的 lock script，可以把這個鎖想像成是一個題目，你必須將題目完整解鎖你才有資格，例如說 lock script 是 + 3 = 5，那你 tx in 的 unlock script 就要是 2，組合起來驗證 2 + 3 = 5 這樣才是一個合法的交易簽章\n主要分成幾種模式：\nP2PKH (Pay to Pubkey Hash) 算是最基礎的模式，使用的 lock script 是\nOP_DUP OP_HASH160 \u0026lt;Public Key Hash\u0026gt; OP_EQUAL OP_CHECKSIG unlock script\n\u0026lt;Signature\u0026gt; \u0026lt;Public Key\u0026gt; P2SH (Pay to Script Hash) 在這之前要先認識一下多簽 (Multi-signature)，他的 lock script 是由多個公鑰組成，你必須完成他指定數量的簽章才能解鎖，\n例如說 2-3 多簽，就是你必須要有這 3 個人其中兩個的簽章\n2 \u0026lt;Public Key A\u0026gt; \u0026lt;Public Key B\u0026gt; \u0026lt;Public Key C\u0026gt; 3 OP_CHECKMULTISIG 假設你有 B, C 的同意， unlock script 會像是\nOP_0 \u0026lt;Signature B\u0026gt; \u0026lt;Signature C\u0026gt; 不過，這樣的方式如果人數一多會讓 lock script 變得非常非常長，這樣儲存 UTXO 會浪費掉很多珍貴的記憶體，因此 P2SH 來解決問題惹，簡單來說就是把題目放到 lock script，而 unlock script 只存題目的 hash，驗證時首先驗證 lock script 裡面的題目 hash 後是否和 unlock script 相同，相同的話就相信你並接收你的驗證\nlock script, 裡面的 redeem scriptHash 就是題目的 hash，\nredeem script(題目): 2 PKA PKB PKC 3 OP_CHECKMULTISIG\nOP_HASH160 \u0026lt;redeem scriptHash\u0026gt; OP_EQUAL unlock script 比較一下前面的多簽\n\u0026lt;SigB\u0026gt; \u0026lt;SigC\u0026gt; 2 PKA PKB PKC 3 OP_CHECKMULTISIG example: P2WPKH ( pay to witness public key hash) SegWit (Segregated Witness) 隔離見證 由於每個區塊最多最多只能夠有 1MB，而每一筆交易的簽章佔用了很大的比例， 因此在 BIP141 提出了見證隔離這個方案，將原本一個區塊的最大值從 1MB 改成 4MB，計算單位從 bytes 改成 weight，並將原本簽章的部份抽出來存放，這表示發一筆交易需要的 byte 更少更便宜，經過計算後一個區塊能夠放更多的交易，因此交易速度提高，而礦工打包區塊也可以拿到更多手續費，\nBech32 encoded segwit addresses start with a human-readable\n帳號安全 橢圓曲線用的是這條 secp256k1，他長這樣\nsecp256k1.P = fromHex(\u0026quot;FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F\u0026quot;) secp256k1.N = fromHex(\u0026quot;FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141\u0026quot;) secp256k1.B = fromHex(\u0026quot;0000000000000000000000000000000000000000000000000000000000000007\u0026quot;) secp256k1.Gx = fromHex(\u0026quot;79BE667EF9DCBBAC55A06295CE870B07029BFCDB2DCE28D959F2815B16F81798\u0026quot;) secp256k1.Gy = fromHex(\u0026quot;483ADA7726A3C4655DA4FBFC0E1108A8FD17B448A68554199C47D08FFB10D4B8\u0026quot;) 比特幣錢包地址怎麼來的呢?\n把公鑰拿出來找到他在曲線上的 (x, y)，再拿去 hash 2 次， 再將 hash 結果做兩次 sha256 取得前四個 byte 作為 checkSum 最後 base58 encode 就是人類看到的地址囉 hash = ripemd160(sha256(pubkey_bits)) checkSum = sha256(sha256(\u0026ldquo;00\u0026rdquo;+hash))[:4] // (0x00 for Main Network) addr = base58(hash + checkSum) 詳細可以參考這篇wiki\n以太幣錢包的話有點不同\n把公鑰拿出來後用的是 Keccak-256(sha-3) 來 hash，特點是長度是不固定的 最後加上 EIP55 的大小寫檢查碼 (這是可選的) 詳細可以參考這個 https://git.io/ethAddressHash\nRef 什麼是節點 https://academy.binance.com/zt/articles/what-are-nodes https://medium.com/taipei-ethereum-meetup/%E8%99%9B%E6%93%AC%E8%B2%A8%E5%B9%A3%E9%8C%A2%E5%8C%85-%E5%BE%9E-bip32-bip39-bip44-%E5%88%B0-ethereum-hd-%EF%BD%97allet-a40b1c87c1f7 https://github.com/bitcoin/bips/blob/master/bip-0044.mediawiki 比特幣問題們 https://bitcoin.org/zh_TW/faq#wont-the-finite-amount-of-bitcoins-be-a-limitation 關於比特幣地址 https://medium.com/my-blockchain-development-daily-journey/%E9%97%9C%E6%96%BC%E6%AF%94%E7%89%B9%E5%B9%A3%E5%9C%B0%E5%9D%80-%E4%BD%A0%E8%A9%B2%E7%9F%A5%E9%81%93%E7%9A%84%E4%BA%8B-8dd3bbb89ade 隔離見證 https://blockcast.it/2017/04/24/what-is-scalability-issue-and-segregated-witness/ bitcoin tx怎麼包 https://medium.com/taipei-ethereum-meetup/mastering-bitcoin-ch5-transactions-38a387e3819a 比特節點介紹 https://academy.binance.com/zt/articles/what-are-nodes 註記詞與BIP https://www.mdeditor.tw/pl/pCPM/zh-tw\n","id":34,"section":"posts","summary":"這次筆記內容會圍繞在比特幣這個區塊鍊加密貨幣系統 然後比特幣是一種讓北極熊沒有家住的技術 (? 區塊鏈的安全 區塊鏈鏈的模式，保證新的區塊接續前一個區","tags":null,"title":"新米 blockchain 混亂中","uri":"https://blog.10oz.tw/20200919-blockchain-bitcoin-beginer/","year":"2020"},{"content":"wire 是個啥米 wire 是一個靜態的注入工具，不像是其他的注入工具(uber/fx, facebook/inject)使用 reflect 來達成，他選擇使用 gen code 的方式產生可以使用的注入程式碼。\n能夠在編譯階段將注入的動作完成，而不是在執行程式的當下才知道發生了什麼錯誤\nQ: Should I use Wire for small applications?\nProbably not. Wire is designed to automate more intricate setup code found in larger applications. For small applications, hand-wiring dependencies is simpler. 不複雜的小型專案還是手動注入會更乾淨喔~\ngo build tag 菜鳥如我這時候才知道，在 .go 檔案最前面加入 build tag 的檔案，在編譯的時候是不會被加進去的(ex: //+build foo ) 所以可以放重複的 function 在同一個 package 裡面，這個操作在 lorca 那篇也有出現過，可以交叉比較一下～\n這是一個 wire.go 檔案\n//+build wireinject package main import ( \u0026quot;learnGo/wire/repo\u0026quot; \u0026quot;learnGo/wire/service\u0026quot; \u0026quot;github.com/google/wire\u0026quot; ) func CreateService() (service.Service, error) { wire.Build(repo.NewRepo, service.NewService) panic(\u0026quot;never be triggered\u0026quot;) return nil, nil } 這是一個 wire_gen.go 檔案，他們在同一個 package 下，定義著相同的函式，但是編譯的時候只會看 wire_gen.go，因為 wire.go 的最前面有標記 build tag\n// Code generated by Wire. DO NOT EDIT. //go:generate wire //+build !wireinject package main import ( \u0026quot;learnGo/wire/repo\u0026quot; \u0026quot;learnGo/wire/service\u0026quot; ) import ( _ \u0026quot;github.com/google/wire\u0026quot; ) // Injectors from wire.go: func CreateService() (service.Service, error) { repoRepo := repo.NewRepo() serviceService := service.NewService(repoRepo) return serviceService, nil } 假設我們有個 main.go 來執行\u0026hellip;\npackage main import ( _ \u0026quot;github.com/google/wire\u0026quot; ) func main() { svc, err := CreateService() if err != nil { panic(err) } svc.SayHello(\u0026quot;wire main package\u0026quot;) } 執行 go build -tags wireinject 這樣會使用 wire.go 來編譯，長出來的執行檔就會跑 wire.go:14 的 panic\n根據這樣的經驗，進階可以利用 golang build tag 的功能，依照不同的需求來編譯出不同的執行檔\n踩到坑: 如果用 go run *.go 來跑，那麼你會得到 {function} redeclared in this block，你的所有檔案還是會被拿來用QQ\nWire 的使用方法 使用上一段落的範例， wire_gen.go 是怎麼長出來的呢？ 首先需要安裝 wire\ngo get github.com/google/wire/cmd/wire 然後輸入\nwire 就可以看見 wire_gen.go 長出來囉\n詳細看一下內容的前幾行，\n// 提醒你和編譯器這是一個產生出來的檔案，不是給人類直接修改的 // Code generated by Wire. DO NOT EDIT. // 可以使用 `go generate` 指令來觸發後面的指令， // 在這裡會幫你跑 wire 來 gen code //go:generate wire // 註記 build tags 不存在 wireinject 用的 //+build !wireinject // ... 注入 Interface 在 github 的 document guide 上有寫，很實用也寫一份易讀版\n任務: repo.NewRepo 回傳 *repo.DefaultRepo (他實作 repo.Repoer) svc.NewService 需要一個 repo.Repoer 因此我們需要多做一層將 pointer 轉成 interface\n// Repo ... type Repoer interface { // } // NewRepo ... func NewRepo(cfg *config.Config) *DefultRepo { return \u0026amp;DefultRepo{ Prefix: cfg.DBCfg.Prefix, } } // NewService ... func NewService(repo repo.Repoer) *DefultService { return \u0026amp;DefultService{ repo: repo, } } var Set = wire.NewSet( // 產生 *DefaultRepo repo.NewRepo, // 將 *DefaultRepo 轉成 Repoer wire.Bind(new(repo.Repo), new(*repo.DefultRepo)), // 注入需要 Repoer service.NewService, ) Ref https://medium.com/@dche423/master-wire-cn-d57de86caa1b https://github.com/google/wire/blob/main/docs/guide.md\n","id":35,"section":"posts","summary":"wire 是個啥米 wire 是一個靜態的注入工具，不像是其他的注入工具(uber/fx, facebook/inject)使用 reflect 來達成，他選擇使用 gen code 的方式產","tags":["golang","di","wire"],"title":"golang 注入工具 wire","uri":"https://blog.10oz.tw/20200908-golang-di-tool-wire/","year":"2020"},{"content":"介紹 GitHub 在 2018 年推出的短網址服務: git.io\n他可以把 GitHub 的網址縮短~\nwith fish 其實會發現他的原因，是因為在尋找 fish 的 plugin\nhttps://github.com/jorgebucaran/gitio.fish\nfisher 是一個 fish 的套件管理工具，我們用它來安裝 fish 版 gitio\nfisher add jorgebucaran/gitio.fish 用這個工具的話可以自定義名稱喔！ 網頁版的 UI 好像就沒有這個選項 QQ\n安裝完成後 gitio key=url 就可以了\ngitio yamcha=https://github.com/XiaoXiaoSN/YamCha # https://git.io/yamcha without fish? 直接自己組 queryString 打過去也是可以的\nexport url=https://github.com/XiaoXiaoSN/YamCha export code=yamcha curl https://git.io/ --data-urlencode \u0026quot;url=$url\u0026quot; --data-urlencode code=\u0026quot;$code\u0026quot; ","id":36,"section":"posts","summary":"介紹 GitHub 在 2018 年推出的短網址服務: git.io 他可以把 GitHub 的網址縮短~ with fish 其實會發現他的原因，是因為在尋找 fish 的 plugin https://github.com/jorgebucaran/gitio.fish fisher 是一個 fish 的套件管理工具，我們用它來安裝 fish","tags":[],"title":"已知用火 - git.io 短網址","uri":"https://blog.10oz.tw/20200831-known-fire-gitio/","year":"2020"},{"content":"環境 我們先用 macOS Catalina 10.15.2 來做筆記喔\n1. 虛擬機 一開始當然是虛擬機啦，讓我們用 vagrant 搭配 virtual box 吧～\n1.1 安裝 vagrant 跟 virtual box brew cask install vagrant vagrant version vagrant 使用版本 2.2.10\n支援的 virtual box 版本沒有到最新的 6， 我們到這邊下載舊版吧\nhttps://www.virtualbox.org/wiki/\n如果 mac 不給你開的話，記得可以到 系統偏好設定 \u0026gt; 安全性與隱私 \u0026gt; 一般 開啟權限\n1.2 設定 vagrant 第一步要先建立一個 Vagrantfile，我們選用 ubuntu 16.04 TLS\n這邊也有更多選擇 \u0026ndash;\u0026gt; https://app.vagrantup.com/boxes/search\n# 先在你喜歡的地方開個資料夾吧 mkdir -p ~/projects/vagrant/k8s-master cd ~/projects/vagrant/k8s-master vim Vagrantfile # -*- mode: ruby -*- # vi: set ft=ruby : Vagrant.configure(2) do |config| # 選用的檔案，xenial 是 ubuntu16 的名字 config.vm.box = \u0026quot;ubuntu/xenial64\u0026quot; # 將虛擬機內部的 6443 port 導出到本機的 26443 port # config.vm.network \u0026quot;forwarded_port\u0026quot;, guest: 6443, host: 26443 config.vm.network \u0026quot;private_network\u0026quot;, ip: \u0026quot;172.16.16.100\u0026quot; # 分配 2GB 的記憶體給虛擬機 config.vm.provider \u0026quot;virtualbox\u0026quot; do |vb| v.name = \u0026quot;k8s-m1\u0026quot; vb.memory = 2048 vb.cpus = 2 end # 設定帳號密碼是 ubuntu:ubuntu config.vm.provision 'shell', inline: \u0026lt;\u0026lt;-SHELL echo 'ubuntu:ubuntu' | sudo chpasswd SHELL end 1.3 用 vagrant 啟動虛擬機 設定好後就開起來連進去吧\nvagrant up vagrant ssh 2. 安裝 kubernetes server 2.1 安裝 container 服務 最重要的，我們要先裝 docker \u0026raquo; 我是指南\n## 進入 super user 模式來安裝 sudo su ## 以下開始安裝 Docker CE ## Set up the repository: ## Install packages to allow apt to use a repository over HTTPS apt-get update -y \u0026amp;\u0026amp; apt-get install -y \\ apt-transport-https ca-certificates curl software-properties-common ## Add Docker’s official GPG key curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add - ## Add Docker apt repository. add-apt-repository \\ \u0026quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\u0026quot; ## Install Docker CE. apt-get update -y \u0026amp;\u0026amp; apt-get install -y \\ containerd.io=1.2.10-3 \\ docker-ce=5:19.03.4~3-0~ubuntu-$(lsb_release -cs) \\ docker-ce-cli=5:19.03.4~3-0~ubuntu-$(lsb_release -cs) ## Setup daemon. cat \u0026gt; /etc/docker/daemon.json \u0026lt;\u0026lt;EOF { \u0026quot;exec-opts\u0026quot;: [\u0026quot;native.cgroupdriver=systemd\u0026quot;], \u0026quot;log-driver\u0026quot;: \u0026quot;json-file\u0026quot;, \u0026quot;log-opts\u0026quot;: { \u0026quot;max-size\u0026quot;: \u0026quot;100m\u0026quot; }, \u0026quot;storage-driver\u0026quot;: \u0026quot;overlay2\u0026quot; } EOF mkdir -p /etc/systemd/system/docker.service.d # Restart docker. systemctl daemon-reload systemctl restart docker # If you want the docker service to start on boot, run the following command: sudo systemctl enable docker 2.2 安裝 kubernetes 我們需要 kubelet、 kubeadm 和 kubectl \u0026raquo; 指南\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y apt-transport-https curl curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - cat \u0026lt;\u0026lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list deb https://apt.kubernetes.io/ kubernetes-xenial main EOF sudo apt-get update sudo apt-get install -y kubelet kubeadm kubectl sudo apt-mark hold kubelet kubeadm kubectl # 禁用 swap swapoff -a; sed -i '/swap/d' /etc/fstab # 更改網路設定 cat \u0026gt;\u0026gt;/etc/sysctl.d/kubernetes.conf\u0026lt;\u0026lt;EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system 2.3 kubernetes master 之 kubeadm 連線回來後記得切換回 super user\nvagrant ssh # 這時候可以看到 hostname 已經變成 k8s-m1 sudo su 這邊簡單選用默認的 Flannel 實作 pod 與 pod 間溝通的介面~\nkubeadm only supports Container Network Interface (CNI) based networks\nkubeadm init \\ --apiserver-advertise-address=172.16.16.100 \\ --pod-network-cidr=172.16.0.0/16 等待個 2~3 分鐘\n成功後會提示你以下訊息！ 就表示成功了\nYour Kubernetes control-plane has initialized successfully! ## 讓 user 可以連線到 k8s cluster To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \u0026quot;kubectl apply -f [podnetwork].yaml\u0026quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ ## 加入 node 到 cluster，複製起來晚點開好其他 node 後要用 Then you can join any number of worker nodes by running the following on each as root: kubeadm join 10.0.2.15:6443 --token 3vex22.6kqkhji310d3ckp0 \\ --discovery-token-ca-cert-hash sha256:cb8bb2fde074ba2a294413122a5a9208479b12a73ec316c01bd9a8b485add2fa 先跑個他提示的訊息，讓 user 可以連線到 cluster\nmkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 2.4 安裝 kubernetes 網路介面 接下來要為我們的 k8s cluster 建立 pod network，他的工作是負責跟 Container 連線，他們各自有實作 CNI( Container Network Interface)，詳細可以來參考Kubernetes網絡模型列表\n這裡我們選擇官方偷偷推薦的 Calico (CentOS 的 Flannel 也很多人用)\nkubectl create -f https://docs.projectcalico.org/v3.14/manifests/calico.yaml 2.5 image 存起來才可以複製好多個 回到本地端 vagrant 的資料夾，把目前的狀態打包起來\n給想要有很多台 master 的你~~\nvagrant package --output k8s-master.box 2.6 讓 master 可以用於部署 在預設情況下，為了安全和穩定性，master node 會被隔離開來，不允許部署 Pod 上去\n但是如果你要做單節點的話~~\nkubectl taint nodes --all node-role.kubernetes.io/master- 3. 安裝 kubernetes worker 3.1 Vagrant 啟動檔案 # -*- mode: ruby -*- # vi: set ft=ruby : Vagrant.configure(2) do |config| NodeCount = 4 (1..NodeCount).each do |i| config.vm.define \u0026quot;k8s-w#{i}\u0026quot; do |node| node.vm.box = \u0026quot;ubuntu/xenial64\u0026quot; node.vm.hostname = \u0026quot;k8s-w#{i}\u0026quot; node.vm.network \u0026quot;private_network\u0026quot;, ip: \u0026quot;172.16.16.10#{i}\u0026quot; node.vm.provider \u0026quot;virtualbox\u0026quot; do |v| v.name = \u0026quot;k8s-w#{i}\u0026quot; v.memory = 2048 v.cpus = 1 end node.vm.provision 'shell', inline: \u0026lt;\u0026lt;-SHELL echo 'ubuntu:ubuntu' | sudo chpasswd SHELL end end end 3.2 安裝步驟 2.1 2.2\nvagrant 開多台vm時，連線回去要加上名字:\nvagrant ssh k8s-w1\n3.3 加入 kubernetes cluster 到 master 機器上拿到加入 cluster 的指令\nkubeadm token create --print-join-command 再回來 worker 機器上，使用 sudo 加入節點後貼上剛才拿到的指令\nsudo su kubeadm join 172.16.16.100:6443 --token 7fz9ob.a6sno93d0zwcz3v9 --discovery-token-ca-cert-hash sha256:cb8bb2fde074ba2a294413122a5a9208479b12a73ec316c01bd9a8b485add2fa 回到 master\nkubectl get nodes 以上 k8s 架設就大功告成了，把 master 的 ~/.kube/config 複製一份回到本地端就可以用 local 端拜訪囉~\nReference https://rickhw.github.io/2019/03/17/Container/Install-K8s-with-Kubeadm/ https://zhuanlan.zhihu.com/p/31398416 https://www.vagrantup.com/docs/providers/virtualbox https://www.youtube.com/watch?v=mMmxMoprxiY 更換 master IP https://github.com/kubernetes/kubeadm/issues/338\n","id":37,"section":"posts","summary":"環境 我們先用 macOS Catalina 10.15.2 來做筆記喔 1. 虛擬機 一開始當然是虛擬機啦，讓我們用 vagrant 搭配 virtual box 吧～ 1.1 安裝 vagrant 跟 virtual box brew cask install vagrant vagrant version vagrant 使用版本 2.2.10 支援的 virtual box 版本沒有到最","tags":["kubernetes","vm","vagrant"],"title":"我們想在虛擬機上跑個 K8s","uri":"https://blog.10oz.tw/20200830-run-kubernetes-on-vm/","year":"2020"},{"content":"問題起源 看看人家，一個 latest 有這麼多種架構的版本 羨慕耶 我也想要編一個給我的樹莓派 執行環境 » docker version Client: Docker Engine - Community Version: 19.03.12 API version: 1.40 Go version: go1.13.10 Git commit: 48a66213fe Built: Mon Jun 22 15:41:33 2020 OS/Arch: darwin/amd64 Experimental: true Server: Docker Engine - Community Engine: Version: 19.03.12 API version: 1.40 (minimum version 1.12) Go version: go1.13.10 Git commit: 48a66213fe Built: Mon Jun 22 15:49:27 2020 OS/Arch: linux/amd64 Experimental: true containerd: Version: v1.2.13 GitCommit: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc: Version: 1.0.0-rc10 GitCommit: dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init: Version: 0.18.0 GitCommit: fec3683 開始正題 (buildx 快速版) 這是實驗性功能~ Mac \u0026amp; Windows 請進，linux 先來這看看 \u0026gt; https://github.com/docker/buildx ，或是下滑懷舊版\n設定環節 首先我們要開啟 docker 實驗功能 vim ~/.docker/config.json 加上 16 行的 experimental: \u0026quot;enabled\u0026quot;\n{ \u0026quot;auths\u0026quot;: { \u0026quot;474872403908.dkr.ecr.us-east-1.amazonaws.com\u0026quot;: {}, \u0026quot;917719776018.dkr.ecr.ap-northeast-1.amazonaws.com\u0026quot;: {}, \u0026quot;https://917719776018.dkr.ecr.ap-northeast-1.amazonaws.com\u0026quot;: {}, \u0026quot;https://index.docker.io/v1/\u0026quot;: {}, \u0026quot;https://registry.tenoz.tw\u0026quot;: {}, \u0026quot;registry.heroku.com\u0026quot;: {}, \u0026quot;registry.tenoz.tw\u0026quot;: {} }, \u0026quot;HttpHeaders\u0026quot;: { \u0026quot;User-Agent\u0026quot;: \u0026quot;Docker-Client/19.03.1 (darwin)\u0026quot; }, \u0026quot;credsStore\u0026quot;: \u0026quot;desktop\u0026quot;, \u0026quot;stackOrchestrator\u0026quot;: \u0026quot;swarm\u0026quot;, \u0026quot;experimental\u0026quot;: \u0026quot;enabled\u0026quot;, \u0026quot;debug\u0026quot;: true } 這樣就可以下指令查看 image 的相關資料 docker manifest inspect --verbose xiao4011/toolbox:latest 再來下個指令看看別人的多架構版 docker manifest inspect --verbose redis:latest 一看不得了，人家是 array 阿！！ 帥吧\n編譯 Image 拿出你的 Dockerfile 在 From 前面加上你要執行的 target 像這樣 --platform=$TARGETPLATFORM\n# Build code FROM --platform=$TARGETPLATFORM golang:alpine as builder ENV GO111MODULE=on WORKDIR /app COPY . . RUN apk add --update git ca-certificates RUN go mod download RUN go build -o app . # pull the binary file and service work really in the layer FROM --platform=$TARGETPLATFORM alpine:latest WORKDIR /srv/application COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/ COPY --from=builder /app/app /srv/application/toolbox COPY --from=builder /app/public /srv/application/public ENTRYPOINT [\u0026quot;./toolbox\u0026quot;] 改好了之後呢 編譯給他跑下去，可以選擇幾個你喜歡的 \u0026ndash;platform 內容來跑\ndocker buildx build \\ --push \\ --platform linux/amd64,linux/arm64,linux/arm/v7,linux/arm/v6 --tag xiao4011/toolbox:latest . 如果不知道你的環境有什麼 platform 可以編譯的話 可以輸入docker buildx inspect --bootstrap 因為我們有加上 --push 所以直接出發到 docker hub 上面看一下狀況 直接完成，484很快～ 開始正題 (懷舊版) 方法是利用 docker manifest 將多個 docker images 整合在一起 因此首先我們要準備編譯多個 images\n編譯 Images 方法1： 指定架構拉取 image 這個方法是建立在別人的 mutli-arch image 上的，用不同架構直接來編譯 # 編譯 amd64 架構 docker build --platform linux/amd64 --pull . -t xiao4011/toolbox:amd64 docker push xiao4011/toolbox:amd64 # 編譯 armv7 架構 docker build --platform linux/arm/v7 --pull . -t xiao4011/toolbox:armv7 docker push xiao4011/toolbox:armv7 方法2： 手動更換編譯平台架構 image 在 Dockerfile 中加入 ARG ARCH 加入一個編譯變數叫做 ARCH 來指定編譯的架構 ARG ARCH FROM $ARCH/golang:alpine as builder // 更多操作 dockerfile... # 執行編譯 export ARCH=arm32v7; docker build --build-arg ARCH=$ARCH . -t xiao4011/toolbox:$ARCH docker push xiao4011/toolbox:$ARCH 包裝 manifest 檔案 發出去~~\ndocker manifest create xiao4011/toolbox:manifest \\ --amend xiao4011/toolbox:amd64 \\ --amend xiao4011/toolbox:armv7 docker manifest push xiao4011/toolbox:manifest 一言不合就 CI/CD (example for buildx) 更新 images 這種事情當然要自動化一下啊！這次跟著 docker 官方介紹第一次認識了 github actions，他是 github 內建的 pipeline 工具 有個有趣的地方是可以插入別人寫的 actions，幾乎每個步驟都有人給你包好了，只要 call function 就對了\n首先我們建立檔案 vim .github/workflows/cicd.yml\n# .github/workflows/cicd.yml name: build our image on: push: branches: - master jobs: build: runs-on: ubuntu-latest steps: - name: install Go uses: actions/setup-go@v1 with: go-version: ${{ matrix.go-version }} - name: check out path uses: actions/checkout@v2 - name: testing run: go test ./... - name: install buildx id: buildx uses: crazy-max/ghaction-docker-buildx@v1 with: version: latest - name: login to docker hub run: echo \u0026quot;${{ secrets.DOCKER_PASSWORD }}\u0026quot; | docker login -u \u0026quot;${{ secrets.DOCKER_USERNAME }}\u0026quot; --password-stdin - name: build the image run: | docker buildx build \\ --push \\ --tag xiao4011/toolbox:latest \\ --platform linux/amd64,linux/arm64,linux/arm/v7,linux/arm/v6 . 接下來要去 github 設定 Secrets，開啟專案頁面後選擇 Setting \u0026gt; Secrets 選擇 New secret 加入 docker 的帳號密碼，等一下 pipeline 在 push image 的時候會使用到\n也可以額外設定除錯模式 ACTIONS_RUNNER_DEBUG=true ACTIONS_STEP_DEBUG=true\nRef https://www.docker.com/blog/multi-arch-build-and-images-the-simple-way/\nhttps://hub.docker.com/r/ckulka/multi-arch-example\nhttps://docs.docker.com/buildx/working-with-buildx/\n","id":38,"section":"posts","summary":"問題起源 看看人家，一個 latest 有這麼多種架構的版本 羨慕耶 我也想要編一個給我的樹莓派 執行環境 » docker version Client: Docker Engine - Community Version: 19.03.12 API version: 1.40 Go version: go1.13.10 Git commit: 48a66213fe Built: Mon Jun 22 15:41:33 2020 OS/Arch: darwin/amd64 Experimental:","tags":["docker","multi-arch","buildx"],"title":"Docker 建立不同架構的 Image","uri":"https://blog.10oz.tw/20200814-docker-mutli-arch-image/","year":"2020"},{"content":"\nCasbin 是什麼 casbin 是一個權限控管的模組，可以定義不同的權限模型來管理使用者的權限，預設包含了很多知名的模型如 RBAC ABAC 他雖然規則複雜但他卻支持許多語言，可以在不同的環境下使用，包含 Go, Java, Node.js, php, python, c#, c++, rust\n所以學學看應該很不錯吧！\nModel, Policy 語法 開啟編輯器的畫面 https://casbin.org/editor/ 實際操作更好了解！\n首先要了解 Model, Policy 是什麼呢?\nPolicy 是規則，裡面寫了一系列的權限像是\n{小明} 可以對 {文件} {查看}\n{小明} 可以對 {程式} {查看}\n{小明} 可以對 {程式} {修改}\nModel 是用來定義 Input 的格式， Policy 的格式， Policy 的使用方法 像是前面 Policy 的寫法就是在這裡來定義\nModel 權限模組 r request_definition 用來表示輸入，例如說 r = sub, obj, act 就有 3 種輸入，分別表示Subject(人) Object(資源) 動作(Action)\np policy_definition 用來表示規則的形狀，等一下在設定 Policy 的時候就要按這這個規則 範例像是 p = sub, act 就可以設定只和人、動作有關的規則 (alice 可以 read) 也可以同時設定第二條 Policy 格式 p2 = sub, act, act2，就可以把更多的資訊納入規則的建立，前提當然你的 r(輸入)要有帶入 act2\ng (role_definition) 也就是 RBAC 裡面的 R(role)，可以想像成是一個群組(group)裡面有很多的人，當你定義該群組有什麼權限，那麼在該群組裡面的人也就同時擁有這些權限。\ne (policy_effect) 定義規則公式的結果，最常見的是 e = some(where (p.eft == allow)) 表示只要有一條 match 結果通過就通過了 !some(where (p.eft == deny)) 表示只要有一條沒有通過，那就不通過 這裡 casbin 還有預設一些函數可以使用，像是用 keyMatch 來比對， * 表示全過，或是進一步的 regexMatch，還有 eval 可以動態的輸入規則 甚至可以自己寫 function 綁定進去，非常有用！可以去官網看看 更多function\nm (matchers) 就是使用前面設定檔來寫規則公式的地方\n來看一個範例模型 ACL (Access Control List) 也就是白名單模式 看到 matchers 很明顯說明了，你的 sub, obj, act 人、物、動作 都要相同才會是 allow\n[request_definition] r = sub, obj, act [policy_definition] p = sub, obj, act [policy_effect] e = some(where (p.eft == allow)) [matchers] m = r.sub == p.sub \u0026amp;\u0026amp; r.obj == p.obj \u0026amp;\u0026amp; r.act == p.act Policy 權限規則 定義好模型之後，還需要資料才可以開始跑，跟上面的 Model 模型可以搭配著看 這裏 Policy 的寫法需符合 model 裡面 p(policy_definition) 的規範\np, alice, data1, read p, bob, data2, write 來看扣 複製了範例的 RBAC 模式，可以在剛剛的 editor 上選擇 RBAC with resource roles 來看看執行結果是否相同\n這邊在看的時候可以先看 policy g 定義的 group，\nalice 是 admin\ndata1 是 data_group\ndata2 是 data_group\n然後 admin 可以 write data_group\n這樣應該相當容易理解了～\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;github.com/casbin/casbin/v2\u0026quot; \u0026quot;github.com/casbin/casbin/v2/model\u0026quot; scas \u0026quot;github.com/qiangmzsx/string-adapter/v2\u0026quot; ) var modelStr = ` [request_definition] r = sub, obj, act [policy_definition] p = sub, obj, act [role_definition] g = _, _ g2 = _, _ [policy_effect] e = some(where (p.eft == allow)) [matchers] m = g(r.sub, p.sub) \u0026amp;\u0026amp; g2(r.obj, p.obj) \u0026amp;\u0026amp; r.act == p.act ` var policyStr = ` p, alice, data1, read p, bob, data2, write p, admin, data_group, write g, alice, admin g2, data1, data_group g2, data2, data_group ` func main() { // 設定 Model 模型 // 參考 https://casbin.org/docs/en/model-storage m, _ := model.NewModelFromString(modelStr) // 設定 Policy 具體規則 // 可以參考 https://casbin.org/docs/en/adapters p := scas.NewAdapter(policyStr) // 建立 Enforcer 需要輸入 Model 和 Policy // casbin 提供很多的 adapter 讓開發者用自己適合的方式填充資料 (file, db, redis, cloud...) // 範例選擇了最方便的直接讀文字 XDD enforcer, _ := casbin.NewEnforcer(m, p) // 實際測試時間: // 在 model [request_definition] 設定了三個變數輸入 sub, obj, act := \u0026quot;alice\u0026quot;, \u0026quot;data2\u0026quot;, \u0026quot;write\u0026quot; result, _ := enforcer.Enforce(sub, obj, act) fmt.Printf(\u0026quot;enforce1: %t\\n\u0026quot;, result) // true sub, obj, act = \u0026quot;alice\u0026quot;, \u0026quot;data2\u0026quot;, \u0026quot;read\u0026quot; result, _ = enforcer.Enforce(sub, obj, act) fmt.Printf(\u0026quot;enforce1: %t\\n\u0026quot;, result) // false (因為 admin 對 data_group 沒有 read) } 再來偷偷推薦每日一庫的 casbin 文章 https://darjun.github.io/2020/06/12/godailylib/casbin/ 裡面提到 ABAC（attribute base access list）模型的用法，相當有趣 需求是這樣的：\n正常工作時間9:00-18:00所有人都可以讀寫data，其他時間只有數據所有者能讀寫。\nModel 如下\n[request_definition] r = sub, obj, act [policy_definition] p = sub, obj, act [matchers] m = r.sub.Hour \u0026gt;= 9 \u0026amp;\u0026amp; r.sub.Hour \u0026lt; 18 || r.sub.Name == r.obj.Owner [policy_effect] e = some(where (p.eft == allow)) 該規則不需要策略文件：\n存進去 SQL 裡面 實際上在使用 casbin 的時候我們不會用字串來寫 model, policy 更多會存在 file 或是 db 裡面，這時候 adapter 就派上用場啦~\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;github.com/casbin/casbin/v2\u0026quot; xormadapter \u0026quot;github.com/casbin/xorm-adapter/v2\u0026quot; _ \u0026quot;github.com/lib/pq\u0026quot; ) func main() { // 初始化 xorm adapter，在這裡與 DB 連線 // 沒有指定 db 的話會幫你建立一個 casbin (加入 dbname=abc 可以指定使用 DB abc) // 進去會幫你檢查有沒有 casbin_rule 的資料表，沒有的話也會幫你加進去 driverName := \u0026quot;postgres\u0026quot; pgUser, pgPassWd := \u0026quot;root\u0026quot;, \u0026quot;root\u0026quot; dataSource := fmt.Sprintf(\u0026quot;user=%s password=%s host=127.0.0.1 port=5432 sslmode=disable\u0026quot;, pgUser, pgPassWd) a, _ := xormadapter.NewAdapter(driverName, dataSource) // Your driver and data source. // 直接讀檔案最快啦 enforcer, _ := casbin.NewEnforcer(\u0026quot;model_rbac.conf\u0026quot;, a) // 第一次跑的話會需要 Policy 資料，讓他幫忙寫進去吧 // enforcer.EnableAutoSave(false) // 關閉自動同步 { // 如果是 enforcer.AddPolicy 的話會幫你填第一個 \u0026quot;p\u0026quot; enforcer.AddNamedPolicy(\u0026quot;p\u0026quot;, \u0026quot;alice\u0026quot;, \u0026quot;data1\u0026quot;, \u0026quot;read\u0026quot;) enforcer.AddNamedPolicy(\u0026quot;p\u0026quot;, \u0026quot;bob\u0026quot;, \u0026quot;data2\u0026quot;, \u0026quot;write\u0026quot;) enforcer.AddNamedPolicy(\u0026quot;p\u0026quot;, \u0026quot;data_group_admin\u0026quot;, \u0026quot;data_group\u0026quot;, \u0026quot;write\u0026quot;) // enforcer.AddGroupingPolicies 的話會幫你填第一個 \u0026quot;g\u0026quot; enforcer.AddNamedGroupingPolicy(\u0026quot;g\u0026quot;, \u0026quot;alice\u0026quot;, \u0026quot;data_group_admin\u0026quot;) enforcer.AddNamedGroupingPolicy(\u0026quot;g2\u0026quot;, \u0026quot;data1\u0026quot;, \u0026quot;data_group\u0026quot;) enforcer.AddNamedGroupingPolicy(\u0026quot;g2\u0026quot;, \u0026quot;data2\u0026quot;, \u0026quot;data_group\u0026quot;) } // Load the policy from DB. enforcer.LoadPolicy() // 實際測試時間: // 在 model [request_definition] 設定了三個變數輸入 sub, obj, act := \u0026quot;alice\u0026quot;, \u0026quot;data2\u0026quot;, \u0026quot;write\u0026quot; result, _ := enforcer.Enforce(sub, obj, act) fmt.Printf(\u0026quot;enforce1: %t\\n\u0026quot;, result) // true sub, obj, act = \u0026quot;alice\u0026quot;, \u0026quot;data2\u0026quot;, \u0026quot;read\u0026quot; result, _ = enforcer.Enforce(sub, obj, act) fmt.Printf(\u0026quot;enforce2: %t\\n\u0026quot;, result) // false (因為 data_group_admin 對 data_group 沒有 read) } Ref https://darjun.github.io/2020/06/12/godailylib/casbin/ https://github.com/casbin/xorm-adapter/tree/v2.0.1 https://casbin.org/docs/en/overview\n","id":39,"section":"posts","summary":"Casbin 是什麼 casbin 是一個權限控管的模組，可以定義不同的權限模型來管理使用者的權限，預設包含了很多知名的模型如 RBAC ABAC 他雖然規則複雜但他卻支持許多語言，可","tags":["golang","casbin"],"title":"Casbin 權限管理模組","uri":"https://blog.10oz.tw/20200813-casbin-the-access-control-model/","year":"2020"},{"content":"不囉唆直接上圖 馬上試試 pokesay\nbrew tap xiaoxiaosn/xiaoxiao brew install pokesay 起源 這個故事是這樣的，有一天發現了一個有趣的 command pokemonsay他是 cowsay 的改編版，它可以讓 pokemon 出現說你想要他說的話 XDD\n我用得很快樂的時候發現一件事很不快樂，當一行太多字的時候會換行\n你看！都擠在一起了 R\n這時我想到 cowsay 應該有這個功能才對呀！ 查詢了之後發現 在 pokemonsay 裡面 -n 被用在 Do not tell the pokémon name. 也就是最底下不要 show pokemon 的名字\nQQ 我不依，我自己改!\n介紹 Homebrew 首先先介紹一下 homebrew 這個軟體～ 他是 MacOS 上的套件管理工具，是 mac 最重要的必裝軟體之一\nbrew 這個字是釀造的意思，homebrew 在家釀造也就是自釀的意思 tap 第三方套件的倉庫，就相當於是 apt 的 ppa 一樣的角色 formula 公式、配方，上面寫著軟體安裝的步驟，也就是釀製(brew)的方法 cellar 酒窖存放釀好的酒，預設存在 /usr/local/Cellar，每個資料夾裡面也存有不同的版本，當 brew switch 某個套件版本的時候就是把 /usr/local/bin 的 link 指過去 補充: brew cask 用來安裝 macOS apps 也就是可以直接在應用程式裡面看到的圖像化軟體，像是 Chrome, Firefox, 360Safe 之類的\n了解完基本架構後，我們知道目標就是製作自己的 tap 好讓 brew 可以安裝我們釋出的第三方套件\n開始釀酒 我們分成兩個部分來完成，一個是我們的應用程式另一個是 homebrew 的安裝腳本\n程式本身 只要任何一個可以執行的命令都行，所以先不著墨於此 範例會用下面這個 repo，已經把我想要的 -n 指令加回來啦～～ https://github.com/XiaoXiaoSN/pokesay\nFormula 安裝指南 本文的重點來啦! 首先我們要到 github 上開一個新專案，命名叫做 homebrew-{your-tap-name}，例如我的 homebrew-xiaoxiao\n進入專案底下新增 Formula 資料夾，在底下新增你的 formula\n# Formula/pokesay.rb # 定義 Pokesay 繼承 Formula class Pokesay \u0026lt; Formula desc '\u0026quot;pokesay\u0026quot; is like \u0026quot;cowsay\u0026quot; but for pokémon.' homepage \u0026quot;https://github.com/XiaoXiaoSN/pokesay\u0026quot; # url 說明要去哪裡下載專案 # https://github.com/{username}/{repo}/{format}/{tag or branch} # format 我們都寫 tarball # tag or branch 就看你喜歡用哪個囉 url \u0026quot;https://github.com/XiaoXiaoSN/pokesay/tarball/v1.0.1\u0026quot; # sha256 用來確認你上面說的檔案身份，等等下面會說怎麼長出來 sha256 \u0026quot;43511be3dbb52b380bf7501e3b06a0a17ee0349d0246601537481ca811753a4a\u0026quot; # 版本號 version \u0026quot;v1.0.1\u0026quot; # depends_on 定義安裝你的東西前，會用到的依賴套件 depends_on \u0026quot;cowsay\u0026quot; =\u0026gt; :recommended depends_on \u0026quot;coreutils\u0026quot; =\u0026gt; [:recommended, \u0026quot;with-default-names\u0026quot;] if not OS.linux? # 定義安裝步驟 def install system \u0026quot;cp\u0026quot;, \u0026quot;-r\u0026quot;, \u0026quot;./cows\u0026quot;, \u0026quot;#{prefix}/cows\u0026quot; system \u0026quot;cp\u0026quot;, \u0026quot;pokemonsay.sh\u0026quot;, \u0026quot;pokesay\u0026quot; # 字串取代，讓 pokesay 在本地也可以找得到參考檔案 inreplace \u0026quot;pokesay\u0026quot;, /^pokemon_path=.*$/, \u0026quot;pokemon_path=#{prefix}/cows\u0026quot; # 把 pokesay 複製到這個 formula 的目錄 (/usr/local/Cellar/{pkg}/0.1/bin) # 並設定成可執行檔案 (chmod 0555 foo) bin.install \u0026quot;pokesay\u0026quot; end # 安裝完成後的驗證測試，這邊偷懶沒寫 XD test do system \u0026quot;false\u0026quot; end end 如何產生 sha256\n# 用 curl 下載壓縮檔下來， -L 跟隨跳轉 -o 儲存輸出到檔案 curl -L https://github.com/XiaoXiaoSN/pokesay/tarball/v1.0.1 -o pokesay.tar.gz # 計算 sha256 雜湊值 shasum -a 256 pokesay.tar.gz brew edit brew edit 會叫出你安裝時下載的 Formula，讓你可以編輯再重新安裝\n也可以藉機偷偷參考別人的 Formula 是如何編寫的～～\nbrew edit wget # 會使用預設編輯器開啟 Ref homebrew 故事 https://www.onejar99.com/mac-homebrew-homebrew-cask-mac/ Formula-Cookbook https://docs.brew.sh/Formula-Cookbook\n","id":40,"section":"posts","summary":"不囉唆直接上圖 馬上試試 pokesay brew tap xiaoxiaosn/xiaoxiao brew install pokesay 起源 這個故事是這樣的，有一天發現了一個有趣的 command pokemonsay他是 cowsay 的改編版，它可以讓 pokemon 出現說你想要","tags":["homebrew","ruby","pokesay","pokemon"],"title":"Homebrew 自己寫配方一起來釀酒","uri":"https://blog.10oz.tw/20200811-homebrew-create-app/","year":"2020"},{"content":"步驟說明時間 確認 Windows 版本 首先按一下 Windows 鍵輸入 winver 來確認目前版本，版本必須是 19041 或是 2004 才可以喔 如果版本不夠的話，更新器下載 \u0026raquo; https://www.microsoft.com/en-us/software-download/windows10\n開啟環境設定 用系統管理員身分開啟 PowerShell 後，輸入指令開啟 Linux Subsystem 的支援和 HyperV 的虛擬機器平台 用 HyperV 要記得到 BIOS 開啟虛擬機器的支援喔\ndism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 這時候你需要重啟一下電腦~\n然後要更新 linux subsystem kernel https://docs.microsoft.com/nl-nl/windows/wsl/wsl2-kernel\n安裝 Linux 發行版 按一下 Windows 鍵輸入 Microsoft Store 後開啟商店選擇你要的 Linux 版本，在這裡我選擇 Ubuntu1804 另外偷偷下載了 windows terminal，有比較漂亮R 看一看 WSL2 的設定 更新完後開啟 PowerShell 將 WSL 預設版本改為 2\nwsl --set-default-version 2 可以用 wsl -l 來列出你的 Linux 們，把原本存在的 WSL 升級成 WSL2\nwsl --set-version Ubuntu-18.04 2 輸入 wsl -l -v 應該可以看見 Version 2，那這樣就對啦~ Docker Time 首先在 Win10 下載桌面版 Docker， https://docs.docker.com/docker-for-windows/wsl/\n下載好了嗎? 打開來選擇 WSL2 作為 backend 安裝好之後他會請你重新登入你的 Win10， 完成後選擇 Settings(上方的小齒輪) \u0026gt; General 來確認一下 Use the WSL2 based engine 選項 再來到 Resources \u0026gt; WSL Integartion，把你的 WSL linux 發行版選起來 點右下角的 Apply \u0026amp; Restart\n開啟你的 terminal，輸入 wsl -d \u0026lt;你的系統\u0026gt; 進入 WSL 的系統內 輸入 docker ps 確認有抓到 docker ~ 開個服務吧\n-d 在背景執行 -p port 導出 --name 幫 container 取名字 docker run -d -p 8080:80 --name docker_time docker/getting-started 看看你的 http://localhost:8080 服務開起來囉 測試完 docker 可以工作了，所以刪掉\ndocker kill docker_time 任性的個人化時間 # 更新一下 sudo apt update \u0026amp;\u0026amp; sudo apt upgrade -y # git 設定 git config --global core.ignorecase false git config --global alias.co 'checkout' git config --global alias.chekcout 'checkout' git config --global alias.log1 'log --oneline -n 10' git config --global alias.logg 'log --oneline --graph' git config --global alias.cm 'commit -m' git config --global alias.cmamend '!git add $1 \u0026amp;\u0026amp; git commit --amend --no-edit' # shell 設定 sudo apt install fish -y curl -L https://get.oh-my.fish | fish omf install godfather # 開專案資料夾 mkdir projects ln -s (pwd)/projects ~/projects Golang 環境 (gvm) 不囉嗦直接抄 \u0026raquo; https://blog.miniasp.com/post/2020/07/27/Build-Golang-Dev-Box-in-Windows?utm_source=Facebook_PicSee\nsudo apt install binutils bison gcc make build-essential -y curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer | bash -E source ~/.gvm/scripts/gvm set GOVER go1.14 gvm install go1.14 --binary gvm use go1.14 --default # 確認我們的工作~~ go version 紀錄一點問題 [time=Sat, Aug 8, 2020 1:07 PM]\n開啟工作管理員時發現，有一個叫做 vmmem 的佔用了很多的 memory 和 CPU 發現很多人都有這樣的問題，紀錄一下解決方法 移駕到 c:\\users\\{{your profile name}} 開啟或新增 .wslconfig\n{%gist lewcianci/d09ef5e6741fe0eff61935d39e9667ee %}\n使用系統管理員身分開啟 PowerShell\nRestart-Service LxssManager 參考文章\nMicroK8s Time (請勿參考) 直接遇到問題了，snapd 是不可用的狀態 sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -yqq daemonize dbus-user-session fontconfig sudo daemonize /usr/bin/unshare --fork --pid --mount-proc /lib/systemd/systemd --system-unit=basic.target exec sudo nsenter -t $(pidof systemd) -a su - $LOGNAME snap version 還需要開啟 Systemd 把這一段貼上去後關掉視窗重開\n## /etc/profile.d/00-wsl2-systemd.sh # Create the starting script for SystemD SYSTEMD_PID=$(ps -ef | grep '/lib/systemd/systemd --system-unit=basic.target$' | grep -v unshare | awk '{print $2}') if [ -z \u0026quot;$SYSTEMD_PID\u0026quot; ]; then sudo /usr/bin/daemonize /usr/bin/unshare --fork --pid --mount-proc /lib/systemd/systemd --system-unit=basic.target SYSTEMD_PID=$(ps -ef | grep '/lib/systemd/systemd --system-unit=basic.target$' | grep -v unshare | awk '{print $2}') fi if [ -n \u0026quot;$SYSTEMD_PID\u0026quot; ] \u0026amp;\u0026amp; [ \u0026quot;$SYSTEMD_PID\u0026quot; != \u0026quot;1\u0026quot; ]; then exec sudo /usr/bin/nsenter -t $SYSTEMD_PID -a su - $LOGNAME fi 好，問題解決來安裝吧\n# 安裝 microk8s sudo snap install microk8s --classic # 嘗試一下指令，他會提醒你要給權限照著做吧~記得要把 user 換掉喔 microk8s.status sudo usermod -a -G microk8s arios sudo chown -f -R arios ~/.kube 完成後離開重新登入，就可以開始開服務囉\nmicrok8s.enable dns dashboard for Win10 2004 你各位阿~!這個中文輸入阿，很不ok阿 當輸入中文的時候需要切換成英文就會爆炸?\n往右下角的 中/A 點一下右鍵 一般 \u0026gt; 輸入設定 \u0026gt; \u0026ldquo;自動將中文模式中的按鍵順序切換為英數字元\u0026rdquo; 開起來 恩~是稍微好點了，不過這個選項也有毛病\u0026hellip;\u0026hellip; 你一按錯注音他給你改成英文阿QQ 哪個比較困擾需要個人評估了\nRef https://docs.microsoft.com/zh-tw/windows/wsl/install-win10\nhttps://pureinfotech.com/install-windows-subsystem-linux-2-windows-10/\nhttps://blog.miniasp.com/post/2020/07/26/Multiple-Linux-Dev-Environment-build-on-WSL-2\nhttps://docs.docker.com/docker-for-windows/wsl/\nhttps://github.com/microsoft/WSL/issues/5126#issuecomment-653715201\nhttps://wsl.dev/wsl2-microk8s\n","id":41,"section":"posts","summary":"步驟說明時間 確認 Windows 版本 首先按一下 Windows 鍵輸入 winver 來確認目前版本，版本必須是 19041 或是 2004 才可以喔 如果版本不夠的話，更新器下載 \u0026raquo; https://www.microsoft.com/en-us/software-download/windows10 開啟環境設定 用系統管理員","tags":["wsl2","windows"],"title":"出發尋找 WSL2 的旅程","uri":"https://blog.10oz.tw/20200728-journey-in-wsl2/","year":"2020"},{"content":"偶爾在 debug 的時候，看到的都是一整行實在不太快樂呀！\n我需要排版！！趕快筆記一下\n一、我有一個 struct stack overflow 上有重點！！ func prettyPrint(data interface{}) { jsonByte, err := json.MarshalIndent(data, \u0026quot;\u0026quot;, \u0026quot; \u0026quot;) if err != nil { fmt.Println(\u0026quot;\u0026quot;) } fmt.Printf(\u0026quot;%s\\n\u0026quot;, jsonByte) } 二、我有一個 json byte func prettyPrintByte(jsonByte []byte) { var buf bytes.Buffer err := json.Indent(\u0026amp;buf, jsonByte, \u0026quot;\u0026quot;, \u0026quot; \u0026quot;) if err == nil { jsonByte = buf.Bytes() } fmt.Printf(\u0026quot;%s\\n\u0026quot;, jsonByte) } 參考 https://stackoverflow.com/questions/19038598/how-can-i-pretty-print-json-using-go/42426889\n","id":42,"section":"posts","summary":"偶爾在 debug 的時候，看到的都是一整行實在不太快樂呀！ 我需要排版！！趕快筆記一下 一、我有一個 struct stack overflow 上有重點！！ func prettyPrint(data interface{}) { jsonByte, err := json.MarshalIndent(data, \u0026quot;\u0026quot;, \u0026quot; \u0026quot;) if err != nil { fmt.Println(\u0026quot;\u0026quot;) }","tags":["golang","json","pretty"],"title":"Golang 漂亮的輸出 JSON","uri":"https://blog.10oz.tw/20200229-golang-pretty-print/","year":"2020"},{"content":"json 格式簡單易讀，經常出現在各種 API、設定檔裡，golang 也有內建處理的 package，寫扣的時候也會經常遇到他喔，來筆記一下！ 內文會分成常用處理json、自定義處理 json和多層處理 三個 part， GOGO\n一、常用方法 package main import ( \u0026quot;encoding/json\u0026quot; \u0026quot;fmt\u0026quot; ) // Box 是個箱子 type Box struct { Name string `json:\u0026quot;name\u0026quot;` Color string `json:\u0026quot;color\u0026quot;` } func main() { jsonStr := ` { \u0026quot;name\u0026quot;: \u0026quot;喵喵\u0026quot;, \u0026quot;color\u0026quot;: \u0026quot;blue\u0026quot; }` box := new(Box) // 把 bytes 寫進去 Box 物件裡面 _ = json.Unmarshal([]byte(jsonStr), box) fmt.Printf(\u0026quot;%+v\\n\u0026quot;, box) // {Name:喵喵 Color:blue} // 再把物件寫回去 binary json box.Color = \u0026quot;黃色的\u0026quot; byteJSON, _ := json.Marshal(box) fmt.Printf(\u0026quot;%s\\n\u0026quot;, string(byteJSON)) // {\u0026quot;name\u0026quot;:\u0026quot;喵喵\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;黃色的\u0026quot;} } 二、更多方法 當我傻傻的以為，json 就這麼結束了的時候\n燈愣！！ 還有兩個 interface 可以實作\n// Unmarshaler is the interface implemented by types // that can unmarshal a JSON description of themselves. // The input can be assumed to be a valid encoding of // a JSON value. UnmarshalJSON must copy the JSON data // if it wishes to retain the data after returning. // // By convention, to approximate the behavior of Unmarshal itself, // Unmarshalers implement UnmarshalJSON([]byte(\u0026quot;null\u0026quot;)) as a no-op. type Unmarshaler interface { UnmarshalJSON([]byte) error } // Marshaler is the interface implemented by types that // can marshal themselves into valid JSON. type Marshaler interface { MarshalJSON() ([]byte, error) } 當你傳進去的物件有實作了這兩個 function 時，他會改用物件自己的方法 看看下面的範例他已經完全地掌握了 json.Marshal 的輸出啦\n// Box 是個箱子 type Box struct { Name string `json:\u0026quot;name\u0026quot;` Color string `json:\u0026quot;color\u0026quot;` } // UnmarshalJSON 實作箱子的 json.Unmarshaler func (b *Box) UnmarshalJSON(byteData []byte) (err error) { // 臨時變數，不直接用 Box 物件，會遞迴 type _box Box newBox := \u0026amp;struct{ *_box }{ _box: (*_box)(b), } newBox.Color = \u0026quot;會被蓋掉\u0026quot; return json.Unmarshal(byteData, newBox) } // MarshalJSON 實作箱子的 json.Marshaler func (b *Box) MarshalJSON() (byteData []byte, err error) { // 臨時變數，不直接用 Box 物件，會遞迴 type _box Box newBox := \u0026amp;struct{ *_box }{ _box: (*_box)(b), } newBox.Name = b.Name + \u0026quot;~~⭐️\u0026quot; return json.Marshal(newBox) } func main() { jsonStr := ` { \u0026quot;name\u0026quot;: \u0026quot;喵喵\u0026quot;, \u0026quot;color\u0026quot;: \u0026quot;blue\u0026quot; }` box := new(Box) _ = json.Unmarshal([]byte(jsonStr), box) fmt.Printf(\u0026quot;%+v\\n\u0026quot;, box) // \u0026amp;{Name:喵喵 Color:你只能是黑色} box.Color = \u0026quot;黃色的\u0026quot; byteJSON, _ := json.Marshal(box) fmt.Printf(\u0026quot;%s\\n\u0026quot;, string(byteJSON)) // {\u0026quot;name\u0026quot;:\u0026quot;喵喵~~⭐️\u0026quot;,\u0026quot;color\u0026quot;:\u0026quot;黃色的\u0026quot;} } 三、多層的方法 再來就是混合表演啦，要根據不同的格式回傳不同的 struct 類型\n例子是箱子裡面還可以再裝箱子，還可以裝各種不同的箱子～\npackage main import ( \u0026quot;encoding/json\u0026quot; \u0026quot;errors\u0026quot; \u0026quot;fmt\u0026quot; ) type iBox interface{} // Box 是個箱子 type Box struct { Type string `json:\u0026quot;type\u0026quot;` Name string `json:\u0026quot;name\u0026quot;` Color string `json:\u0026quot;color\u0026quot;` Box iBox `json:\u0026quot;box,omitempty\u0026quot;` } // UnmarshalJSON 實作箱子的 json.Unmarshaler func (b *Box) UnmarshalJSON(byteData []byte) (err error) { // 臨時變數，不要直接用 Box 物件，會遞迴 type _box Box newBox := \u0026amp;struct{ *_box }{ _box: (*_box)(b), } err = json.Unmarshal(byteData, \u0026amp;newBox) if err != nil { return } // 上面處理完了其他變數，再來依照 newBox 的 type 來\u0008包裝裡面的 box if newBox.Box != nil { switch newBox.Type { case \u0026quot;box\u0026quot;: innerBox := \u0026amp;struct { InnerBox Box `json:\u0026quot;box\u0026quot;` }{} err = json.Unmarshal(byteData, \u0026amp;innerBox) if err != nil { return } newBox.Box = innerBox.InnerBox case \u0026quot;xbox\u0026quot;: innerBox := \u0026amp;struct { InnerBox xBox `json:\u0026quot;box\u0026quot;` }{} err = json.Unmarshal(byteData, \u0026amp;innerBox) if err != nil { return } newBox.Box = innerBox.InnerBox } } return } // xBox 是特別的箱子 type xBox struct { Type string `json:\u0026quot;type\u0026quot;` Name string `json:\u0026quot;xName\u0026quot;` Foo string `json:\u0026quot;foo\u0026quot;` Box iBox `json:\u0026quot;box,omitempty\u0026quot;` } // UnmarshalJSON 實作 x箱子的 json.Unmarshaler func (b *xBox) UnmarshalJSON(byteData []byte) (err error) { type _box xBox newBox := \u0026amp;struct{ *_box }{ _box: (*_box)(b), } err = json.Unmarshal(byteData, \u0026amp;newBox) if err != nil { return } if newBox.Box != nil { switch newBox.Type { case \u0026quot;box\u0026quot;: innerBox := \u0026amp;struct { InnerBox Box `json:\u0026quot;box\u0026quot;` }{} err = json.Unmarshal(byteData, \u0026amp;innerBox) if err != nil { return } newBox.Box = innerBox.InnerBox case \u0026quot;xbox\u0026quot;: innerBox := \u0026amp;struct { InnerBox xBox `json:\u0026quot;box\u0026quot;` }{} err = json.Unmarshal(byteData, \u0026amp;innerBox) if err != nil { return } newBox.Box = innerBox.InnerBox } } return } func getInnerBox(boxType string, byteData []byte) (iBox, error) { switch boxType { case \u0026quot;box\u0026quot;: innerBox := \u0026amp;struct { InnerBox Box `json:\u0026quot;box\u0026quot;` }{} err := json.Unmarshal(byteData, \u0026amp;innerBox) if err != nil { return nil, err } return innerBox.InnerBox, nil case \u0026quot;xbox\u0026quot;: innerBox := \u0026amp;struct { InnerBox xBox `json:\u0026quot;box\u0026quot;` }{} err := json.Unmarshal(byteData, \u0026amp;innerBox) if err != nil { return nil, err } return innerBox.InnerBox, nil } return nil, errors.New(\u0026quot;unknown type of box\u0026quot;) } func main() { jsonStr := ` { \u0026quot;type\u0026quot;: \u0026quot;box\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;喵喵\u0026quot;, \u0026quot;color\u0026quot;: \u0026quot;藍色\u0026quot;, \u0026quot;box\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;xbox\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;裡面的\u0026quot;, \u0026quot;foo\u0026quot;: \u0026quot;bar\u0026quot;, \u0026quot;box\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;box\u0026quot;, \u0026quot;color\u0026quot;: \u0026quot;更裡面的\u0026quot;, \u0026quot;box\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;box\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;最裡面\u0026quot; } } } }` box := new(Box) _ = json.Unmarshal([]byte(jsonStr), box) // 然後你可以這樣! // layer 1 全部 fmt.Printf(\u0026quot;layer 1:\\n%#v\\n\\n\u0026quot;, box) // layer 2 \u0026quot;name=喵喵\u0026quot; fmt.Printf(\u0026quot;layer 2:\\n%#v\\n\\n\u0026quot;, box.Box.(Box)) // layer 3 \u0026quot;name=裡面的\u0026quot; fmt.Printf(\u0026quot;layer 3:\\n%#v\\n\\n\u0026quot;, box.Box.(Box).Box.(xBox)) // layer 4 \u0026quot;name=\u0026quot;更裡面的\u0026quot; fmt.Printf(\u0026quot;layer 4:\\n%#v\\n\\n\u0026quot;, box.Box.(Box).Box.(xBox).Box) // layer 5 \u0026quot;name=最裡面\u0026quot; 這層沒有 box，所以是 nil fmt.Printf(\u0026quot;layer 5:\\n%#v\\n\\n\u0026quot;, box.Box.(Box).Box.(xBox).Box.(Box).Box) } 也可以把重複的部份抽出來，不然豈不是每次新增新的 box 時都要改以前的 code？\n// UnmarshalJSON 實作 x箱子的 json.Unmarshaler func (b *xBox) UnmarshalJSON(byteData []byte) (err error) { type _box xBox newBox := \u0026amp;struct{ *_box }{ _box: (*_box)(b), } err = json.Unmarshal(byteData, \u0026amp;newBox) if err != nil { return } // 上面處理完了其他變數，再來依照 newBox 的 type 來\u0008包裝裡面的 box if newBox.Box != nil { newBox.Box, err = getInnerBox(newBox.Type, byteData) if err != nil { return } } return } func getInnerBox(boxType string, byteData []byte) (iBox, error) { switch boxType { case \u0026quot;box\u0026quot;: innerBox := \u0026amp;struct { InnerBox Box `json:\u0026quot;box\u0026quot;` }{} err := json.Unmarshal(byteData, \u0026amp;innerBox) if err != nil { return nil, err } return innerBox.InnerBox, nil case \u0026quot;xbox\u0026quot;: innerBox := \u0026amp;struct { InnerBox xBox `json:\u0026quot;box\u0026quot;` }{} err := json.Unmarshal(byteData, \u0026amp;innerBox) if err != nil { return nil, err } return innerBox.InnerBox, nil } return nil, errors.New(\u0026quot;unknown type of box\u0026quot;) } 結論 原本傻傻的不會用 Unmarshaler Marshaler，很難去做到多層的實作，現在會惹QQ\n參考資料 https://medium.com/@xfstart07/go-json-%E7%9A%84%E7%BC%96%E7%A0%81%E5%92%8C%E8%A7%A3%E7%A0%81-e689522a1f1f\nhttps://github.com/line/line-bot-sdk-go/blob/362880a2e613ce24eb32e1b72cd345370578b6df/linebot/flex_unmarshal.go#L23\n","id":43,"section":"posts","summary":"json 格式簡單易讀，經常出現在各種 API、設定檔裡，golang 也有內建處理的 package，寫扣的時候也會經常遇到他喔，來筆記一下！ 內文會分成","tags":["golang","json"],"title":"Golang 怎麼處理 JSON","uri":"https://blog.10oz.tw/20200228-golang-json-marshal/","year":"2020"},{"content":"步驟教學 一、開始之前 目標是用 hugo 協助我們使用 markdown 輕鬆製造靜態網頁，再把這個靜態網頁利用 Github Page 部署出去！\n所以我們需要:\n一人份的 github 帳號 安裝 hugo 點我看教學 挑選喜歡的 hugo 模板 點我參觀 $ hugo version Hugo Static Site Generator v0.62.2/extended darwin/amd64 BuildDate: unknown 二、開跑囉 開啟一個新的 hugo 專案，這邊的 xiaoxiao 可以換成你喜歡的專案名字\n$ hugo new site xiaoxiao $ cd xiaoxiao 會看到目錄長這樣:\n├── archetypes │ └── default.md # 產生新文章時的模板 ├── config.toml # 最主要的設定檔案 ├── content # Markdown 的文章在這邊 ├── data ├── layouts ├── resources │ └── _gen ├── static └── themes # 套用的主題包們 └── hugo-theme-m10c 接著挑選一個漂亮的 hugo 模板來下載，我用人家教學示範的模板\n$ git clone https://github.com/vaga/hugo-theme-m10c.git themes/hugo-theme-m10c 再來，開啟文字編輯器修改 config.toml， 最主要是第六行的 theme 和第四行的 publishDir = \u0026quot;docs\u0026quot;，docs 是 GithubPage 規定的喔不能改\n我的改完長這樣:\nbaseURL = \u0026quot;https://xiaoxiaosn.github.io\u0026quot; languageCode = \u0026quot;en-us\u0026quot; title = \u0026quot;XiaoXiao Notes\u0026quot; publishDir = \u0026quot;docs\u0026quot; theme = \u0026quot;hugo-theme-m10c\u0026quot; paginate = 10 [params] author = \u0026quot;Xiao Xiao\u0026quot; description = \u0026quot;XiaoXiao 的筆記書\u0026quot; 跑跑看，是不是能看到頁面啦? 服務會在 http://localhost:1313\n$ hugo server -D # -D 表示我們想看到草稿文章(draft) 看到有安捏就對了! 三、來寫文章r 這邊的 make-a-hugo-blog 可以換成你想要的文章名字，等等會被用在網址上喔\n$ hugo new make-a-hugo-blog 這個指令會幫你在 content 目錄下新增一個 make-a-hugo-blog.md 檔案， 接著我們寫點內容上去，像這樣: 要注意的是 draft: true 這行在正式上線的時候記得刪掉喔~\n--- title: \u0026quot;製造一個 hugo 部落格\u0026quot; date: 2020-01-24T23:02:16+08:00 tags: [\u0026quot;hugo\u0026quot;] --- ## 開始之前 目標是用 hugo 協助我們使用 markdown 輕鬆製造靜態網頁，再把這個靜態網頁利用 Github Page 部署出去！ 所以我們需要: 1. 一人份的 github 帳號 2. 安裝 hugo [點我看教學](https://gohugo.io/getting-started/installing#quick-install) 3. 挑選喜歡的 hugo 模板 [點我參觀](https://themes.gohugo.io/tags/blog/) 輸入 hugo 指令，讓他跑編譯囉\n$ hugo 四、來部署r 打開你的 github 按下 new 來新增一個 repo\n接下來會進到這個畫面，先不急著跟他操作 我們要先到 config.toml 修改域名 這邊的規則是 https://帳號.github.io/專案\n# 修改 config.toml 的這一行 baseURL = \u0026quot;https://xiaoxiaosn.github.io/XiaoXiaoBlog\u0026quot; 然後下指令重新產生一下\n$ hugo 回到專案，是時候該讓 git 加入了 第二行這邊記得換成你自己的 github 專案喔\n$ git init $ git remote add origin git@github.com:XiaoXiaoSN/XiaoXiaoBlog.git $ git add --all $ git commit -m \u0026quot;init my hugo blog\u0026quot; $ git push origin master 在 add 的時候出現 warn 不擔心，他只是提醒你在這個 git 專案下還有包含了另一個 git 專案 (theme裡面那個) 更新上去後，我們回到 github，選擇 Setting 後往下拉找到 Github Page\n選那個 master branch /docs folder\n五、收割囉~~ 等待 10 秒，然後帶著一顆誠摯的新把連結給按下去 XD https://帳號.github.io/專案\n選修 - 使用自己的 domain 回到前面部署時候的頁面，Setting 往下滑到 GitHub Pages 填寫 Custom domain 的這個欄位\n這裡我已經有 domain，然後是交給 cloudflare 管理，因此接下來會以此介紹 開啟 cloudflare 選到 DNS 後，設定 CNAME 把你的網址導引到 githubPage 接下來到 Page Rules 新增一筆強制使用 https 的選項 這樣就設定好囉～ 記得要回到專案的 config.toml 設定新的 url 喔\nbaseURL = \u0026quot;https://blog.10oz.tw\u0026quot; 補充設定 md 換行格式 由於很多人從 hackmd 或是其他的平台轉過來 發現他們原來的 md 貼過來換行符號沒有被保留在 html 上，也就是兩行連起來啦\n[blackfriday] extensions = [\u0026quot;hardLineBreak\u0026quot;] References hugo\nhttps://gohugo.io/documentation/ https://siddharam.com.tw/post/20190418/ github page\nhttps://gohugo.io/hosting-and-deployment/hosting-on-github/#deployment-of-project-pages-from-docs-folder-on-master-branch https://blog.cloudflare.com/secure-and-fast-github-pages-with-cloudflare/ ","id":44,"section":"posts","summary":"步驟教學 一、開始之前 目標是用 hugo 協助我們使用 markdown 輕鬆製造靜態網頁，再把這個靜態網頁利用 Github Page 部署出去！ 所以我們需要: 一人份的 github 帳號 安裝 hugo 點我看教學","tags":["hugo"],"title":"製造一個 hugo 部落格","uri":"https://blog.10oz.tw/20200124-make-a-hugo-blog/","year":"2020"},{"content":" ** 2019.08 更新** https://www.php.net/manual/en/mongodb.installation.homebrew.php mac php72 請使用 pecl install mongodb 安裝 mongodb driver 因為 mongodb, xdebug 從 homebrew 被移除了\n[time=Thu, Aug 15, 2019 7:59 PM]\n問題描述 想在 Laravel 用 MongoDB\ncomposer require jenssegers/mongodb 錯誤：\nthe requested PHP extension mongodb is missing from your system. =\u0026gt; 沒有裝 php 的擴展\n解決方案 先來個悲劇， homebrew 拿掉 php-mongodb 的擴展了QQ\n只好去裝人家的，我的 php 版本是 7.1 所以裝 php71-mongodb 忘記版本的話可以用 php --version 查看\nbrew tap kyslik/php brew install phpxx-mongodb {xx = 71,72} 裝完惹！ 但是當我輸入 php -i 檢查的時候 dyld: Library not loaded: /usr/local/opt/readline/lib/libreadline.7.dylib\n哎呀QQ 來去 Google 看看\nln -s /usr/local/opt/readline/lib/libreadline.8.0.dylib /usr/local/opt/readline/lib/libreadline.7.dylib 之後可以輸入來檢查有沒有成功\n» php -m | grep mongodb mongodb link 我手上有的版本過去之後，一切順利呢！！\ncomposer require jenssegers/mongodb 後記 - 小踩雷 要是php -i | grep mongodb什麼都沒有的話可能是當初在安裝php的時候沒有安裝完全\n移除php重裝一次 然後 brew link phpxx 你的 /usr/local/有可能會沒有sbin這個資料夾所以就mkdir sbin他 然後成功連結他應該就可以惹 ※小秘訣：你可以跑 brew doctor 叫醫生幫你診斷～ 跑起來遇到\nSymfony\\Component\\Debug\\Exception\\FatalThrowableError : Call to a member function prepare() on null 可以把原本 extend 的 Model 換成 \\Jenssegers\\Mongodb\\Eloquent\\Model\n","id":45,"section":"posts","summary":"** 2019.08 更新** https://www.php.net/manual/en/mongodb.installation.homebrew.php mac php72 請使用 pecl install mongodb 安裝 mongodb driver 因為 mongodb, xdebug 從 homebrew 被移除了 [time=Thu, Aug 15, 2019 7:59 PM] 問題描述 想在 Laravel 用 MongoDB composer require jenssegers/mongodb 錯誤： the requested PHP extension mongodb is missing from your system. =\u0026gt; 沒有裝 php 的擴展 解決","tags":["php","laravel","mongodb"],"title":"筆記 Install php MongoDB driver on MacOS","uri":"https://blog.10oz.tw/20190815-install-php-mongodb-driver-on-macos/","year":"2019"},{"content":" @elasticsearch version 6.8\nSTRUCTURE 可以這樣想像\nRelational DB -\u0026gt; Databases -\u0026gt; Tables -\u0026gt; Rows -\u0026gt; Columns\nElasticsearch -\u0026gt; Indices -\u0026gt; Types -\u0026gt; Documents -\u0026gt; Fields\n不過啊，type 要被人家丟掉了（現在是限制只能有一個 type，等同於這層沒意義）\nIndices created in 6.x only allow a single-type per index. 6.x 後建議 type 使用 _doc，\n然後 8.x: Specifying types in requests is no longer supported.\n我發現我發現 看一眼 reindex 就很清楚他改了什麼了喔！\nPOST _reindex { \u0026quot;source\u0026quot;: { \u0026quot;index\u0026quot;: \u0026quot;twitter\u0026quot; }, \u0026quot;dest\u0026quot;: { \u0026quot;index\u0026quot;: \u0026quot;new_twitter\u0026quot; }, \u0026quot;script\u0026quot;: { \u0026quot;source\u0026quot;: \u0026quot;\u0026quot;\u0026quot; ctx._source.type = ctx._type; ctx._id = ctx._type + '-' + ctx._id; ctx._type = '_doc'; \u0026quot;\u0026quot;\u0026quot; } } 這是一個新增範例，依照 /Index/Type/ID 新增一筆 Document\nPUT /employee/_doc/1 { \u0026quot;first_name\u0026quot; : \u0026quot;John\u0026quot;, \u0026quot;last_name\u0026quot; : \u0026quot;Smith\u0026quot;, \u0026quot;age\u0026quot; : 25, \u0026quot;about\u0026quot; : \u0026quot;I love to go rock climbing\u0026quot;, \u0026quot;interests\u0026quot;: [\u0026quot;sports\u0026quot;, \u0026quot;music\u0026quot;] } USAGE 列出所有 index\nGET /_cat/indices?v 所有在 index 中的 type\nGET /_mapping?pretty=true Search - ES DSL Query DSL(Domain Specific Language)\n架構介紹 來自這邊\nGET /_search { \u0026quot;query\u0026quot;: { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ { \u0026quot;match\u0026quot;: { \u0026quot;title\u0026quot;: \u0026quot;Search\u0026quot; }}, { \u0026quot;match\u0026quot;: { \u0026quot;content\u0026quot;: \u0026quot;Elasticsearch\u0026quot; }} ], \u0026quot;filter\u0026quot;: [ { \u0026quot;term\u0026quot;: { \u0026quot;status\u0026quot;: \u0026quot;published\u0026quot; }}, { \u0026quot;range\u0026quot;: { \u0026quot;publish_date\u0026quot;: { \u0026quot;gte\u0026quot;: \u0026quot;2015-01-01\u0026quot; }}} ] } } } 在 bool 裡面， must match 表示檢索的評分項目\n而 filter 中的兩個 term 和 range 表示過濾條件，不會影響到評分\n由 index 來搜尋\nGET users/_search { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: { } } } 多個 index 搜尋是這樣的 GET /kimchy,elasticsearch/_search?q=tag:wow MatchAll GET /_search { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} } } match_none 是他的相反\nRollover Index 可參考 文件。當檔案大時，可以利用 rollover index 來分檔案，並且利用 alias 統一搜尋\nPUT /logs-000001 { \u0026quot;aliases\u0026quot;: { \u0026quot;logs_write\u0026quot;: {} } } # Add \u0026gt; 1000 documents to logs-000001 POST /logs_write/_rollover { \u0026quot;conditions\u0026quot;: { \u0026quot;max_age\u0026quot;: \u0026quot;7d\u0026quot;, \u0026quot;max_docs\u0026quot;: 1000, \u0026quot;max_size\u0026quot;: \u0026quot;5gb\u0026quot; } } 也可以使用日期來做\n# PUT /\u0026lt;logs-{now/d}-1\u0026gt; with URI encoding: PUT /%3Clogs-%7Bnow%2Fd%7D-1%3E { \u0026quot;aliases\u0026quot;: { \u0026quot;logs_write\u0026quot;: {} } } Mapping Mapping 可以設定這個 Index 裡面的 Fields 的 type\nref\n如果你是 7.x 記得看到 _doc 就給它拿掉\nPUT twitter {} PUT twitter/_mapping/_doc { \u0026quot;properties\u0026quot;: { \u0026quot;email\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; } } } GET /twitter/_mapping/_doc ILM (Index Lifecycle Management) rollover 的條件是當你 call API 的時候才會檢查，也就是說他不會自動生效 而 ILM 的功能就是讓 elasticsearch 排程幫你做 rollover\n先開一個 policy PUT _ilm/policy/mylogs_policy { \u0026quot;policy\u0026quot;: { \u0026quot;phases\u0026quot;: { \u0026quot;hot\u0026quot;: { \u0026quot;actions\u0026quot;: { \u0026quot;rollover\u0026quot;: { \u0026quot;max_docs\u0026quot;: \u0026quot;4\u0026quot;, \u0026quot;max_age\u0026quot;: \u0026quot;30d\u0026quot;, \u0026quot;max_size\u0026quot;: \u0026quot;5gb\u0026quot; } } } } } } 開一個 template 綁定這個 policy PUT /_template/mylogs_template { \u0026quot;index_patterns\u0026quot;: [\u0026quot;mylogs-*\u0026quot;], \u0026quot;settings\u0026quot;: { \u0026quot;number_of_shards\u0026quot;: 1, \u0026quot;number_of_replicas\u0026quot;: 1, \u0026quot;index.lifecycle.name\u0026quot;: \u0026quot;mylogs_policy\u0026quot;, \u0026quot;index.lifecycle.rollover_alias\u0026quot;: \u0026quot;mylogs\u0026quot; } } 建立 alias # PUT /\u0026lt;mylogs-000001\u0026gt; PUT %3Cmylogs-000001%3E { \u0026quot;aliases\u0026quot;:{ \u0026quot;mylogs\u0026quot;: { \u0026quot;is_write_index\u0026quot;:true } } } 當這個 alias 會被用於寫入時，要將 is_write_index 設定成 true，同時間 is_write_index=true 只會有一筆\n一直打資料進去 mylogs，他會依照上面的設定 rollover 可透過別名查詢所有 index\nPOST /prod_vpn_event/_refresh GET /prod_vpn_event/_search { \u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} } } REFERENCE https://es.xiaoleilu.com https://www.elastic.co/guide/en/elasticsearch/reference/6.8/query-dsl.html ILM https://elasticsearch.cn/article/6358\n","id":46,"section":"posts","summary":"@elasticsearch version 6.8 STRUCTURE 可以這樣想像 Relational DB -\u0026gt; Databases -\u0026gt; Tables -\u0026gt; Rows -\u0026gt; Columns Elasticsearch -\u0026gt; Indices -\u0026gt; Types -\u0026gt; Documents -\u0026gt; Fields 不過啊，type 要被人家丟掉了（現在是限制只能有一個 type，等同於這層沒意義） Indices","tags":["es","elasticsearch","ilm"],"title":"Learning Elasticsearch","uri":"https://blog.10oz.tw/20190814-learning-elasticsearch/","year":"2019"},{"content":" laravel version: 5.8 [time=Wed, Jul 3, 2019 1:27 PM]\n開始之前 test 的設定檔在 ./phpunit.xml ，\n\u0026lt;!-- phpunit.xml --\u0026gt; \u0026lt;phpunit\u0026gt; \u0026lt;php\u0026gt; \u0026lt;!-- laravel 環境設定檔案使用 .emv.testing --\u0026gt; \u0026lt;server name=\u0026quot;APP_ENV\u0026quot; value=\u0026quot;testing\u0026quot;/\u0026gt; \u0026lt;!-- 測試環境的資料庫連線設定，我們將使用 sqlite --\u0026gt; \u0026lt;server name=\u0026quot;DB_CONNECTION\u0026quot; value=\u0026quot;sqlite_for_testing\u0026quot;/\u0026gt; \u0026lt;env name=\u0026quot;DB_DATABASE\u0026quot; value=\u0026quot;:memory:\u0026quot;/\u0026gt; \u0026lt;/php\u0026gt; \u0026lt;/phpunit\u0026gt; php 也要加在 Config/dataset.php\n/* Config/dataset.php */ \u0026lt;?php 'connections' =\u0026gt; [ // ...other db connection configuration // 為了方便測試，使用 memory sqlite 做為我們的資料庫 'sqlite_for_testing' =\u0026gt; [ 'driver' =\u0026gt; 'sqlite', 'database' =\u0026gt; ':memory:', 'prefix' =\u0026gt; '', 'foreign_key_constraints' =\u0026gt; true, ], ] 確認好設定後，我們執行起來\n# -v 代表 --verbose 顯示更詳細的資訊 ./vendor/bin/phpunit -v --debug 寫個測試來跑跑 最近要重構一個 function，覺得裡面的邏輯有點複雜，決定先寫個測試再來開工\n這次的目標是 app/Http/Services/ScheduleService.php 裡面的 checkScheduleAvailable 這個 function\n所以我們先來準備測試檔案:\nphp artisan make:test Schedule/availableTest --unit 產生了一個 tests/Unit/Schedule/availableTest.php ，來看看裡面有什麼吧\n\u0026lt;?php // test 開頭的 function 會被測試 public function testExample() { // assertTrue 指定結果要是 true, // 因為 (true === true) ，所以我們將會通過測試 $this-\u0026gt;assertTrue(true); } 製造假資料 為了測試 function 能夠順利回傳，總要給點資料才能測吧?\n\u0026lt;?php class availableTest extends TestCase { // 資料庫每次用完要復原，才不會讓測試資料一直留在資料庫中 use RefreshDatabase; public function testQueryUnAvailable(): void { // inject some fake data into database factory(User::class)-\u0026gt;create(); factory(Project::class)-\u0026gt;create(); factory(Pole::class, 5)-\u0026gt;create(); $ad = factory(Ad::class)-\u0026gt;make([ 'ad_status_id' =\u0026gt; 4, // ad_status_id: 4 is depolyed 'ad_types_id' =\u0026gt; 1, // ad_types_id: 1 is slideshow ]); factory(Ad::class)-\u0026gt;create($ad-\u0026gt;toArray()); // 測試一波，資料是不是有好好的塞進資料庫了 $this-\u0026gt;assertCount(5, Pole::all()); $this-\u0026gt;assertDatabaseHas('ads', [ 'ad_status_id' =\u0026gt; 4, 'ad_types_id' =\u0026gt; 1, ]); } } Ref https://blog.goodjack.tw/2018/07/laravel-phpunit.html https://gist.github.com/jaceju/c415c1b42daf4c589f2a https://laravel.com/docs/5.8/database-testing\n","id":47,"section":"posts","summary":"laravel version: 5.8 [time=Wed, Jul 3, 2019 1:27 PM] 開始之前 test 的設定檔在 ./phpunit.xml ， \u0026lt;!-- phpunit.xml --\u0026gt; \u0026lt;phpunit\u0026gt; \u0026lt;php\u0026gt; \u0026lt;!-- laravel 環境設定檔案使用 .emv.testing --\u0026gt; \u0026lt;server name=\u0026quot;APP_ENV\u0026quot; value=\u0026quot;testing\u0026quot;/\u0026gt; \u0026lt;!-- 測試環境的資料庫連線設定，我們將使用 sqlite --\u0026gt; \u0026lt;server name=\u0026quot;DB_CONNECTION\u0026quot; value=\u0026quot;sqlite_for_testing\u0026quot;/\u0026gt; \u0026lt;env name=\u0026quot;DB_DATABASE\u0026quot; value=\u0026quot;:memory:\u0026quot;/\u0026gt; \u0026lt;/php\u0026gt; \u0026lt;/phpunit\u0026gt;","tags":["php","laravel","test"],"title":"筆記 laravel test - 我們也來寫測試","uri":"https://blog.10oz.tw/20190703-laravel-testing/","year":"2019"},{"content":" Laravel 5.8\n$kernel = $app-\u0026gt;make(Illuminate\\Contracts\\Console\\Kernel::class); $output = new Symfony\\Component\\Console\\Output\\ConsoleOutput; $output-\u0026gt;getFormatter() -\u0026gt;setStyle('error', new \\Symfony\\Component\\Console\\Formatter\\OutputFormatterStyle('yellow')); $status = $kernel-\u0026gt;handle( $input = new Symfony\\Component\\Console\\Input\\ArgvInput, $output ); 修改的話在 line:37 可以帶三種參數\npublic function __construct( string $foreground = null, string $background = null, array $options = []){ /****/ } 三種參數可以參考\nprivate static $availableForegroundColors = [ 'black' =\u0026gt; ['set' =\u0026gt; 30, 'unset' =\u0026gt; 39], 'red' =\u0026gt; ['set' =\u0026gt; 31, 'unset' =\u0026gt; 39], 'green' =\u0026gt; ['set' =\u0026gt; 32, 'unset' =\u0026gt; 39], 'yellow' =\u0026gt; ['set' =\u0026gt; 33, 'unset' =\u0026gt; 39], 'blue' =\u0026gt; ['set' =\u0026gt; 34, 'unset' =\u0026gt; 39], 'magenta' =\u0026gt; ['set' =\u0026gt; 35, 'unset' =\u0026gt; 39], 'cyan' =\u0026gt; ['set' =\u0026gt; 36, 'unset' =\u0026gt; 39], 'white' =\u0026gt; ['set' =\u0026gt; 37, 'unset' =\u0026gt; 39], 'default' =\u0026gt; ['set' =\u0026gt; 39, 'unset' =\u0026gt; 39], ]; private static $availableBackgroundColors = [ 'black' =\u0026gt; ['set' =\u0026gt; 40, 'unset' =\u0026gt; 49], 'red' =\u0026gt; ['set' =\u0026gt; 41, 'unset' =\u0026gt; 49], 'green' =\u0026gt; ['set' =\u0026gt; 42, 'unset' =\u0026gt; 49], 'yellow' =\u0026gt; ['set' =\u0026gt; 43, 'unset' =\u0026gt; 49], 'blue' =\u0026gt; ['set' =\u0026gt; 44, 'unset' =\u0026gt; 49], 'magenta' =\u0026gt; ['set' =\u0026gt; 45, 'unset' =\u0026gt; 49], 'cyan' =\u0026gt; ['set' =\u0026gt; 46, 'unset' =\u0026gt; 49], 'white' =\u0026gt; ['set' =\u0026gt; 47, 'unset' =\u0026gt; 49], 'default' =\u0026gt; ['set' =\u0026gt; 49, 'unset' =\u0026gt; 49], ]; private static $availableOptions = [ 'bold' =\u0026gt; ['set' =\u0026gt; 1, 'unset' =\u0026gt; 22], 'underscore' =\u0026gt; ['set' =\u0026gt; 4, 'unset' =\u0026gt; 24], 'blink' =\u0026gt; ['set' =\u0026gt; 5, 'unset' =\u0026gt; 25], 'reverse' =\u0026gt; ['set' =\u0026gt; 7, 'unset' =\u0026gt; 27], 'conceal' =\u0026gt; ['set' =\u0026gt; 8, 'unset' =\u0026gt; 28], ]; ","id":48,"section":"posts","summary":"Laravel 5.8 $kernel = $app-\u0026gt;make(Illuminate\\Contracts\\Console\\Kernel::class); $output = new Symfony\\Component\\Console\\Output\\ConsoleOutput; $output-\u0026gt;getFormatter() -\u0026gt;setStyle('error', new \\Symfony\\Component\\Console\\Formatter\\OutputFormatterStyle('yellow')); $status = $kernel-\u0026gt;handle( $input = new Symfony\\Component\\Console\\Input\\ArgvInput, $output ); 修改的話在 line:37 可以帶三種參數 public function __construct( string $foreground = null, string $background = null, array $options = []){ /****/ } 三種參數可以參考 private static $availableForegroundColors = [ 'black' =\u0026gt; ['set' =\u0026gt; 30,","tags":["php","laravel","artisan"],"title":"筆記 artisan 的大紅色好刺眼啊啊啊啊","uri":"https://blog.10oz.tw/20190523-laravel-artisan-change-color-style/","year":"2019"},{"content":" 從 golang 1.13 release(2019/09/03) 後，gomodule 變成預設，大家都用官方的 gomodule 了喔 在這之前的版本使用環境變數 GOMODULE111=true 來做管理\n安裝 golang (on Mac) 1. 第一步當然是拿到 golnag 囉 brew install go 2. 環境設定 試著在 terminal 輸入 go env，能夠拿到 golang 用到的環境變數 特別注意一下幾個環境變數\nGOROOT: 是你 golang 執行環境住的地方 GOPATH: 是你的 golang 程式 和 用到的套件們所住的地方 GOBIN: 因為 golang 是編譯式的語言，他可以把相依套件事先build 好，製作成 .a 的二進位檔，存在 GOBIN 裡面 # create GOPATH dir mkdir $HOME/gocode 永久設定~~ 如果你的 shell 是 bash 的話 (預設) 開啟編輯器修改 $HOME/.bashrc 檔案，bash 在登入後會做上面的事情\n# edit $HOME/.bashrc vim $HOME/.bashrc 按下 G 到最底部後 i 進入編輯模式，把環境變數設定貼上去\nexport GOPATH=$HOME/gocode export GOBIN=$GOPATH/bin export PATH=$PATH:$GOBIN 按下esc退出編輯模式，輸入:wq存檔並離開\nor you are using fish vim ~/.config/fish/config.fish\n# GOLANG configurations set -x GOPATH $HOME/gocode set -x GOBIN $GOPATH/bin set -x GOROOT /usr/local/opt/go/libexec set PATH $GOPATH/bin $GOROOT/bin $PATH 重新再開一個小黑窗跑一下新的設定， 再一次 go env 看看幾個參數有沒有不同吧\n3. 下載專案 在下載前，有些事情是我們要知道的 Golang 的資料夾下有 src pkg bin 三個目錄\nsrc: 當你找相依套件時，會來拜訪這裡 pkg: 編譯好的 go 檔案(*.a)，使用相依套件時，可以直接取用 bin: 裡面是編譯好的二進位檔案（golang工具）們 先設定 ssh 下載我們的 repo，而不是 https\ngit config --global url.\u0026quot;git+ssh://git@gitlab.tenoz.tw/\u0026quot;.insteadOf \u0026quot;https://repo.tenoz.tw/\u0026quot; go get repo.tenoz.tw/leotek/pelipper 趕快來確認一下，是不是成功下載回來了呢？\ncd $GOPATH/src/repo.tenoz.tw/leotek/pelipper 4. 套件管理工具 go modules 推薦用這個\n先來看看 go modules 介紹) 吧\ngo vendor 前置任務：下載 govendor\ngo get -u github.com/kardianos/govendor 好，回來看一下\npelipper 這個專案就是用 govendor 來對他的套件做管理\n看一下 vendor/vendor.json 裡面寫了他使用的套件和版本\n一個指令下載相依套件\ngovendor sync 跑跑看~~\ngo build ./pelipper 雖然跑起來了， 不過他可能會跟你說他需要設定檔喔\n附錄、還有其他管理工具 這裡有詳細資訊\ndep 官方推薦的管理包，不過有要被人家取代掉的趨勢\nGo Modules 94J個，窩看好ni啦 \u0026raquo; 介紹\n參考資料 https://github.com/golang/go/wiki/PackageManagementTools https://ieevee.com/tech/2017/07/10/go-import.html\n","id":49,"section":"posts","summary":"從 golang 1.13 release(2019/09/03) 後，gomodule 變成預設，大家都用官方的 gomodule 了喔 在這之前的版本使用環境變數 GOMODULE111=true 來做管理 安裝 golang (on Mac) 1. 第一步當然是拿到 golnag 囉 brew install go 2. 環境設","tags":["golang"],"title":"筆記 安裝 Golang 與他們的套件管理工具","uri":"https://blog.10oz.tw/20190501-golang-getting-start-and-package-manager/","year":"2019"},{"content":"簡介 Golang 官方在 1.11 版推出的相依套件管理工具，還是在測試階段(會在1.13正式登場) 他在 2018/3/20 提交，並於 2018/5/21 被接受 想使用他的話，要開個開關： 環境變數 GO111MODULE 控制行為：\noff: go command 不使用 modules 功能，而是沿用舊有的 GOPATH 模式 on: 強制使用 modules 功能，只根據 go.mod 下載 dependency 而完全忽略 GOPATH 以及 vendor 目錄 auto: Golang 1.11 預設值，go command 根據當前工作目錄狀態決定是否啟用 modules 功能，滿足任一條件時才啟動此功能: 當前目錄位於 GOPATH/src 之外並且包含 go.mod 文件 當前目錄位於包含 go.mod 文件的目錄下 因此，我們的第一步就是開啟他\nexport GO111MODULE=on 來吧，新專案 mkdir goModTest cd goModTest main.go // at goModTest/main.go package main import ( \u0026quot;net/http\u0026quot; \u0026quot;github.com/gin-gonic/gin\u0026quot; ) func main() { router := gin.Default() router.GET(\u0026quot;/health\u0026quot;, GetHealthHandler) s := \u0026amp;http.Server{ Addr: \u0026quot;:8000\u0026quot;, Handler: router, } s.ListenAndServe() } // GetHealthHandler - GET /health to expose service health func GetHealthHandler(c *gin.Context) { c.JSON(http.StatusOK, gin.H{ \u0026quot;code\u0026quot;: 0, \u0026quot;message\u0026quot;: \u0026quot;Service is alive!\u0026quot;, }) } 我們在 main.go 裡面用了 gin 這個 web framework\ngo mod init # 產生 go.mod go build # 編譯時會去下載缺少的相依套件 執行完後發現 go.mod 中多了幾個相依套件 還多了一個 go.sum， 他就像是其他語言的 .lock 一樣，是用來記錄安裝的版本\ntidy 自動幫你檢查你的程式碼中使用到的外部引用， 幫你加入你需要的也幫你移除你用不到的\ngo mod tidy Vendor 預設的情況下，go mod 幫你把相依套件下載到 $GOPATH 不過你希望有放在專案目錄下的話\u0026hellip;\ngo mod tidy # 先做個整理，才不會多下載 go mod vendor import local package 可以直接 import 專案下的模組，go.mod 知道你目前的位置在 goModTest 也就是寫在 go.mod 的第一行 module goModTest\n// 程式裡面這樣引用自己專案的package import dataapi \u0026quot;goModTest/pkg/myapi\u0026quot; Reference 官方連結 https://github.com/golang/go/wiki/Modules 你看人家 Drone 也用了 https://github.com/drone/drone https://www.lightblue.asia/golang-1-11-new-festures-modules https://www.lightblue.asia/go-modules-with-insecure-git/\n","id":50,"section":"posts","summary":"簡介 Golang 官方在 1.11 版推出的相依套件管理工具，還是在測試階段(會在1.13正式登場) 他在 2018/3/20 提交，並於 2018/5/21 被接受 想使用他的話，要開個開關： 環境變數 GO111MODULE 控","tags":["golang","gomod"],"title":"筆記 我是個 go module 的菜鳥","uri":"https://blog.10oz.tw/20190501-a-new-in-go-module/","year":"2019"},{"content":" laravel version: 5.8\n一、安裝篇 裝這個，跟著他的步驟做 https://github.com/robsontenorio/laravel-keycloak-guard\n二、使用篇 我們假設 Keycloak Server 有大大幫你開好了 (沒有請點我)\n取得 Keycloak 金鑰 https://auth.leotekiot.com 預設帳號: admin 預設密碼: Pa55w0rd\n登入後，依序操作得到金鑰 Realm Setting \u0026gt; Keys \u0026gt; RS256 Public key 放到 laravel 的 .env 設定中\nKEYCLOAK_REALM_PUBLIC_KEY=你的公開金鑰 登入 Keycloak Clients \u0026gt; {{ 選個Client }} \u0026gt; Credentials Secret 那邊就是我們的 Client Secret 了 User \u0026gt; View all users \u0026gt; {{ 選個User }} 或是你要新創一個也可以， 總之要記得你的帳號密碼喔\n移駕到 Postman 來嘗試登入 用這個 API 取得 token， auth_realm 填上現在使用的 Realm 預設是 Master\n/auth/realms/{{auth_realm}}/protocol/openid-connect/token 需要的參數前面有介紹過了，按照圖片填滿它吧！\n送出就有 AccessToken 了 應用他!! 複製剛才的 access_token 貼到那個需要登入的 API 裡面 Authorization \u0026gt; Type: Bearer Token \u0026gt; 成功登入～\n三、檢查權限篇 // import Auth use Illuminate\\Support\\Facades\\Auth; // 解析 JWT 並取得 token $tokenString = Auth::token(); return [ 'token' =\u0026gt; json_decode($tokenString) ]; // 從 token 來檢查權限(角色) $Role = 'admin'; $isAdmin = Auth::hasRole($CLIENT, $Role); ","id":51,"section":"posts","summary":"laravel version: 5.8 一、安裝篇 裝這個，跟著他的步驟做 https://github.com/robsontenorio/laravel-keycloak-guard 二、使用篇 我們假設 Keycloak Server 有大大幫你開好了 (沒有請點我) 取得 Keycloak 金鑰 https://auth.leotekiot.com 預設帳號: admin 預設密碼: Pa55w0rd 登入後，依序","tags":["php","laravel","keycloak","oauth"],"title":"筆記 Laravel with Keycloak","uri":"https://blog.10oz.tw/20190424-laravel-with-keycloak/","year":"2019"},{"content":" 版本 Larael 5.7\n範例模型 accounts\nCREATE TABLE `accounts` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `website_id` int(10) unsigned NOT NULL, `account` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL, `password` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL, `name` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL, `created_at` timestamp NULL DEFAULT NULL, `updated_at` timestamp NULL DEFAULT NULL, `deleted_at` timestamp NULL DEFAULT NULL, PRIMARY KEY (`id`) ); websites\nCREATE TABLE `websites` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL, `created_at` timestamp NULL DEFAULT NULL, `updated_at` timestamp NULL DEFAULT NULL, PRIMARY KEY (`id`) ) accounts table 底下有個 column website_id 用來關聯 websites 這張表。\n正片開始 - Model Account 是一個 Model，跟 websites 屬於多對一的關係 一個 website 底下可以有很多 account\n方案一、加入參數 $with 在 Account.php 中\u0026hellip;\n// Account.php Account Model // will call getWebsiteAttribute and append to the model object protected $with = ['website']; public function website() { return $this-\u0026gt;belongsTo('App\\Website'); // 等於 $this-\u0026gt;belongsTo('App\\Website', 'website_id', 'id'); } public function getWebsiteAttribute() { return $this-\u0026gt;website()-\u0026gt;first(); } 他會自動幫你找到 $with 內的 relation\n輸出看起來像這樣，多了 website\n{ \u0026quot;id\u0026quot;: 1, \u0026quot;website_id\u0026quot;: 1, \u0026quot;account\u0026quot;: \u0026quot;ditto\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;niguai.tenoz.1006\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;meow\u0026quot;, \u0026quot;created_at\u0026quot;: \u0026quot;2019-01-28 06:58:44\u0026quot;, \u0026quot;updated_at\u0026quot;: \u0026quot;2019-01-28 06:58:44\u0026quot;, \u0026quot;website\u0026quot;: { \u0026quot;id\u0026quot;: 1, \u0026quot;name\u0026quot;: \u0026quot;meo.tw\u0026quot;, \u0026quot;created_at\u0026quot;: null, \u0026quot;updated_at\u0026quot;: null } } 方案二、 加入參數 $appends 只是把 $with 換成 $appends，可以達到一樣的效果\n// Account.php Account Model // will call getWebsiteAttribute and append to the model object protected $appends = ['website']; public function website() { return $this-\u0026gt;belongsTo('App\\Website'); } public function getWebsiteAttribute() { return $this-\u0026gt;website()-\u0026gt;first(); } 不過為什麼要重複做這樣的功能呢? 我認為 appends 跟 $with 的使用時機不同！ $with 更用在 關聯另外的資料表 時 $appends 則是可以用於加入其他資訊，像是:\n// Account.php Account Model protected $appends = ['uniqName']; public function getUniqNameAttribute() { return \u0026quot;{$this-\u0026gt;name}#{$this-\u0026gt;id}\u0026quot;; } 輸出看起來像這樣，多了 uniqName\n{ \u0026quot;id\u0026quot;: 1, \u0026quot;website_id\u0026quot;: 1, \u0026quot;account\u0026quot;: \u0026quot;ditto\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;niguai.tenoz.1006\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;meow\u0026quot;, \u0026quot;created_at\u0026quot;: \u0026quot;2019-01-28 06:58:44\u0026quot;, \u0026quot;updated_at\u0026quot;: \u0026quot;2019-01-28 06:58:44\u0026quot;, \u0026quot;uniqName\u0026quot;: \u0026quot;meow#1\u0026quot;, \u0026quot;website\u0026quot;: { \u0026quot;id\u0026quot;: 1, \u0026quot;name\u0026quot;: \u0026quot;meo.tw\u0026quot;, \u0026quot;created_at\u0026quot;: null, \u0026quot;updated_at\u0026quot;: null } } :::info 小Hint: belongsTo 這個 function 會幫你猜你 relate 的 key column name， 他用的是你呼叫他的那個 function name\n因此， function website() 中的 belongsTo 可以省略掉後面兩個參數 :::\n","id":52,"section":"posts","summary":"版本 Larael 5.7 範例模型 accounts CREATE TABLE `accounts` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `website_id` int(10) unsigned NOT NULL, `account` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL, `password` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL, `name` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL, `created_at` timestamp NULL DEFAULT NULL, `updated_at` timestamp NULL DEFAULT NULL, `deleted_at` timestamp NULL DEFAULT NULL, PRIMARY KEY (`id`) ); websites CREATE TABLE `websites` ( `id` int(10) unsigned NOT","tags":["php","laravel","eloquent","orm"],"title":"筆記 Laravel Eloquent Model 的 relation","uri":"https://blog.10oz.tw/20190416-relation-of-laravel-eloquent-model/","year":"2019"},{"content":"使用 JWT 版本 (2018/09 更新) 前面幾個步驟同官方安裝教學\n步驟說明 1. composer 載回來 composer require laravel/passport\n2. 開資料表 php artisan migrate 然後你會多 5 張表 (主要使用到 oauth_access_token)\n3.創造 key php artisan passport:install\n他會幫你的 OAuth Server 準備一對 Key (storage/oauth-private.key, storage/outhpublic.key)\n同時也準備 2 個 Client Key 在 oauth_clients 資料表內\nPersonal access client created successfully. Client ID: 1 Client Secret: ETOhMRq7faRSnb1jN2F168jlbYFcf25MOHj0cOxt Password grant client created successfully. Client ID: 2 Client Secret: fibc50RiIjAiYSLR7xceQyoxQE3oGWtIXpCLj9Co 4. 附加 passport 至 auth 系統 在 app\\User.php 新增 Laravel\\Passport\\HasApiTokens line:5,11 \u0026lt;?php namespace App; use Laravel\\Passport\\HasApiTokens; use Illuminate\\Notifications\\Notifiable; use Illuminate\\Foundation\\Auth\\User as Authenticatable; class User extends Authenticatable { use HasApiTokens, Notifiable; // ... 在 app/Providers/AuthServiceProvider.php 新增 passport 的 route (我們 jwt 版本可以不用) line:29 \u0026lt;?php namespace App\\Providers; use Laravel\\Passport\\Passport; use Illuminate\\Support\\Facades\\Gate; use Illuminate\\Foundation\\Support\\Providers\\AuthServiceProvider as ServiceProvider; class AuthServiceProvider extends ServiceProvider { /** * The policy mappings for the application. * * @var array */ protected $policies = [ 'App\\Model' =\u0026gt; 'App\\Policies\\ModelPolicy', ]; /** * Register any authentication / authorization services. * * @return void */ public function boot() { $this-\u0026gt;registerPolicies(); Passport::routes(); // set when access tokens expire Passport::tokensExpireIn(now()-\u0026gt;addDays(15)); } } 在 config/auth.php\n修改 guard 使用 passport 'guards' =\u0026gt; [ 'web' =\u0026gt; [ 'driver' =\u0026gt; 'session', 'provider' =\u0026gt; 'users', ], 'api' =\u0026gt; [ 'driver' =\u0026gt; 'passport', 'provider' =\u0026gt; 'users', ], ], 修改 app/Http/Kernel.php\n加進 web middleware 中 (此步驟 JWT 才需要) 'web' =\u0026gt; [ // Other middleware... \\Laravel\\Passport\\Http\\Middleware\\CreateFreshApiToken::class, ], 5. 修改登入步驟 當我們登入成功的時候，回傳加密過的 jwt\n在 app/Http/Controllers/Auth/LoginController.php override 掉 authenticated function\n當登入成功的時候會進入這個function\ncreateToken 第一個參數是 token的名稱 第二個是權限領域(Scopes)，建立後可以在oauth_xxx 資料表中確認\n/** * The user has been authenticated. * Do not use the origin response of success login with 302, create access token * and return json format * * @param Request $request * @param User $user * @return \\Illuminate\\Http\\JsonResponse|\\Symfony\\Component\\HttpFoundation\\Response * @throws \\Illuminate\\Validation\\ValidationException */ protected function authenticated(Request $request, $user) { if (!is_null($user)) { // create persionalAccessToken for authrizate API $token = $user-\u0026gt;createToken('access_token', ['guard', 'employee'])-\u0026gt;accessToken ?: ''; return response()-\u0026gt;json([ 'access_token' =\u0026gt; $token ], 200); } // throw error return $this-\u0026gt;sendFailedLoginResponse($request); } // 加入 scope middleware\n// 在 app/Http/Kernel.php 裡面的 $routeMiddleware\nscopes 是你指定的 scope 們都要通過 (AND)\nscope 則是你指定的 scope 們其中之一通過 (OR)\n可以挑需要用的(我是兩種都加進去了啦)\n'scopes' =\u0026gt; \\Laravel\\Passport\\Http\\Middleware\\CheckScopes::class, 'scope' =\u0026gt; \\Laravel\\Passport\\Http\\Middleware\\CheckForAnyScope::class, 回到 app/Providers/AuthServiceProvider.php 我們可以在這裡設定 scpoe 們 line:35 \u0026lt;?php namespace App\\Providers; use Laravel\\Passport\\Passport; use Illuminate\\Support\\Facades\\Gate; use Illuminate\\Foundation\\Support\\Providers\\AuthServiceProvider as ServiceProvider; class AuthServiceProvider extends ServiceProvider { /** * The policy mappings for the application. * * @var array */ protected $policies = [ 'App\\Model' =\u0026gt; 'App\\Policies\\ModelPolicy', ]; /** * Register any authentication / authorization services. * * @return void */ public function boot() { $this-\u0026gt;registerPolicies(); // set when access tokens expire Passport::tokensExpireIn(now()-\u0026gt;addDays(15)); // set when refresh tokens expire Passport::refreshTokensExpireIn(now()-\u0026gt;addDays(30)); Passport::tokensCan([ 'admin' =\u0026gt; 'system admin', 'guard' =\u0026gt; 'a good guy', 'employee' =\u0026gt; 'just a poor engineer' ]); } } 6. 裝備上去 在 routes/api.php 加上 middleware auth 並指定 guard 是 api 這樣有加上 middleware 的 API 們， 沒有 token 就進不去囉！\nRoute::apiResource('report', 'API\\ReportController') -\u0026gt;middleware('auth:api')-\u0026gt;middleware('scope:employee,guard'); Route::post('/report/multi_assign', 'API\\ReportController@assignReports') -\u0026gt;middleware('auth:api')-\u0026gt;middleware('scope:guard'); 7. 前端接收 在這裡我將token存在local storage裡面\n為了接收內容，所以將 make:auth產生的模板修改成 vue component 了\n範例使用 ajax 做登入\naxios.post('/login', { 'email': this.email, 'password': this.password }) .then(res =\u0026gt; { window.localStorage.setItem('accessToken', res.data.access_token) window.location.href = this.redirect_to }) .catch(err =\u0026gt; { console.error('login failed') // 處理回傳的錯誤訊息 }) 在 resources/assets/js/bootstrap.js\n為了不用每一次送 API 請求都要手動加上 token， 我們修改 axios 的預設\n/** * We will use laravel/passport JWT to verify API permission. * Once user success to login, get a access token. The access token will be * stored in the Local Storage of browser. */ let accessToken = JSON.parse(window.localStorage.getItem('accessToken')|| null); if (accessToken) { window.axios.defaults.headers.common['Authorization'] = accessToken; } 補充\n可以在 app/Exceptions/Handler.php 做 error handle\n在這裡把全部的 api error 都回傳 401 未驗證， 不良示範XDD /** * Convert an authentication exception into an unauthenticated response. * * @param \\Illuminate\\Http\\Request $request * @param \\Illuminate\\Auth\\AuthenticationException $exception * @return \\Illuminate\\Http\\Response */ protected function unauthenticated($request, AuthenticationException $exception) { if ($request-\u0026gt;expectsJson()) { return response()-\u0026gt;json(['error' =\u0026gt; 'Unauthenticated.'], 401); } $guard = array_get($exception-\u0026gt;guards(), 0); switch ($guard) { case 'web': $login = 'login'; break; case 'api': return response()-\u0026gt;json(['error' =\u0026gt; 'API Unauthenticated.'], 401); break; } return redirect()-\u0026gt;guest(route($login)); } 參考 Laravel 官方 Laravel Passport JWT Authentication\nOAuth2 什麼是 OAuth? 例如說你從你的服務要跟 google 拿取使用者的資訊\n- - Resource Owner 使用者 Client 你的服務 Authorization Server 授權者，服務跟這邊拿token 如: google Resource Server 服務會跟這裡拿資料 開始安裝 - 實戰時間 前幾個步驟同官方教學\n1. composer 載回來 composer require laravel/passport\n2. 開表 php artisan migrate\n然後你會多 5 張表 (主要使用到 oauth_access_token)\n$ php artisan migrate Migrating: 2016_06_01_000001_create_oauth_auth_codes_table Migrated: 2016_06_01_000001_create_oauth_auth_codes_table Migrating: 2016_06_01_000002_create_oauth_access_tokens_table Migrated: 2016_06_01_000002_create_oauth_access_tokens_table Migrating: 2016_06_01_000003_create_oauth_refresh_tokens_table Migrated: 2016_06_01_000003_create_oauth_refresh_tokens_table Migrating: 2016_06_01_000004_create_oauth_clients_table Migrated: 2016_06_01_000004_create_oauth_clients_table Migrating: 2016_06_01_000005_create_oauth_personal_access_clients_table Migrated: 2016_06_01_000005_create_oauth_personal_access_clients_table 3. 創造 key php artisan passport:install\n他會幫你的 OAuth Server 準備一對 Key (storage/oauth-private.key, storage/outhpublic.key)\n同時也準備一組 Client Key 在 oauth_clients 資料表內\n$ php artisan passport:install Encryption keys generated successfully. Personal access client created successfully. Client ID: 1 Client secret: VJZEYfTpsHBkNCv9ULUyHvGBbJvYiD1ZVP86cbYu Password grant client created successfully. Client ID: 2 Client secret: l4kh71C2DpdUsNmJFipi0hiDnhdgj6VfF5lGGDam 4. 附加 passport 至 auth 系統 在 app\\User.php 新增一個 trait Laravel\\Passport\\HasApiTokens line:5,11 \u0026lt;?php namespace App; use Laravel\\Passport\\HasApiTokens; use Illuminate\\Notifications\\Notifiable; use Illuminate\\Foundation\\Auth\\User as Authenticatable; class User extends Authenticatable { use HasApiTokens, Notifiable; // other code... 在 app/Providers/AuthServiceProvider.php 新增 passport 的 route line:5 import passport line:29 add passport routes \u0026lt;?php namespace App\\Providers; use Laravel\\Passport\\Passport; use Illuminate\\Support\\Facades\\Gate; use Illuminate\\Foundation\\Support\\Providers\\AuthServiceProvider as ServiceProvider; class AuthServiceProvider extends ServiceProvider { /** * The policy mappings for the application. * * @var array */ protected $policies = [ 'App\\Model' =\u0026gt; 'App\\Policies\\ModelPolicy', ]; /** * Register any authentication / authorization services. * * @return void */ public function boot() { $this-\u0026gt;registerPolicies(); Passport::routes(); // set when access tokens expire Passport::tokensExpireIn(now()-\u0026gt;addDays(15)); } } 在 config/auth.php\n修改 guard 使用 passport 'guards' =\u0026gt; [ 'web' =\u0026gt; [ 'driver' =\u0026gt; 'session', 'provider' =\u0026gt; 'users', ], 'api' =\u0026gt; [ 'driver' =\u0026gt; 'passport', 'provider' =\u0026gt; 'users', ], ], ","id":53,"section":"posts","summary":"使用 JWT 版本 (2018/09 更新) 前面幾個步驟同官方安裝教學 步驟說明 1. composer 載回來 composer require laravel/passport 2. 開資料表 php artisan migrate 然後你會多 5 張表 (主要使用到 oauth_access_token) 3.創造 key php artisan passport:install 他會幫你的","tags":["php","laravel","passport","jwt"],"title":"筆記 Laravel API 權限 (Passport)","uri":"https://blog.10oz.tw/20190217-laravel-api-permission-by-passport/","year":"2019"},{"content":"新手入門 結構介紹 我們現在在 laravel v5.7\n一起來看一下 laravel 專案的結構吧\napp 大部份的網頁後端主要程式碼 也就是說他很重要\n(Model)放在外面的大寫開頭們～\n例如說 User.php 就是， 他們是 Model，定義了資料庫的物件模式\nHttp/\nControllers/\ncontroller可以作為路由進來後的流程控制器，可以想像它負責告訴大家要做什麼 Middleware/\nmiddleware叫做中間層，用來包著你的程式內容，request 進出都會經過 bootstrap 程式啟動第一個執行的套件\nconfig 所有應用的設定檔們\ndatabase 顧名思義：資料庫～\nmigrations/\n紀錄了資料庫的心路歷程\n其中定義了up跟down，模擬建立資料還有需要rollback回去時的動作 fatories/\n定義了一些資料的模式，可以使用seeder批量製造 seeds/\n他是一顆會長出資料的種子，當你需要產生測試用的資料的時候很常遇到他 public 對外公開給使用者看得到的資源\nEx: 圖片、webpack包裝過的檔案 resources 本地資源\nEx: js的原始碼、CSS\u0026hellip;\n/assets\n/js/components\n裡面寫了好多 vue component 們，他們是前端主力! /views\n這邊放了 blade ，他是 laravel選用的模板引擎，幫你更智慧的寫你的html\nroutes api.php 裡面註冊API web.php 裡面註冊網頁 他們最大的差別就是套用了不同的middleware\nstorage 網頁被儲存的資源\nEx: log日誌檔案(紀錄檔)、檔案快取 tests 測試單元、整合測試\n大家都說用TDD比較快ㄛ\nvendor 放別人code的地方\n拿別人的code來用\nlaradock 它幫助我們使用docker來建制服務\nlaradock/.env 存放 laradock的設定參數 其他檔案 .env 在這個網頁會用到的參數，像是資料庫的密碼 artisan 放了些 laravel 的工作指令 composer.json composer 用在 php 的套件管理 當你需要幫你的 php 程式裝點別人的套件的時候，你會進來這邊看看 package.json javascript 的套件版本管理，還有 npm 指令喔 webpack.min.js webpack 會幫你打包前端的資源們 簡單操作 (by Xiao \u0026amp; Andrew \u0026amp; Dagg) 註冊路由 寫在 routes/web.php\n這邊可以試著用你的路由連上預設的welcome首頁了\n你要在postman測試的話 要關掉csrf防禦 app/Http/Middleware/VerifyCsrfToken.php\nmigrate - 開個資料表 php artisan make:migration crete_todoList_table 檔案會在 ./database/migration/ 檔名範例: 2018_01_22_170244_crete_todoList_table\ncolumn 建立說明 https://laravel.com/docs/5.5/migrations#creating-columns\n寫個Controller php artisan make:controller TodoListController 在 ./app/Http/Controller/ 會長出來\nresource 如果你加上 \u0026ndash;resource 的話,它會長出預設的幾個功能框框 而你可以在route裡面 Route::resource() 來管理他們 https://laravel.com/docs/5.5/controllers#resource-controllers\n不得已用简体中文输入法的补充： 关于controller: 中层的class，管理http之间的行為（ ex: get and post method ） 另一种则是管理资源的class,管理对于资源的事件（ex: 图片的新增、修改、删除）, 称為resource controller 每一个controller都可以注册一个路由方便管理 如果想要resourcecontroller继承特定model特性的话, 可以在指令后方加上 --model=[model name] 所以我們的結論:\nAPI Controller + Model 的產生方法\nphp artisan make:controller TodoListController --resource --model=TodoList 如果不需要頁面的話　--resource 可以換成加上 --api 喔\nphp artisan make:controller API/TodoListController --api 用個model裝起來 php artisan make:model TodoList 會長出 ./app/TodoList.php\n在裡面寫你跟資料庫的互動等等(static function)\n然後你可以在controller裡面呼叫他們\nResource 打包你的資料 php artisan make:resource TodoList :::info app/Providers/AppServiceProvider 裡面的 boot() 可以加上 use Illuminate\\Http\\Resources\\Json\\Resource; Resource::withoutWrapping(); 它會不包裝你的response :::\nCollection 打包你的資料們 php artisan make:resource TodoListCollection 來灌些假資料 factory製造出假的資料、資料型態, seeder把他們寫起來\nphp artisan make:seeder TodoListSeeder php artisan make:factory TodoListFactory 首先去DatabaseSeeder 的 run 裡面, 把你要跑的seeder註冊個\n$this-\u0026gt;call([ TodoListSeeder::class, //other seeder ]); 再來是目標的TodoListSeeder 會用到factory回傳資料, 到 TodoListFactory 設計 這樣它會回傳5筆 fake 資料到資料庫\n//call factory to fake data factory(App\\TodoList::class, 5)-\u0026gt;create(); 執行 DatabaseSeeder 中被指定的 seeder 們\n./artisan db:seed BLOG - 實作時間 (by Dagg) 建立Article的Model 為了建立存放文章的Model輸入指令: php artisan make:model 'Article' --migration 同時建立該model的migration\n管理Article的Model class Article extends Model { protected $table = 'articles'; // $fillable 為可以填入的table protected $fillable = [ 'content' ]; } 建立Migration文件中資料表的欄位格式 $table-\u0026gt;increment(\u0026rsquo;_\u0026rsquo;); // 自動產生的key $table-\u0026gt;longText(\u0026rsquo;_\u0026rsquo;); // 放置無限字元的欄位 例如:文章內容 $table-\u0026gt;string(\u0026rsquo;_\u0026rsquo;); // 放置255字元內的字串欄位 $table-\u0026gt;softDeletes(); // 建立一個判別軟刪除的欄位 $table-\u0026gt;timestamps(); // 建立時間標記的欄位(會建立兩個欄位，一個放建立時間一個放更新時間) 調整完你要產生的欄位行別之後在終端機輸入: $ php artisan migrate\nController public function store(Request $request) // 建立一個store的函式 會接收Request { $article = $request-\u0026gt;input('article'); //把Request的input丟進去$article這個變數裡面 $show = new Article(); // 建立一個新的Article物件 $show-\u0026gt;content = $article; // 讓新建的Article物件轉成Request的input $show-\u0026gt;user_id = 1; // 紀錄user_id $show-\u0026gt;save(); // 把這個Article這個物件save return 'Hi'; // 測試用寫爽的 想不到吧 } ","id":54,"section":"posts","summary":"新手入門 結構介紹 我們現在在 laravel v5.7 一起來看一下 laravel 專案的結構吧 app 大部份的網頁後端主要程式碼 也就是說他很重要 (Model)放在外面的大寫開頭們～ 例如","tags":["php","laravel"],"title":"筆記 laravel 真新手時間","uri":"https://blog.10oz.tw/20190123-a-new-in-laravel/","year":"2019"},{"content":"Step by Step 安裝指南 事前準備 HomeBrew 首先安裝 HomeBrew，他是 Mac 上的套件管理工具\n在終端機執行他： (裝過了可以跳過)\n/usr/bin/ruby -e \u0026quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026quot; ＊ Docker 安裝 Docker， 以會需要他多多照顧\n不想登入可以直接點 下載連結 下載 .dmg 並安裝\n安裝 python3 用 brew 裝，已經裝好了，跳過\n安裝 docker-compose 就是把 docker 組隊，一次把一群不同 docker 給開起來的工具\npip3 install docker-compose ＊ 安裝 PHP (7.1.3以上) brew install php@7.2 ＊ 下載 Composer composer 是 php 的套件管理工具，想像他跟 pip, npm 這些的傢伙是一樣的\n可以直接跑下面的指令，或是到下載頁面下載 php -r \u0026quot;copy('https://getcomposer.org/installer', 'composer-setup.php');\u0026quot; php -r \u0026quot;if (hash_file('sha384', 'composer-setup.php') === '93b544968e392c0362774670ac182b134cd3b3a09695e5dca5e53c3728f1a9f115f20b3b754bf9a1be329d521bdaa8b26ac6a13e9a62d6444cdb0dc8a1da0806156398a5cbe587c3f0fe57a54d8f5') { echo 'Installer verified'; } else { echo 'Installer corrupt'; unlink('composer-setup.php'); } echo PHP_EOL;\u0026quot; php composer-setup.php php -r \u0026quot;unlink('composer-setup.php');\u0026quot; 裝完後會多出一個 composer.phar，我們把它放到可使用指令區 sudo mkdir /usr/local/bin -p sudo mv composer.phar /usr/local/bin/composer ＊ 安裝 NodeJS 來這邊安裝 https://nodejs.org/en/download/ 目前我使用的版本是 8.12 ，不過下載到 10版的應該也不會有問題啦 \u0026gt; \u0026lt;\n下載 Laravel 框架 移動到要安裝的資料夾，例如： cd ~/project 利用 git 下載， 完成後會多一個 practice 資料夾 git clone https://github.com/laravel/laravel.git practice 安裝 Laravel 相依套件 移動到專案資料夾 cd practice 利用 composer 安裝 php 的相依套件 composer install 更新一下 js 套件 npm install 更改權限 sudo chmod -R 777 storage/ bootstrap/cache/ 試試看能不能開服務啦～～～ php artisan serve 用你的瀏覽器開這個 http://127.0.0.1:8000\n敲棒der～～～ 開過後，更改權限2 sudo chmod -R 777 storage/ 好像\u0026hellip;還缺了些東西？ 那我的資料庫呢？ 我們找 Laradock來幫我們吧!\n＊ 在 project 裡面安裝 laradock # cd ~/project/practice git submodule add https://github.com/Laradock/laradock.git 裝好之後, 我們複製一份 laravel 的設定檔 cp .env.example .env 產生 app key php artisan key:generate 然後修改一下 MySQL 連線的設定 # at ~/project/practice/.env # line 9 DB_CONNECTION=mysql DB_HOST=mysql DB_PORT=3306 DB_DATABASE=default DB_USERNAME=default DB_PASSWORD=secret 還有 laradock 的也是 cd laradock cp env-example .env 最後我們要小改一下，改變 laradock 存檔的位置 # line 14 DATA_PATH_HOST=~/.laradock/practice-data 下載 docker image docker pull xiao4011/laradock_mysql docker tag xiao4011/laradock_mysql:latest laradock_mysql:latest 看起來設定好了，跑跑看？ laradock 也可以幫你開很多不同的服務，這裡我們先開好我們需要用的\ndocker-compose up -d mysql phpmyadmin 試試看連線 回到外層，也就是 ~/project/practice\n執行一下這個指令\nphp artisan migrate 他幫你建了幾張 table 你就成功了\nBonus 找個視窗開啟服務 php artisan serve 執行一下這個指令，看看多了些什麼\nphp artisan make:auth 就自動幫你建好會員登入系統了，很方便ㄅ\nTo Be Continue\u0026hellip; 下集待續\n","id":55,"section":"posts","summary":"Step by Step 安裝指南 事前準備 HomeBrew 首先安裝 HomeBrew，他是 Mac 上的套件管理工具 在終端機執行他： (裝過了可以跳過) /usr/bin/ruby -e \u0026quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026quot; ＊ Docker 安裝 Docker， 以","tags":["php","laravel"],"title":"筆記 安裝 Laravel on MacOS","uri":"https://blog.10oz.tw/20190117-install-laravel-on-macos/","year":"2019"},{"content":"需求 讓 console log 可以正確顯示來源 ip 而不是被 web server 轉發的 ip\n實作修改 覆蓋掉 address_string 這個 function line:8 覆蓋掉 log function line:9\nimport logging # get werkzeug_logger werkzeug_logger = logging.getLogger('werkzeug') # Override the built-in werkzeug logging function in order to change the log line format. from werkzeug.serving import WSGIRequestHandler WSGIRequestHandler.address_string = lambda self: \\ self.headers.get('X-Forwarded-For') if self.headers.get('X-Forwarded-For') else self.client_address[0] WSGIRequestHandler.log = lambda self, type, message, *args: \\ getattr(werkzeug_logger, type)('%s %s' % (self.address_string(), message % args)) ","id":56,"section":"posts","summary":"需求 讓 console log 可以正確顯示來源 ip 而不是被 web server 轉發的 ip 實作修改 覆蓋掉 address_string 這個 function line:8 覆蓋掉 log function line:9 import logging # get werkzeug_logger werkzeug_logger = logging.getLogger('werkzeug') # Override the built-in werkzeug logging function in order to change the log line format. from werkzeug.serving import WSGIRequestHandler WSGIRequestHandler.address_string","tags":["python","flask"],"title":"筆記 自定義 flask 的 console log 之路","uri":"https://blog.10oz.tw/20181128-custom-flask-console-log/","year":"2018"},{"content":"問題描述 同時開太多連線啦\n環境 Ubuntu 16.04\n解決方法 https://blog.csdn.net/qq_23926575/article/details/76619827\n開啟這個檔案 sudo vim /etc/security/limits.conf\n在最底下新增兩行\n* soft nofile 10000 * hard nofile 10000 記得重開Server\n","id":57,"section":"posts","summary":"問題描述 同時開太多連線啦 環境 Ubuntu 16.04 解決方法 https://blog.csdn.net/qq_23926575/article/details/76619827 開啟這個檔案 sudo vim /etc/security/limits.conf 在最底下新增兩行 * soft nofile 10000 * hard nofile 10000 記得重開Server","tags":["python"],"title":"筆記 python: Error 24: too many open files","uri":"https://blog.10oz.tw/20181120-python-error24-too-many-open-files/","year":"2018"},{"content":"錯誤: 目標是成功執行它：\npip3 install mysqlclient arios@AriosMac: pymysql_pool » pip3 install mysqlclient Collecting mysqlclient Using cached https://files.pythonhosted.org/packages/ec/fd/83329b9d3e14f7344d1cb31f128e6dbba70c5975c9e57896815dbb1988ad/mysqlclient-1.3.13.tar.gz Complete output from command python setup.py egg_info: /bin/sh: mysql_config: command not found Traceback (most recent call last): File \u0026quot;\u0026lt;string\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; File \u0026quot;/private/var/folders/xf/g7567kgs05vf5t8zfrnfh9th0000gn/T/pip-install-pqr5axvg/mysqlclient/setup.py\u0026quot;, line 18, in \u0026lt;module\u0026gt; metadata, options = get_config() File \u0026quot;/private/var/folders/xf/g7567kgs05vf5t8zfrnfh9th0000gn/T/pip-install-pqr5axvg/mysqlclient/setup_posix.py\u0026quot;, line 53, inget_config libs = mysql_config(\u0026quot;libs_r\u0026quot;) File \u0026quot;/private/var/folders/xf/g7567kgs05vf5t8zfrnfh9th0000gn/T/pip-install-pqr5axvg/mysqlclient/setup_posix.py\u0026quot;, line 28, inmysql_config raise EnvironmentError(\u0026quot;%s not found\u0026quot; % (mysql_config.path,)) OSError: mysql_config not found ---------------------------------------- Command \u0026quot;python setup.py egg_info\u0026quot; failed with error code 1 in /private/var/folders/xf/g7567kgs05vf5t8zfrnfh9th0000gn/T/pip-install-pqr5axvg/mysqlclient/ 解決方法 for ubuntu 16 LTS：\napt install -y libmysqlclient-dev for mac:\nbrew install mysql ","id":58,"section":"posts","summary":"錯誤: 目標是成功執行它： pip3 install mysqlclient arios@AriosMac: pymysql_pool » pip3 install mysqlclient Collecting mysqlclient Using cached https://files.pythonhosted.org/packages/ec/fd/83329b9d3e14f7344d1cb31f128e6dbba70c5975c9e57896815dbb1988ad/mysqlclient-1.3.13.tar.gz Complete output from command python setup.py egg_info: /bin/sh: mysql_config: command not found Traceback (most recent call last): File \u0026quot;\u0026lt;string\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt; File \u0026quot;/private/var/folders/xf/g7567kgs05vf5t8zfrnfh9th0000gn/T/pip-install-pqr5axvg/mysqlclient/setup.py\u0026quot;, line 18, in \u0026lt;module\u0026gt; metadata, options = get_config() File \u0026quot;/private/var/folders/xf/g7567kgs05vf5t8zfrnfh9th0000gn/T/pip-install-pqr5axvg/mysqlclient/setup_posix.py\u0026quot;, line 53, inget_config libs = mysql_config(\u0026quot;libs_r\u0026quot;) File \u0026quot;/private/var/folders/xf/g7567kgs05vf5t8zfrnfh9th0000gn/T/pip-install-pqr5axvg/mysqlclient/setup_posix.py\u0026quot;, line","tags":["python","mysql","mysqlclient"],"title":"筆記 mysqlclient 安裝, error: python setup.py egg_info ","uri":"https://blog.10oz.tw/20181117-install-mysqlclient/","year":"2018"},{"content":"問題 當你的函示庫底層使用 C語言 而不是純 python 編寫時 pylint 可能會無法正確的找到他，此問題可能出現在numpy或是本例的mysqlclient上\n解決方法 加入以下至白名單 $vim ~/.pylintrc\nextension-pkg-whitelist=MySQLdb ","id":59,"section":"posts","summary":"問題 當你的函示庫底層使用 C語言 而不是純 python 編寫時 pylint 可能會無法正確的找到他，此問題可能出現在numpy或是本例的mysqlclient上 解決方法","tags":["python","vscode"],"title":"筆記 解決 VSCode 上 pylint 無法解析 c 函式庫的內容","uri":"https://blog.10oz.tw/20181108-run-pylint-clib-on-vscode/","year":"2018"}],"tags":[{"title":"apt","uri":"https://blog.10oz.tw/tags/apt/"},{"title":"argo","uri":"https://blog.10oz.tw/tags/argo/"},{"title":"artisan","uri":"https://blog.10oz.tw/tags/artisan/"},{"title":"aws","uri":"https://blog.10oz.tw/tags/aws/"},{"title":"blockchain","uri":"https://blog.10oz.tw/tags/blockchain/"},{"title":"buildx","uri":"https://blog.10oz.tw/tags/buildx/"},{"title":"casbin","uri":"https://blog.10oz.tw/tags/casbin/"},{"title":"cd","uri":"https://blog.10oz.tw/tags/cd/"},{"title":"chromedp","uri":"https://blog.10oz.tw/tags/chromedp/"},{"title":"chromium","uri":"https://blog.10oz.tw/tags/chromium/"},{"title":"crd","uri":"https://blog.10oz.tw/tags/crd/"},{"title":"de","uri":"https://blog.10oz.tw/tags/de/"},{"title":"di","uri":"https://blog.10oz.tw/tags/di/"},{"title":"docker","uri":"https://blog.10oz.tw/tags/docker/"},{"title":"ecr","uri":"https://blog.10oz.tw/tags/ecr/"},{"title":"elasticsearch","uri":"https://blog.10oz.tw/tags/elasticsearch/"},{"title":"eloquent","uri":"https://blog.10oz.tw/tags/eloquent/"},{"title":"es","uri":"https://blog.10oz.tw/tags/es/"},{"title":"ethereum","uri":"https://blog.10oz.tw/tags/ethereum/"},{"title":"flask","uri":"https://blog.10oz.tw/tags/flask/"},{"title":"future","uri":"https://blog.10oz.tw/tags/future/"},{"title":"geographic","uri":"https://blog.10oz.tw/tags/geographic/"},{"title":"geth","uri":"https://blog.10oz.tw/tags/geth/"},{"title":"gfw","uri":"https://blog.10oz.tw/tags/gfw/"},{"title":"git","uri":"https://blog.10oz.tw/tags/git/"},{"title":"github","uri":"https://blog.10oz.tw/tags/github/"},{"title":"gitlab","uri":"https://blog.10oz.tw/tags/gitlab/"},{"title":"golang","uri":"https://blog.10oz.tw/tags/golang/"},{"title":"golnag","uri":"https://blog.10oz.tw/tags/golnag/"},{"title":"gomod","uri":"https://blog.10oz.tw/tags/gomod/"},{"title":"gql","uri":"https://blog.10oz.tw/tags/gql/"},{"title":"graphql","uri":"https://blog.10oz.tw/tags/graphql/"},{"title":"ha","uri":"https://blog.10oz.tw/tags/ha/"},{"title":"helm","uri":"https://blog.10oz.tw/tags/helm/"},{"title":"homebrew","uri":"https://blog.10oz.tw/tags/homebrew/"},{"title":"hugo","uri":"https://blog.10oz.tw/tags/hugo/"},{"title":"ilm","uri":"https://blog.10oz.tw/tags/ilm/"},{"title":"index","uri":"https://blog.10oz.tw/tags/index/"},{"title":"istio","uri":"https://blog.10oz.tw/tags/istio/"},{"title":"javascript","uri":"https://blog.10oz.tw/tags/javascript/"},{"title":"json","uri":"https://blog.10oz.tw/tags/json/"},{"title":"jwt","uri":"https://blog.10oz.tw/tags/jwt/"},{"title":"keycloak","uri":"https://blog.10oz.tw/tags/keycloak/"},{"title":"kind","uri":"https://blog.10oz.tw/tags/kind/"},{"title":"kops","uri":"https://blog.10oz.tw/tags/kops/"},{"title":"kubernetes","uri":"https://blog.10oz.tw/tags/kubernetes/"},{"title":"laravel","uri":"https://blog.10oz.tw/tags/laravel/"},{"title":"linux","uri":"https://blog.10oz.tw/tags/linux/"},{"title":"location","uri":"https://blog.10oz.tw/tags/location/"},{"title":"log","uri":"https://blog.10oz.tw/tags/log/"},{"title":"macos","uri":"https://blog.10oz.tw/tags/macos/"},{"title":"mongodb","uri":"https://blog.10oz.tw/tags/mongodb/"},{"title":"multi-arch","uri":"https://blog.10oz.tw/tags/multi-arch/"},{"title":"mysql","uri":"https://blog.10oz.tw/tags/mysql/"},{"title":"mysqlclient","uri":"https://blog.10oz.tw/tags/mysqlclient/"},{"title":"neovim","uri":"https://blog.10oz.tw/tags/neovim/"},{"title":"nix","uri":"https://blog.10oz.tw/tags/nix/"},{"title":"nixos","uri":"https://blog.10oz.tw/tags/nixos/"},{"title":"oauth","uri":"https://blog.10oz.tw/tags/oauth/"},{"title":"operator","uri":"https://blog.10oz.tw/tags/operator/"},{"title":"orm","uri":"https://blog.10oz.tw/tags/orm/"},{"title":"passport","uri":"https://blog.10oz.tw/tags/passport/"},{"title":"php","uri":"https://blog.10oz.tw/tags/php/"},{"title":"pokemon","uri":"https://blog.10oz.tw/tags/pokemon/"},{"title":"pokesay","uri":"https://blog.10oz.tw/tags/pokesay/"},{"title":"postgres","uri":"https://blog.10oz.tw/tags/postgres/"},{"title":"pretty","uri":"https://blog.10oz.tw/tags/pretty/"},{"title":"python","uri":"https://blog.10oz.tw/tags/python/"},{"title":"raycast","uri":"https://blog.10oz.tw/tags/raycast/"},{"title":"ruby","uri":"https://blog.10oz.tw/tags/ruby/"},{"title":"rust","uri":"https://blog.10oz.tw/tags/rust/"},{"title":"service-mesh","uri":"https://blog.10oz.tw/tags/service-mesh/"},{"title":"subgroup","uri":"https://blog.10oz.tw/tags/subgroup/"},{"title":"terraform","uri":"https://blog.10oz.tw/tags/terraform/"},{"title":"test","uri":"https://blog.10oz.tw/tags/test/"},{"title":"typescript","uri":"https://blog.10oz.tw/tags/typescript/"},{"title":"ubuntu","uri":"https://blog.10oz.tw/tags/ubuntu/"},{"title":"vagrant","uri":"https://blog.10oz.tw/tags/vagrant/"},{"title":"vim","uri":"https://blog.10oz.tw/tags/vim/"},{"title":"vm","uri":"https://blog.10oz.tw/tags/vm/"},{"title":"vpn","uri":"https://blog.10oz.tw/tags/vpn/"},{"title":"vrrp","uri":"https://blog.10oz.tw/tags/vrrp/"},{"title":"vscode","uri":"https://blog.10oz.tw/tags/vscode/"},{"title":"windows","uri":"https://blog.10oz.tw/tags/windows/"},{"title":"wire","uri":"https://blog.10oz.tw/tags/wire/"},{"title":"wsl2","uri":"https://blog.10oz.tw/tags/wsl2/"}]}